{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well-formedness rules\n",
    "\n",
    "1. Start with 1\n",
    "2. Forbid 00100 (no 100, 001 on the boundary)\n",
    "3. Forbid 0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1., -1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1.,  1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "well_formed_set = np.zeros([1,10])\n",
    "well_formed_set[0,0] = 1\n",
    "\n",
    "for i in range(1,n):\n",
    "    for j in range(np.shape(well_formed_set)[0]):\n",
    "        if i == 2 and np.array_equal(well_formed_set[j,i-2:i], [1,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        elif i > 3 and np.array_equal(well_formed_set[j,i-3:i], [0,0,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        elif i > 3 and np.array_equal(well_formed_set[j,i-4:i], [0,0,1,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        else:\n",
    "            well_formed_set = np.append(well_formed_set, well_formed_set[j:j+1,:], axis=0)\n",
    "            well_formed_set[j,i] = 1\n",
    "            \n",
    "ind = np.array([], dtype=np.int8)\n",
    "for i in range(well_formed_set.shape[0]):\n",
    "    if np.array_equal(well_formed_set[i,-3:], [0,0,1]):\n",
    "        ind = np.append(ind,i)\n",
    "\n",
    "well_formed_set = np.delete(well_formed_set,ind,0)\n",
    "well_formed_set = (well_formed_set - 0.5)*2\n",
    "well_formed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 10)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_formed_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_formed_set[165,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = np.transpose(well_formed_set)\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z):\n",
    "    q_2 = sigmoid(np.matmul(Phi_12,data) + b_12)\n",
    "    x = ((q_2 > np.random.rand(n_x,1)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    # x = np.where(q_2 > 0.5,1,-1)  # deterministic\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    y = ((q_3 > np.random.rand(n_y,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    z = ((q_4 > np.random.rand(n_z,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    Q_2 = (np.cumprod(q_2[np.where(x == 1)])[-1] if q_2[np.where(x == 1)].size != 0 else 1) * (np.cumprod(1-q_2[np.where(x == -1)])[-1] if q_2[np.where(x == -1)].size != 0 else 1)*(1.5**n_x)\n",
    "    Q_3 = (np.cumprod(q_3[np.where(y == 1)])[-1] if q_3[np.where(y == 1)].size != 0 else 1) * (np.cumprod(1-q_3[np.where(y == -1)])[-1] if q_3[np.where(y == -1)].size != 0 else 1)*(1.5**n_y)\n",
    "    Q_4 = (np.cumprod(q_4[np.where(z == 1)])[-1] if q_4[np.where(z == 1)].size != 0 else 1) * (np.cumprod(1-q_4[np.where(z == -1)])[-1] if q_4[np.where(z == -1)].size != 0 else 1)*(1.5**n_z)\n",
    "    Q = Q_2 * Q_3 * Q_4\n",
    "    \n",
    "    return q_2,q_3,q_4,x,y,z,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,1)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    d = ((p_1 > np.random.rand(n_d,1)).astype(int) - 0.5)*2  # sampling\n",
    "    # d = np.where(p_1 > 0.5,1,-1)  # deterministic\n",
    "    \n",
    "    P_4 = (np.cumprod(p_4[np.where(z == 1)])[-1] if p_4[np.where(z == 1)].size != 0 else 1)* (np.cumprod(1-p_4[np.where(z == -1)])[-1] if p_4[np.where(z == -1)].size != 0 else 1)*(1.5**n_z)\n",
    "    P_3 = (np.cumprod(p_3[np.where(y == 1)])[-1] if p_3[np.where(y == 1)].size != 0 else 1)* (np.cumprod(1-p_3[np.where(y == -1)])[-1] if p_3[np.where(y == -1)].size != 0 else 1)*(1.5**n_y)\n",
    "    P_2 = (np.cumprod(p_2[np.where(x == 1)])[-1] if p_2[np.where(x == 1)].size != 0 else 1)* (np.cumprod(1-p_2[np.where(x == -1)])[-1] if p_2[np.where(x == -1)].size != 0 else 1)*(1.5**n_x)\n",
    "    P_1 = (np.cumprod(p_1[np.where(d == 1)])[-1] if p_1[np.where(d == 1)].size != 0 else 1)* (np.cumprod(1-p_1[np.where(d == -1)])[-1] if p_1[np.where(d == -1)].size != 0 else 1)*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta(z,y,x,d,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    Theta -= lr * (p_4 - (1+z)/2)\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    Theta_43 -= lr * np.outer((p_3 - (1+y)/2), z)\n",
    "    b_43 -= lr * (p_3 - (1+y)/2)\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    Theta_32 -= lr * np.outer((p_2 - (1+x)/2), y)\n",
    "    b_32 -= lr * (p_2 - (1+x)/2)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    Theta_21 -= lr * np.outer((p_1 - (1+d)/2), x)\n",
    "    b_21 -= lr * (p_1 - (1+d)/2)\n",
    "    \n",
    "    return Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta(z,y,x,d,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr):\n",
    "    \n",
    "    q_2 = sigmoid(np.matmul(Phi_12,d) + b_12)\n",
    "    Phi_12 -= lr * np.outer((q_2 - (1+x)/2), d)\n",
    "    b_12 -= lr * (q_2 - (1+x)/2)\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    Phi_23 -= lr * np.outer((q_3 - (1+y)/2), x)\n",
    "    b_23 -= lr * (q_3 - (1+y)/2)\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    Phi_34 -= lr * np.outer((q_4 - (1+z)/2), y)\n",
    "    b_34 -= lr * (q_4 - (1+z)/2)\n",
    "    \n",
    "    return Phi_12,Phi_23,Phi_34,b_12,b_23,b_34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 3\n",
    "n_y = 5\n",
    "n_x = 8\n",
    "n_d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "\n",
    "Phi_12 = np.random.rand(n_x,n_d) *2-1\n",
    "Phi_23 = np.random.rand(n_y,n_x) *2-1\n",
    "Phi_34 = np.random.rand(n_z,n_y) *2-1\n",
    "b_12 = np.random.rand(n_x,1) *2-1\n",
    "b_23 = np.random.rand(n_y,1) *2-1\n",
    "b_34 = np.random.rand(n_z,1) *2-1\n",
    "\n",
    "Theta = np.random.rand(n_z,1) *2-1\n",
    "Theta_43 = np.random.rand(n_y,n_z) *2-1\n",
    "Theta_32 = np.random.rand(n_x,n_y) *2-1\n",
    "Theta_21 = np.random.rand(n_d,n_x) *2-1\n",
    "b_43 = np.random.rand(n_y,1) *2-1\n",
    "b_32 = np.random.rand(n_x,1) *2-1\n",
    "b_21 = np.random.rand(n_d,1) *2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero initialization\n",
    "\n",
    "Phi_12 = np.zeros((n_x,n_d))\n",
    "Phi_23 = np.zeros((n_y,n_x))\n",
    "Phi_34 = np.zeros((n_z,n_y))\n",
    "b_12 = np.zeros((n_x,1))\n",
    "b_23 = np.zeros((n_y,1))\n",
    "b_34 = np.zeros((n_z,1))\n",
    "\n",
    "Theta = np.zeros((n_z,1))\n",
    "Theta_43 = np.zeros((n_y,n_z))\n",
    "Theta_32 = np.zeros((n_x,n_y))\n",
    "Theta_21 = np.zeros((n_d,n_x))\n",
    "b_43 = np.zeros((n_y,1))\n",
    "b_32 = np.zeros((n_x,1))\n",
    "b_21 = np.zeros((n_d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "#print (\"Phi_23: \" + str(Phi_23))\n",
    "#print (\"Phi_34: \" + str(Phi_34))\n",
    "#print (\"b_12: \" + str(b_12))\n",
    "#print (\"b_23: \" + str(b_23))\n",
    "#print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "#print (\"Theta_43: \" + str(Theta_43))\n",
    "#print (\"Theta_32: \" + str(Theta_32))\n",
    "#print (\"Theta_21: \" + str(Theta_21))\n",
    "#print (\"b_43: \" + str(b_43))\n",
    "#print (\"b_32: \" + str(b_32))\n",
    "#print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_12_cache = np.copy(Phi_12)\n",
    "Phi_23_cache = np.copy(Phi_23)\n",
    "Phi_34_cache = np.copy(Phi_34)\n",
    "b_12_cache = np.copy(b_12)\n",
    "b_23_cache = np.copy(b_23)\n",
    "b_34_cache = np.copy(b_34)\n",
    "\n",
    "Theta_cache = np.copy(Theta)\n",
    "Theta_43_cache = np.copy(Theta_43)\n",
    "Theta_32_cache = np.copy(Theta_32)\n",
    "Theta_21_cache = np.copy(Theta_21)\n",
    "b_43_cache = np.copy(b_43)\n",
    "b_32_cache = np.copy(b_32)\n",
    "b_21_cache = np.copy(b_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recog_phi: 0.29479901203034636\n",
      "recog_b: 0.028927818497181224\n",
      "gener_theta: 0.2442870321288813\n",
      "gener_b: 0.01834654513287689\n",
      "\n",
      "recog_phi: 0.2948256489061123\n",
      "recog_b: 0.027236174485635145\n",
      "gener_theta: 0.22088436866831984\n",
      "gener_b: 0.018744086572131464\n",
      "\n",
      "recog_phi: 0.2557471087879754\n",
      "recog_b: 0.023859276773154577\n",
      "gener_theta: 0.2165501468774471\n",
      "gener_b: 0.022079992235649527\n",
      "\n",
      "recog_phi: 0.2895937986774551\n",
      "recog_b: 0.038005127955795824\n",
      "gener_theta: 0.2834487812778213\n",
      "gener_b: 0.03903057644468155\n",
      "\n",
      "recog_phi: 0.33209077628261596\n",
      "recog_b: 0.03328008493878254\n",
      "gener_theta: 0.21104712575391144\n",
      "gener_b: 0.012226780222439195\n",
      "\n",
      "recog_phi: 0.29473441019862634\n",
      "recog_b: 0.02681140463368239\n",
      "gener_theta: 0.28289129652338063\n",
      "gener_b: 0.03285355969174268\n",
      "\n",
      "recog_phi: 0.29703480498435886\n",
      "recog_b: 0.02625259126613757\n",
      "gener_theta: 0.30436347015567994\n",
      "gener_b: 0.02853092100370558\n",
      "\n",
      "recog_phi: 0.31735340416394353\n",
      "recog_b: 0.029469204555793604\n",
      "gener_theta: 0.3121973226368945\n",
      "gener_b: 0.043215648329609196\n",
      "\n",
      "recog_phi: 0.44034158581222393\n",
      "recog_b: 0.05989248052514425\n",
      "gener_theta: 0.2946456268825942\n",
      "gener_b: 0.042700242809101494\n",
      "\n",
      "recog_phi: 0.2924870366546161\n",
      "recog_b: 0.030036280087228584\n",
      "gener_theta: 0.2602557944161231\n",
      "gener_b: 0.02678279410509447\n",
      "\n",
      "recog_phi: 0.3154549655486238\n",
      "recog_b: 0.03170543484937814\n",
      "gener_theta: 0.2451309907993296\n",
      "gener_b: 0.02608850154553708\n",
      "\n",
      "recog_phi: 0.24544505097853891\n",
      "recog_b: 0.012755507616716778\n",
      "gener_theta: 0.2762823504755657\n",
      "gener_b: 0.025156988026197605\n",
      "\n",
      "recog_phi: 0.2513833755825267\n",
      "recog_b: 0.02504848939298207\n",
      "gener_theta: 0.26864922968846994\n",
      "gener_b: 0.04054110944173836\n",
      "\n",
      "recog_phi: 0.23992398999729503\n",
      "recog_b: 0.02916843146703718\n",
      "gener_theta: 0.23017515565192478\n",
      "gener_b: 0.02896781802031729\n",
      "\n",
      "recog_phi: 0.24756858366698561\n",
      "recog_b: 0.02315358274032755\n",
      "gener_theta: 0.26826587592458934\n",
      "gener_b: 0.05059403236586183\n",
      "\n",
      "recog_phi: 0.37454681739087897\n",
      "recog_b: 0.038938299210136626\n",
      "gener_theta: 0.2759320560838149\n",
      "gener_b: 0.02220542436656181\n",
      "\n",
      "recog_phi: 0.28533058571675834\n",
      "recog_b: 0.028195068127753985\n",
      "gener_theta: 0.30460425949085945\n",
      "gener_b: 0.01250724690156843\n",
      "\n",
      "recog_phi: 0.32424258033986514\n",
      "recog_b: 0.03645668398162886\n",
      "gener_theta: 0.30203452991996405\n",
      "gener_b: 0.04262734083217152\n",
      "\n",
      "recog_phi: 0.2763953724305379\n",
      "recog_b: 0.0406926838883348\n",
      "gener_theta: 0.22982755709562058\n",
      "gener_b: 0.03479866255454285\n",
      "\n",
      "recog_phi: 0.27244072505777195\n",
      "recog_b: 0.01195189062519491\n",
      "gener_theta: 0.28104754624864997\n",
      "gener_b: 0.031907007901109695\n",
      "\n",
      "recog_phi: 0.3797899888289388\n",
      "recog_b: 0.05897772228307281\n",
      "gener_theta: 0.28227262357244515\n",
      "gener_b: 0.028449955810756034\n",
      "\n",
      "recog_phi: 0.3276963374600849\n",
      "recog_b: 0.03366566270389064\n",
      "gener_theta: 0.24009560856955706\n",
      "gener_b: 0.05126393116467182\n",
      "\n",
      "recog_phi: 0.30103323393202647\n",
      "recog_b: 0.017574021756872255\n",
      "gener_theta: 0.30951892927105834\n",
      "gener_b: 0.019377101968786368\n",
      "\n",
      "recog_phi: 0.2712106676379402\n",
      "recog_b: 0.022956848582985995\n",
      "gener_theta: 0.22745511935018053\n",
      "gener_b: 0.0157636277745326\n",
      "\n",
      "recog_phi: 0.28205890259245664\n",
      "recog_b: 0.019665732449751998\n",
      "gener_theta: 0.24904417727885111\n",
      "gener_b: 0.038681862769888824\n",
      "\n",
      "recog_phi: 0.2723589972805622\n",
      "recog_b: 0.02872610993586235\n",
      "gener_theta: 0.22582319840129658\n",
      "gener_b: 0.024963352064003807\n",
      "\n",
      "recog_phi: 0.29667014776775114\n",
      "recog_b: 0.019107536938252852\n",
      "gener_theta: 0.2220851275412759\n",
      "gener_b: 0.016691617498595143\n",
      "\n",
      "recog_phi: 0.33207199468779985\n",
      "recog_b: 0.02163991372731682\n",
      "gener_theta: 0.2749163886226299\n",
      "gener_b: 0.02965231362801605\n",
      "\n",
      "recog_phi: 0.378042428429649\n",
      "recog_b: 0.03544662087876774\n",
      "gener_theta: 0.2546528979121213\n",
      "gener_b: 0.034327351630267997\n",
      "\n",
      "recog_phi: 0.3351064477359838\n",
      "recog_b: 0.03537605022582983\n",
      "gener_theta: 0.22645076546025186\n",
      "gener_b: 0.030990762432086937\n",
      "\n",
      "recog_phi: 0.371841550789278\n",
      "recog_b: 0.045679765250863945\n",
      "gener_theta: 0.2810558844868422\n",
      "gener_b: 0.03798937828715956\n",
      "\n",
      "recog_phi: 0.38164674753319117\n",
      "recog_b: 0.08586274743885319\n",
      "gener_theta: 0.2790609222679441\n",
      "gener_b: 0.03860768904492434\n",
      "\n",
      "recog_phi: 0.2785733233571387\n",
      "recog_b: 0.025019004673498876\n",
      "gener_theta: 0.23901082024501327\n",
      "gener_b: 0.031019511331520637\n",
      "\n",
      "recog_phi: 0.3142785704586563\n",
      "recog_b: 0.026051837626239353\n",
      "gener_theta: 0.29523468150823334\n",
      "gener_b: 0.053733120973186\n",
      "\n",
      "recog_phi: 0.24451053526448063\n",
      "recog_b: 0.023400304820740132\n",
      "gener_theta: 0.2722666943263044\n",
      "gener_b: 0.021161175500312206\n",
      "\n",
      "recog_phi: 0.26287391015660944\n",
      "recog_b: 0.054921629370190204\n",
      "gener_theta: 0.3131051707556681\n",
      "gener_b: 0.043392328626341806\n",
      "\n",
      "recog_phi: 0.3202206629563319\n",
      "recog_b: 0.03619422340243722\n",
      "gener_theta: 0.24572388360454925\n",
      "gener_b: 0.017648868152830323\n",
      "\n",
      "recog_phi: 0.34965228308555696\n",
      "recog_b: 0.036552965208545445\n",
      "gener_theta: 0.2620196947143384\n",
      "gener_b: 0.01553508258809162\n",
      "\n",
      "recog_phi: 0.2377704542831897\n",
      "recog_b: 0.032753375550183865\n",
      "gener_theta: 0.2688568247322032\n",
      "gener_b: 0.021880780796216453\n",
      "\n",
      "recog_phi: 0.2603601504049869\n",
      "recog_b: 0.039224529251643644\n",
      "gener_theta: 0.24006156742361506\n",
      "gener_b: 0.02212660803161766\n",
      "\n",
      "recog_phi: 0.37334572945717537\n",
      "recog_b: 0.06103291438986275\n",
      "gener_theta: 0.24833361761809342\n",
      "gener_b: 0.03127379295689149\n",
      "\n",
      "recog_phi: 0.3056760324255014\n",
      "recog_b: 0.02340221191020057\n",
      "gener_theta: 0.29198552261560445\n",
      "gener_b: 0.03683678226572878\n",
      "\n",
      "recog_phi: 0.3755067068063438\n",
      "recog_b: 0.05256759107424587\n",
      "gener_theta: 0.29189722517729993\n",
      "gener_b: 0.020041024050698453\n",
      "\n",
      "recog_phi: 0.19472869454863856\n",
      "recog_b: 0.019531095905350158\n",
      "gener_theta: 0.2683512998430987\n",
      "gener_b: 0.028175317253667027\n",
      "\n",
      "recog_phi: 0.380690428564458\n",
      "recog_b: 0.026311189586515252\n",
      "gener_theta: 0.2900366622870492\n",
      "gener_b: 0.030829440194369055\n",
      "\n",
      "recog_phi: 0.3056517674040011\n",
      "recog_b: 0.019589120652893244\n",
      "gener_theta: 0.2669613067415096\n",
      "gener_b: 0.04009211553253711\n",
      "\n",
      "recog_phi: 0.2940497409609377\n",
      "recog_b: 0.027890812336570862\n",
      "gener_theta: 0.2513317575683363\n",
      "gener_b: 0.02611544270670849\n",
      "\n",
      "recog_phi: 0.27989547523262565\n",
      "recog_b: 0.0355486173366299\n",
      "gener_theta: 0.3315253547300677\n",
      "gener_b: 0.04814444207857392\n",
      "\n",
      "recog_phi: 0.2646453781086735\n",
      "recog_b: 0.01839713017616465\n",
      "gener_theta: 0.26082652846050547\n",
      "gener_b: 0.03734791514787235\n",
      "\n",
      "recog_phi: 0.26505771225568475\n",
      "recog_b: 0.034865592293056476\n",
      "gener_theta: 0.2721644017607667\n",
      "gener_b: 0.013413809846119198\n",
      "\n",
      "recog_phi: 0.4118738407068181\n",
      "recog_b: 0.036119484344142035\n",
      "gener_theta: 0.21796448895312465\n",
      "gener_b: 0.023973170755963204\n",
      "\n",
      "recog_phi: 0.21198918390733723\n",
      "recog_b: 0.022253190547562755\n",
      "gener_theta: 0.22666155390606496\n",
      "gener_b: 0.042884457147899666\n",
      "\n",
      "recog_phi: 0.21742012286779863\n",
      "recog_b: 0.01896300508464906\n",
      "gener_theta: 0.24390081879558326\n",
      "gener_b: 0.025409951665627584\n",
      "\n",
      "recog_phi: 0.2543405175249762\n",
      "recog_b: 0.020252193799359705\n",
      "gener_theta: 0.27427011103150745\n",
      "gener_b: 0.05205773588575903\n",
      "\n",
      "recog_phi: 0.31687821425778184\n",
      "recog_b: 0.03946255243474638\n",
      "gener_theta: 0.2545240664167333\n",
      "gener_b: 0.047051745873242984\n",
      "\n",
      "recog_phi: 0.3107430277066049\n",
      "recog_b: 0.05208617411280305\n",
      "gener_theta: 0.29190161944990933\n",
      "gener_b: 0.026354568576992858\n",
      "\n",
      "recog_phi: 0.29974607549580423\n",
      "recog_b: 0.043230340453385634\n",
      "gener_theta: 0.28439427835607345\n",
      "gener_b: 0.04038024992396838\n",
      "\n",
      "recog_phi: 0.18687798201586808\n",
      "recog_b: 0.01289654448543864\n",
      "gener_theta: 0.2632195577705654\n",
      "gener_b: 0.039419163004257254\n",
      "\n",
      "recog_phi: 0.22923128143871932\n",
      "recog_b: 0.019072981160286117\n",
      "gener_theta: 0.22417873616274422\n",
      "gener_b: 0.01991691834586086\n",
      "\n",
      "recog_phi: 0.29667062721105397\n",
      "recog_b: 0.03001740459366975\n",
      "gener_theta: 0.2524357973947812\n",
      "gener_b: 0.03137102906823565\n",
      "\n",
      "recog_phi: 0.33070274424161406\n",
      "recog_b: 0.023134618184427788\n",
      "gener_theta: 0.24807435745411746\n",
      "gener_b: 0.034625122498467886\n",
      "\n",
      "recog_phi: 0.27158391487217476\n",
      "recog_b: 0.02141887831362044\n",
      "gener_theta: 0.3391345032611411\n",
      "gener_b: 0.03694400499453742\n",
      "\n",
      "recog_phi: 0.3010482107929784\n",
      "recog_b: 0.028627620082537848\n",
      "gener_theta: 0.28257793981687096\n",
      "gener_b: 0.04360051059675382\n",
      "\n",
      "recog_phi: 0.28835466587346376\n",
      "recog_b: 0.030187163041277828\n",
      "gener_theta: 0.2846720399597008\n",
      "gener_b: 0.031043848341303814\n",
      "\n",
      "recog_phi: 0.3279159079431859\n",
      "recog_b: 0.05178021845332581\n",
      "gener_theta: 0.24266074224426876\n",
      "gener_b: 0.027130249911646868\n",
      "\n",
      "recog_phi: 0.314163839408424\n",
      "recog_b: 0.029290879234570483\n",
      "gener_theta: 0.25399404125859587\n",
      "gener_b: 0.04553169434267504\n",
      "\n",
      "recog_phi: 0.22461320440720767\n",
      "recog_b: 0.01943503611051122\n",
      "gener_theta: 0.25724988121338666\n",
      "gener_b: 0.03710343504944441\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recog_phi: 0.3048334719675991\n",
      "recog_b: 0.011546978862209276\n",
      "gener_theta: 0.2612583789822007\n",
      "gener_b: 0.028448903370493276\n",
      "\n",
      "recog_phi: 0.285413778104966\n",
      "recog_b: 0.02862003418441953\n",
      "gener_theta: 0.23776406519738208\n",
      "gener_b: 0.02476907991506533\n",
      "\n",
      "recog_phi: 0.314146826825152\n",
      "recog_b: 0.028167985975901616\n",
      "gener_theta: 0.246546145637598\n",
      "gener_b: 0.03108077744279113\n",
      "\n",
      "recog_phi: 0.1975381182469147\n",
      "recog_b: 0.014784059305945072\n",
      "gener_theta: 0.22748931158542143\n",
      "gener_b: 0.020568945682902587\n",
      "\n",
      "recog_phi: 0.29041399971763837\n",
      "recog_b: 0.02694108623279761\n",
      "gener_theta: 0.24381075667734853\n",
      "gener_b: 0.020170126967888877\n",
      "\n",
      "recog_phi: 0.2586589812154065\n",
      "recog_b: 0.034417929753887674\n",
      "gener_theta: 0.27131959517287474\n",
      "gener_b: 0.02298275860688452\n",
      "\n",
      "recog_phi: 0.2735237263692101\n",
      "recog_b: 0.023258048474713185\n",
      "gener_theta: 0.23405549153258365\n",
      "gener_b: 0.04608533130010377\n",
      "\n",
      "recog_phi: 0.2806320803321922\n",
      "recog_b: 0.024321865931606422\n",
      "gener_theta: 0.29754951680872493\n",
      "gener_b: 0.027523947315523736\n",
      "\n",
      "recog_phi: 0.32714181640126566\n",
      "recog_b: 0.03354512420910584\n",
      "gener_theta: 0.31037612892595756\n",
      "gener_b: 0.046399446276521726\n",
      "\n",
      "recog_phi: 0.34230917562447016\n",
      "recog_b: 0.04333735627541325\n",
      "gener_theta: 0.3074222605469228\n",
      "gener_b: 0.030876400093557046\n",
      "\n",
      "recog_phi: 0.2695940163141508\n",
      "recog_b: 0.02724511191811034\n",
      "gener_theta: 0.21973475871683149\n",
      "gener_b: 0.04671768551293071\n",
      "\n",
      "recog_phi: 0.26916202280193885\n",
      "recog_b: 0.0356927424014672\n",
      "gener_theta: 0.24451290113985838\n",
      "gener_b: 0.03139101688405564\n",
      "\n",
      "recog_phi: 0.303043183161223\n",
      "recog_b: 0.040080557593218984\n",
      "gener_theta: 0.23598079201783687\n",
      "gener_b: 0.020325071685913507\n",
      "\n",
      "recog_phi: 0.2637524986090972\n",
      "recog_b: 0.03955309371715802\n",
      "gener_theta: 0.3417413992216419\n",
      "gener_b: 0.07398176849424469\n",
      "\n",
      "recog_phi: 0.2848795036448992\n",
      "recog_b: 0.03755004579459507\n",
      "gener_theta: 0.33681753721115526\n",
      "gener_b: 0.05489064326073318\n",
      "\n",
      "recog_phi: 0.3901355574160401\n",
      "recog_b: 0.04417374268381761\n",
      "gener_theta: 0.24418623722430294\n",
      "gener_b: 0.027493213363175027\n",
      "\n",
      "recog_phi: 0.31755830022174003\n",
      "recog_b: 0.021517186045970714\n",
      "gener_theta: 0.22671322747162978\n",
      "gener_b: 0.029570870872977353\n",
      "\n",
      "recog_phi: 0.3554165393126113\n",
      "recog_b: 0.06678435211425021\n",
      "gener_theta: 0.22497076674694755\n",
      "gener_b: 0.04151125581753119\n",
      "\n",
      "recog_phi: 0.3431718349153781\n",
      "recog_b: 0.05125862841459997\n",
      "gener_theta: 0.2722324659573804\n",
      "gener_b: 0.04050651692815815\n",
      "\n",
      "recog_phi: 0.2578445380022559\n",
      "recog_b: 0.018685020887947115\n",
      "gener_theta: 0.27738285498138826\n",
      "gener_b: 0.029549595419187343\n",
      "\n",
      "recog_phi: 0.270857249943182\n",
      "recog_b: 0.02490804653497489\n",
      "gener_theta: 0.2067777311957088\n",
      "gener_b: 0.014099716611814856\n",
      "\n",
      "recog_phi: 0.3198205381662193\n",
      "recog_b: 0.06832425734791184\n",
      "gener_theta: 0.21335623319659675\n",
      "gener_b: 0.02709995861454764\n",
      "\n",
      "recog_phi: 0.38457167398476916\n",
      "recog_b: 0.06145564555191639\n",
      "gener_theta: 0.2516147004667258\n",
      "gener_b: 0.029417935900935104\n",
      "\n",
      "recog_phi: 0.28647970078855245\n",
      "recog_b: 0.014500939493330612\n",
      "gener_theta: 0.27516748866192714\n",
      "gener_b: 0.04445454557926969\n",
      "\n",
      "recog_phi: 0.27941547906663733\n",
      "recog_b: 0.03384653423808178\n",
      "gener_theta: 0.3827803104397376\n",
      "gener_b: 0.04944761351652985\n",
      "\n",
      "recog_phi: 0.306323707863301\n",
      "recog_b: 0.026223613988753194\n",
      "gener_theta: 0.23873161289846778\n",
      "gener_b: 0.02469215139710842\n",
      "\n",
      "recog_phi: 0.2863157560665874\n",
      "recog_b: 0.0342707499940584\n",
      "gener_theta: 0.2772444022232725\n",
      "gener_b: 0.01460060732527974\n",
      "\n",
      "recog_phi: 0.27279372907578653\n",
      "recog_b: 0.02849898237643934\n",
      "gener_theta: 0.3002950119015372\n",
      "gener_b: 0.02651486928268186\n",
      "\n",
      "recog_phi: 0.2853271381061277\n",
      "recog_b: 0.01775796548890861\n",
      "gener_theta: 0.29092030762108745\n",
      "gener_b: 0.037957284617039254\n",
      "\n",
      "recog_phi: 0.19815998121586872\n",
      "recog_b: 0.04775052245423441\n",
      "gener_theta: 0.2716702564343608\n",
      "gener_b: 0.023727399931420343\n",
      "\n",
      "recog_phi: 0.2829997089165841\n",
      "recog_b: 0.018332918638298997\n",
      "gener_theta: 0.19034711071074828\n",
      "gener_b: 0.013681197319110628\n",
      "\n",
      "recog_phi: 0.3495403848315532\n",
      "recog_b: 0.04447943400639518\n",
      "gener_theta: 0.2496365651885435\n",
      "gener_b: 0.02576680944486603\n",
      "\n",
      "recog_phi: 0.36578546253311556\n",
      "recog_b: 0.06503112814133255\n",
      "gener_theta: 0.23369893339905357\n",
      "gener_b: 0.02256383084573132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample-based training\n",
    "# Local delta rule\n",
    "for e in range(epoch):\n",
    "    num_samples = train_set.shape[1]\n",
    "    train_set = train_set[:,np.random.permutation(num_samples)]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        data = train_set[:,i:i+1]\n",
    "        q_2,q_3,q_4,x_w,y_w,z_w,Q = wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z)\n",
    "        Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta(z_w,y_w,x_w,data,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "        p_4,p_3,p_2,p_1,z_s,y_s,x_s,d_s,P = sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d)\n",
    "        Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta(z_s,y_s,x_s,d_s,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "\n",
    "    recog_phi = np.sum((Phi_12 - Phi_12_cache)**2) + np.sum((Phi_23 - Phi_23_cache)**2) + np.sum((Phi_34 - Phi_34_cache)**2) \n",
    "    recog_b = np.sum((b_12 - b_12_cache)**2) + np.sum((b_23 - b_23_cache)**2) + np.sum((b_34 - b_34_cache)**2)\n",
    "    gener_theta = np.sum((Theta - Theta_cache)**2) + np.sum((Theta_43 - Theta_43_cache)**2) + np.sum((Theta_32 - Theta_32_cache)**2) + np.sum((Theta_21 - Theta_21_cache)**2)\n",
    "    gener_b = np.sum((b_43 - b_43_cache)**2) + np.sum((b_32 - b_32_cache)**2) + np.sum((b_21 - b_21_cache)**2)\n",
    "    print (\"recog_phi: \" + str(recog_phi))\n",
    "    print (\"recog_b: \" + str(recog_b))\n",
    "    print (\"gener_theta: \" + str(gener_theta))\n",
    "    print (\"gener_b: \" + str(gener_b))\n",
    "    print('')\n",
    "    \n",
    "    Phi_12_cache = np.copy(Phi_12)\n",
    "    Phi_23_cache = np.copy(Phi_23)\n",
    "    Phi_34_cache = np.copy(Phi_34)\n",
    "    b_12_cache = np.copy(b_12)\n",
    "    b_23_cache = np.copy(b_23)\n",
    "    b_34_cache = np.copy(b_34)\n",
    "\n",
    "    Theta_cache = np.copy(Theta)\n",
    "    Theta_43_cache = np.copy(Theta_43)\n",
    "    Theta_32_cache = np.copy(Theta_32)\n",
    "    Theta_21_cache = np.copy(Theta_21)\n",
    "    b_43_cache = np.copy(b_43)\n",
    "    b_32_cache = np.copy(b_32)\n",
    "    b_21_cache = np.copy(b_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[-0.01202774  0.20882916  0.03495915 -0.28359468 -0.02771888 -0.75391175\n",
      "   2.32920529  0.11250042 -0.64314087  0.44402129]\n",
      " [ 0.54721525 -0.45284465 -0.76004312  0.0932755   0.37952768 -0.04585168\n",
      "   0.15940188 -0.12358255  0.04180962  0.48122609]\n",
      " [ 0.31355753 -0.87756568 -0.48297103 -0.50509069 -0.0986558   0.19644057\n",
      "   0.43750282  0.20137974 -0.38632892 -0.37611582]\n",
      " [ 0.70689589 -0.06174738 -0.0324438   0.03126557  0.0727922  -0.06323864\n",
      "   0.82121813 -3.2710376   3.01298483 -0.44685985]\n",
      " [ 0.96797435 -0.10612823 -0.32229245  0.80297007 -1.6972897   0.75145217\n",
      "   0.46673241  0.04435295 -0.21196433 -0.06525735]\n",
      " [ 1.78433205  0.15499334  0.18132394 -0.04955838 -0.41506651 -0.08526006\n",
      "  -1.28429291  1.60705319  2.75681938  2.02542017]\n",
      " [ 0.60841762 -0.01218673  0.78662157 -1.40018168  0.05136899  1.23890509\n",
      "   0.60442692 -0.08048718 -0.41267749 -0.14377839]\n",
      " [-0.17772655  3.34671319 -3.91506665 -0.16232842  0.07106487  0.31291741\n",
      "   0.10382335 -0.05329842 -0.01257356 -0.14448803]]\n",
      "Phi_12_cache: [[-0.01202774  0.20882916  0.03495915 -0.28359468 -0.02771888 -0.75391175\n",
      "   2.32920529  0.11250042 -0.64314087  0.44402129]\n",
      " [ 0.54721525 -0.45284465 -0.76004312  0.0932755   0.37952768 -0.04585168\n",
      "   0.15940188 -0.12358255  0.04180962  0.48122609]\n",
      " [ 0.31355753 -0.87756568 -0.48297103 -0.50509069 -0.0986558   0.19644057\n",
      "   0.43750282  0.20137974 -0.38632892 -0.37611582]\n",
      " [ 0.70689589 -0.06174738 -0.0324438   0.03126557  0.0727922  -0.06323864\n",
      "   0.82121813 -3.2710376   3.01298483 -0.44685985]\n",
      " [ 0.96797435 -0.10612823 -0.32229245  0.80297007 -1.6972897   0.75145217\n",
      "   0.46673241  0.04435295 -0.21196433 -0.06525735]\n",
      " [ 1.78433205  0.15499334  0.18132394 -0.04955838 -0.41506651 -0.08526006\n",
      "  -1.28429291  1.60705319  2.75681938  2.02542017]\n",
      " [ 0.60841762 -0.01218673  0.78662157 -1.40018168  0.05136899  1.23890509\n",
      "   0.60442692 -0.08048718 -0.41267749 -0.14377839]\n",
      " [-0.17772655  3.34671319 -3.91506665 -0.16232842  0.07106487  0.31291741\n",
      "   0.10382335 -0.05329842 -0.01257356 -0.14448803]]\n",
      "Phi_23: [[ 0.44982791  0.28923834 -0.35378285  0.36989171 -0.35702136  0.56739584\n",
      "  -0.34482941 -0.28912703]\n",
      " [-1.30708495  0.30728539 -0.5137074  -0.12446101 -0.11309339  1.74598327\n",
      "  -0.33936379 -0.08621785]\n",
      " [ 0.57669349  0.42034023  0.80187414 -0.17653559  0.23841908 -0.34805898\n",
      "   0.61241111  0.15873795]\n",
      " [ 0.28793838  0.27778409  0.22112475  0.57800078 -0.3848142   0.06023628\n",
      "   0.22384989 -0.12972949]\n",
      " [ 0.12198255  0.54261169 -0.2040759   0.09612387  0.44231231  0.21559244\n",
      "  -0.81037676  1.3799082 ]]\n",
      "Phi_34: [[-1.00127016  0.40039021  0.44080358  0.07755648  0.08761372]\n",
      " [ 0.5514064   1.93034147 -1.19390924 -0.06588541  0.08985323]\n",
      " [ 0.57624378  0.24930246  0.51774922  1.16765202 -0.196617  ]]\n",
      "b_12: [[ 0.13019891]\n",
      " [ 0.55678911]\n",
      " [ 0.56006965]\n",
      " [ 0.98253661]\n",
      " [ 1.20511909]\n",
      " [ 2.18504455]\n",
      " [ 0.88270361]\n",
      " [-0.23217854]]\n",
      "b_12_cache: [[ 0.13019891]\n",
      " [ 0.55678911]\n",
      " [ 0.56006965]\n",
      " [ 0.98253661]\n",
      " [ 1.20511909]\n",
      " [ 2.18504455]\n",
      " [ 0.88270361]\n",
      " [-0.23217854]]\n",
      "b_23: [[ 1.81021915]\n",
      " [ 1.2071416 ]\n",
      " [ 1.58430884]\n",
      " [ 2.59951708]\n",
      " [-1.83489041]]\n",
      "b_34: [[ 0.25036265]\n",
      " [-0.16278301]\n",
      " [ 1.25077542]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_12_cache: \" + str(Phi_12_cache))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_12_cache: \" + str(b_12_cache))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[-0.08738571]\n",
      " [ 0.21191686]\n",
      " [ 2.74698581]]\n",
      "Theta_43: [[-1.00062567  0.5265866   0.60943864]\n",
      " [ 0.34544852  1.90063876  0.20111832]\n",
      " [ 0.33237424 -1.20576156  0.44770416]\n",
      " [ 0.08889723 -0.05728154  1.30904422]\n",
      " [-0.013367    0.26513825 -0.22217228]]\n",
      "Theta_32: [[ 0.416265   -1.26595284  0.59611337  0.10657647 -0.00263907]\n",
      " [ 0.25868428  0.18253965  0.4386305   0.25576662  0.62191087]\n",
      " [-0.31802908 -0.52740439  0.8085886   0.2892555  -0.22793591]\n",
      " [ 0.43724786 -0.04957634 -0.18133379  0.60264842  0.13091283]\n",
      " [-0.38906142 -0.18466741  0.30485632 -0.32667913  0.36448714]\n",
      " [ 0.58341298  1.73798734 -0.22115302  0.08469297  0.1587761 ]\n",
      " [-0.33234289 -0.30205329  0.61377788  0.31424842 -0.78299003]\n",
      " [-0.23150467 -0.13100268  0.04495038 -0.22049847  1.39795315]]\n",
      "Theta_21: [[ 2.85199671e-01 -2.67356061e-01  1.17501087e-01  1.65057777e-01\n",
      "   9.28898263e-02  6.56973518e-01  3.05641053e-01 -7.24788496e-02]\n",
      " [ 2.60411058e-01 -4.44058363e-01 -7.49258231e-01 -8.15932597e-02\n",
      "  -1.66467605e-01  7.77330254e-02  3.74728805e-02  3.73126443e+00]\n",
      " [ 1.36385129e-02 -8.04740831e-01 -5.62714462e-01 -3.43987841e-02\n",
      "  -2.30155476e-01 -1.48891059e-02  7.84492433e-01 -4.11298222e+00]\n",
      " [-2.43559133e-01  1.25874763e-01 -5.06576184e-01  2.69690070e-03\n",
      "   7.89500618e-01 -3.40216266e-01 -1.34349521e+00 -1.42308018e-01]\n",
      " [-2.91901401e-02  4.65607758e-01 -7.59867185e-02  8.76232038e-02\n",
      "  -1.67924212e+00 -3.41770687e-01  8.81066353e-02  4.61909141e-02]\n",
      " [-9.17703104e-01 -1.36997667e-01  2.93689692e-01  6.29164750e-02\n",
      "   8.09696849e-01 -5.06465311e-02  1.33510564e+00  4.54938846e-01]\n",
      " [ 2.37764646e+00  3.97151691e-02  5.27411393e-01  1.01021579e+00\n",
      "   6.36457328e-01 -1.33074834e+00  3.97356272e-01  2.24839055e-02]\n",
      " [ 1.43520556e-02 -1.63160056e-01  2.01138701e-01 -3.29698963e+00\n",
      "  -5.36799627e-03  1.54094101e+00 -1.28590893e-01 -6.44438668e-03]\n",
      " [-5.77946445e-01 -7.81329488e-03 -2.64992339e-01  3.09142297e+00\n",
      "  -2.20501010e-01  2.98480465e+00 -3.91523577e-01 -1.39274094e-01]\n",
      " [ 3.07783713e-01  5.47603561e-01 -3.38528250e-01 -4.72657996e-01\n",
      "  -1.35796538e-01  2.25285096e+00 -1.67273629e-01 -1.86915503e-01]]\n",
      "b_43: [[ 1.53424313]\n",
      " [ 1.70317375]\n",
      " [ 1.87614962]\n",
      " [ 1.71752767]\n",
      " [-1.11503043]]\n",
      "b_32: [[ 0.41580269]\n",
      " [ 0.27737348]\n",
      " [ 0.07784441]\n",
      " [-0.00601013]\n",
      " [ 1.82796945]\n",
      " [ 1.61177985]\n",
      " [ 0.64861523]\n",
      " [ 0.82716047]]\n",
      "b_21: [[ 7.42777174]\n",
      " [ 3.4492598 ]\n",
      " [ 3.03558205]\n",
      " [ 1.04151039]\n",
      " [ 1.49378055]\n",
      " [-0.44385678]\n",
      " [ 0.97801339]\n",
      " [ 1.6758204 ]\n",
      " [-0.74231911]\n",
      " [-1.92356597]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 modes, stochastic or deterministic\n",
    "\n",
    "def generation(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2\n",
    "    # x = np.where(p_2 > 0.5,1,-1)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    d = ((p_1 > np.random.rand(n_d,batch_size)).astype(int) - 0.5)*2\n",
    "    # d = np.where(p_1 > 0.5,1,-1)\n",
    "    \n",
    "    P_4 = np.cumprod(np.where(z == 1,p_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-p_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    P_3 = np.cumprod(np.where(y == 1,p_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-p_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    P_2 = np.cumprod(np.where(x == 1,p_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-p_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    P_1 = np.cumprod(np.where(d == 1,p_1,1),axis=0)[-1] * np.cumprod(np.where(d == -1,1-p_1,1),axis=0)[-1]*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4_gen: [[0.47816747]\n",
      " [0.55278183]\n",
      " [0.93974289]]\n",
      "p_3_gen: [[0.97517811 0.93199339 0.64941517 0.97517811 0.64941517 0.84152818\n",
      "  0.84152818 0.93199339 0.93199339 0.97517811]\n",
      " [0.96951267 0.41537346 0.58639976 0.96951267 0.58639976 0.98448604\n",
      "  0.98448604 0.41537346 0.41537346 0.96951267]\n",
      " [0.68691116 0.96073032 0.97940687 0.68691116 0.97940687 0.81007021\n",
      "  0.81007021 0.96073032 0.96073032 0.68691116]\n",
      " [0.94686864 0.95234574 0.95979586 0.94686864 0.95979586 0.95513469\n",
      "  0.95513469 0.95234574 0.95234574 0.94686864]\n",
      " [0.25755845 0.1695283  0.16579765 0.25755845 0.16579765 0.25247954\n",
      "  0.25247954 0.1695283  0.1695283  0.25755845]]\n",
      "p_2_gen: [[0.28479838 0.56744731 0.56744731 0.56744731 0.56744731 0.56744731\n",
      "  0.56744731 0.94285655 0.94285655 0.28479838]\n",
      " [0.47846899 0.68806397 0.68806397 0.68806397 0.68806397 0.68806397\n",
      "  0.68806397 0.60491914 0.60491914 0.47846899]\n",
      " [0.25750323 0.63603386 0.63603386 0.63603386 0.63603386 0.63603386\n",
      "  0.63603386 0.83382744 0.83382744 0.25750323]\n",
      " [0.73783203 0.66196499 0.66196499 0.66196499 0.66196499 0.66196499\n",
      "  0.66196499 0.68378385 0.68378385 0.73783203]\n",
      " [0.56419819 0.70431493 0.70431493 0.70431493 0.70431493 0.70431493\n",
      "  0.70431493 0.77508768 0.77508768 0.56419819]\n",
      " [0.98337773 0.97436791 0.97436791 0.97436791 0.97436791 0.97436791\n",
      "  0.97436791 0.54040405 0.54040405 0.98337773]\n",
      " [0.62191388 0.84880196 0.84880196 0.84880196 0.84880196 0.84880196\n",
      "  0.84880196 0.91127815 0.91127815 0.62191388]\n",
      " [0.23169786 0.2480857  0.2480857  0.2480857  0.2480857  0.2480857\n",
      "  0.2480857  0.30009558 0.30009558 0.23169786]]\n",
      "p_1_gen: [[0.99982219 0.9998018  0.99974931 0.99968124 0.99973747 0.99991652\n",
      "  0.999783   0.99964105 0.99985752 0.99979167]\n",
      " [0.99902094 0.23422995 0.57784616 0.40852392 0.19423695 0.38706924\n",
      "  0.61861802 0.99893893 0.20623599 0.99950639]\n",
      " [0.13173884 0.99828837 0.99944391 0.99938787 0.99125779 0.99963282\n",
      "  0.999624   0.42876101 0.99816669 0.30986747]\n",
      " [0.86040631 0.41645336 0.66280121 0.76284022 0.91333355 0.35808038\n",
      "  0.28950179 0.45316542 0.41776475 0.59786575]\n",
      " [0.25878188 0.44707183 0.48487077 0.5431651  0.44683283 0.27518398\n",
      "  0.96991539 0.4520095  0.49068547 0.55158896]\n",
      " [0.27109531 0.59180514 0.44622217 0.85135807 0.10220643 0.68379362\n",
      "  0.15322763 0.85599689 0.62181655 0.69418625]\n",
      " [0.97778253 0.93041955 0.82322171 0.2320927  0.97851899 0.98937804\n",
      "  0.90769802 0.99928364 0.99018115 0.97349937]\n",
      " [0.60233435 0.99840386 0.99761529 0.35746277 0.52542051 0.54262332\n",
      "  0.36657153 0.05098647 0.46122501 0.36110342]\n",
      " [0.98933991 0.10225283 0.16213124 0.99665282 0.99178425 0.98246787\n",
      "  0.9931823  0.09778118 0.98219667 0.98609964]\n",
      " [0.29376674 0.7689954  0.86757711 0.57903675 0.64379607 0.30198236\n",
      "  0.76958705 0.00327744 0.56398016 0.63658137]]\n",
      "z_s_gen: [[-1. -1.  1. -1.  1.  1.  1. -1. -1. -1.]\n",
      " [ 1. -1. -1.  1. -1.  1.  1. -1. -1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "y_s_gen: [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1. -1. -1.  1.]\n",
      " [-1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "x_s_gen: [[ 1.  1.  1. -1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1.  1.  1.  1. -1.  1. -1.  1.  1.]\n",
      " [ 1.  1. -1. -1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.  1.  1.  1.  1.  1.]\n",
      " [ 1. -1. -1. -1. -1. -1. -1.  1. -1.  1.]]\n",
      "d_s_gen: [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1. -1. -1.  1. -1.  1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]\n",
      " [-1. -1.  1.  1.  1.  1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1. -1.  1. -1.  1. -1. -1. -1.]\n",
      " [-1. -1.  1.  1. -1. -1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1.  1. -1. -1.  1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1.  1.  1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1.  1. -1.  1. -1. -1.  1.]]\n",
      "P_gen: [0.00790122 4.68940094 1.8347944  1.53431015 2.52906238 1.72025332\n",
      " 7.62207843 6.66431881 6.06440592 0.6389928 ]\n"
     ]
    }
   ],
   "source": [
    "p_4_gen,p_3_gen,p_2_gen,p_1_gen,z_s_gen,y_s_gen,x_s_gen,d_s_gen,P_gen = generation(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,test_size)\n",
    "print (\"p_4_gen: \" + str(p_4_gen[:,0:10]))\n",
    "print (\"p_3_gen: \" + str(p_3_gen[:,0:10]))\n",
    "print (\"p_2_gen: \" + str(p_2_gen[:,0:10]))\n",
    "print (\"p_1_gen: \" + str(p_1_gen[:,0:10]))\n",
    "print (\"z_s_gen: \" + str(z_s_gen[:,0:10]))\n",
    "print (\"y_s_gen: \" + str(y_s_gen[:,0:10]))\n",
    "print (\"x_s_gen: \" + str(x_s_gen[:,0:10]))\n",
    "print (\"d_s_gen: \" + str(d_s_gen[:,0:10]))\n",
    "print (\"P_gen: \" + str(P_gen[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 1., 1., 1., 0., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = (d_s_gen+1)/2\n",
    "test_set[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " [1. 0. 1. ... 0. 1. 1.]\n",
      " [1. 1. 0. ... 1. 0. 1.]]\n",
      "[ 1  2  1  1  2  3  2  1  3  4  2  4  1  3  4  5  3  3  6  2  3  7  8  6\n",
      "  1  1  2  4  1  3  8  5  7  2  6  5  7  4  3  1  3 10  5  3  4  5  1  3\n",
      "  6  5  1  2  1  1  2  5  8  4  4  7  5  5  2  6  3  9  3  4 11  2  5  6\n",
      "  5  5  1  4  1  2  1  9  4  3  5  3  1  3  7  1  5  5  2  2  7  2  5  4\n",
      "  3  4  2  2  2  1  1  1  2  3  1  3  2  1  1  2  1  3  2  9  2  2  3  4\n",
      "  1  2  2  1  3  2  3  1  3  5  7  3  1  1  8  3  4  9  8  4  5  2  6  3\n",
      "  1  1  1  2  4  4  3  2  2  6  3  3  5  3  7  2  3  1  1  6  5  3  2  4\n",
      "  1  2  4  4  4  3  6  6  6  3  4  3  7  3  1  3  4  6  5  6 10  2  2  3\n",
      "  2  2  1  1  2  1  4  2  1  3  3  1  2  1  1  3  1  2  4  4  4  2  2  3\n",
      "  2  1  1  2  1  3  2  4  7  2  3  9  9  1  4  3  2  2  3  3  2  3  5  2\n",
      "  7  6  3  1  2  1  2  1  6  3  3  4 10  8  3  2  1  1  5  6  5  3  4  9\n",
      "  4  9  1  1  4  4  9  4  7  3  2  2  3  4  2  2  2  2  6  7  1  5  4  3\n",
      "  3  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 290)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, counts = np.unique(test_set, axis=1,return_counts=True)\n",
    "print(st)\n",
    "print(counts)\n",
    "st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_rule1 = 0\n",
    "violation_rule1_index = []\n",
    "violation_rule2 = 0\n",
    "violation_rule2_index = []\n",
    "violation_rule2_bd = 0\n",
    "violation_rule2_bd_index = []\n",
    "violation_rule3 = 0\n",
    "violation_rule3_index = []\n",
    "valid_num = 0\n",
    "valid_index = []\n",
    "\n",
    "pattern_len = test_set.shape[0]\n",
    "for i in range(test_set.shape[1]):\n",
    "    flag = 0\n",
    "    pattern = test_set[:,i]\n",
    "    if pattern[0] != 1:\n",
    "        violation_rule1 += 1\n",
    "        violation_rule1_index.append(i)\n",
    "        flag = 1\n",
    "    if np.array_equal(pattern[0:3], [1,0,0]) or np.array_equal(pattern[-3:], [0,0,1]):\n",
    "        violation_rule2_bd += 1\n",
    "        violation_rule2_bd_index.append(i)\n",
    "        flag = 1\n",
    "    for j in range(pattern_len - 5):\n",
    "        if np.array_equal(pattern[j:j+5],[0,0,1,0,0]):\n",
    "            violation_rule2 += 1\n",
    "            violation_rule2_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    for j in range(pattern_len - 4):\n",
    "        if np.array_equal(pattern[j:j+4],[0,0,0,0]):\n",
    "            violation_rule3 += 1\n",
    "            violation_rule3_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 0:\n",
    "        valid_num += 1\n",
    "        valid_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation_rule1: 0\n",
      "violation_rule1_index: []\n",
      "violation_rule2: 28\n",
      "violation_rule2_index: [50, 86, 105, 141, 156, 163, 211, 225, 248, 307, 383, 465, 470, 539, 570, 610, 636, 656, 658, 659, 681, 720, 750, 857, 875, 911, 925, 992]\n",
      "violation_rule2_bd: 2\n",
      "violation_rule2_bd_index: [465, 911]\n",
      "violation_rule3: 28\n",
      "violation_rule3_index: [21, 81, 131, 140, 283, 288, 299, 346, 374, 386, 405, 427, 438, 465, 494, 536, 661, 666, 685, 733, 766, 864, 893, 901, 911, 914, 944, 946]\n",
      "valid_num: 946\n",
      "valid_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 660, 662, 663, 664, 665, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 682, 683, 684, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 861, 862, 863, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 894, 895, 896, 897, 898, 899, 900, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 993, 994, 995, 996, 997, 998, 999]\n",
      "valid_percentage: 0.946\n"
     ]
    }
   ],
   "source": [
    "print (\"violation_rule1: \" + str(violation_rule1))\n",
    "print (\"violation_rule1_index: \" + str(violation_rule1_index))\n",
    "print (\"violation_rule2: \" + str(violation_rule2))\n",
    "print (\"violation_rule2_index: \" + str(violation_rule2_index))\n",
    "print (\"violation_rule2_bd: \" + str(violation_rule2_bd))\n",
    "print (\"violation_rule2_bd_index: \" + str(violation_rule2_bd_index))\n",
    "print (\"violation_rule3: \" + str(violation_rule3))\n",
    "print (\"violation_rule3_index: \" + str(violation_rule3_index))\n",
    "print (\"valid_num: \" + str(valid_num))\n",
    "print (\"valid_index: \" + str(valid_index))\n",
    "print (\"valid_percentage: \" + str(valid_num/test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with active sampling\n",
    "\n",
    "We fine-tune the pre-trained model with valid generations within the well-formed set, shrinking the input data by active sampling to construct a niche within the well-formed set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_set = np.transpose(well_formed_set)\n",
    "init_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1.,  1.],\n",
       "       [ 1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1.,  1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1.,  1.,  1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "itr = 5000\n",
    "gen_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    " # check if \"d_s_gen\" is in the well-formed set\n",
    "def check(d_s_gen):\n",
    "    d_s = 0\n",
    "    pattern_len = d_s_gen.shape[0]\n",
    "    for j in range(d_s_gen.shape[1]):\n",
    "        flag = 0\n",
    "        pattern = d_s_gen[:,j]\n",
    "        if pattern[0] != 1:\n",
    "            flag = 1\n",
    "            continue\n",
    "        if np.array_equal(pattern[0:3], [1,-1,-1]) or np.array_equal(pattern[-3:], [-1,-1,1]):\n",
    "            flag = 1\n",
    "            continue\n",
    "        for k in range(pattern_len - 5):\n",
    "            if np.array_equal(pattern[k:k+5],[-1,-1,1,-1,-1]):\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            continue\n",
    "        for k in range(pattern_len - 4):\n",
    "            if np.array_equal(pattern[k:k+4],[-1,-1,-1,-1]):\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "        if flag == 0:\n",
    "            d_s = d_s_gen[:,j:j+1]\n",
    "            break\n",
    "    return d_s,j,flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    d = ((p_1 > np.random.rand(n_d,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    P_4 = np.cumprod(np.where(z == 1,p_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-p_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    P_3 = np.cumprod(np.where(y == 1,p_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-p_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    P_2 = np.cumprod(np.where(x == 1,p_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-p_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    P_1 = np.cumprod(np.where(d == 1,p_1,1),axis=0)[-1] * np.cumprod(np.where(d == -1,1-p_1,1),axis=0)[-1]*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_12_cache = np.copy(Phi_12)\n",
    "Phi_23_cache = np.copy(Phi_23)\n",
    "Phi_34_cache = np.copy(Phi_34)\n",
    "b_12_cache = np.copy(b_12)\n",
    "b_23_cache = np.copy(b_23)\n",
    "b_34_cache = np.copy(b_34)\n",
    "\n",
    "Theta_cache = np.copy(Theta)\n",
    "Theta_43_cache = np.copy(Theta_43)\n",
    "Theta_32_cache = np.copy(Theta_32)\n",
    "Theta_21_cache = np.copy(Theta_21)\n",
    "b_43_cache = np.copy(b_43)\n",
    "b_32_cache = np.copy(b_32)\n",
    "b_21_cache = np.copy(b_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recog_phi: 0.0026409244652869355\n",
      "recog_b: 0.00030897607798271813\n",
      "gener_theta: 0.0024945501419105865\n",
      "gener_b: 0.00046249788011139167\n",
      "\n",
      "recog_phi: 0.1375580747723551\n",
      "recog_b: 0.010274731988056103\n",
      "gener_theta: 0.15060684433439142\n",
      "gener_b: 0.02571320653508742\n",
      "\n",
      "recog_phi: 0.09326303697728121\n",
      "recog_b: 0.008221198514492689\n",
      "gener_theta: 0.13609572737133543\n",
      "gener_b: 0.018480875854421718\n",
      "\n",
      "recog_phi: 0.14591551348677337\n",
      "recog_b: 0.01925495995361564\n",
      "gener_theta: 0.15649615184421367\n",
      "gener_b: 0.033539373305982424\n",
      "\n",
      "recog_phi: 0.1615150563311825\n",
      "recog_b: 0.013277418801566389\n",
      "gener_theta: 0.14753147176431164\n",
      "gener_b: 0.015728869097385467\n",
      "\n",
      "recog_phi: 0.12708380405404515\n",
      "recog_b: 0.0092436563134415\n",
      "gener_theta: 0.15156758529339126\n",
      "gener_b: 0.014611882275432302\n",
      "\n",
      "recog_phi: 0.13425764240705249\n",
      "recog_b: 0.0105318906583423\n",
      "gener_theta: 0.20866786367495177\n",
      "gener_b: 0.03927542553358748\n",
      "\n",
      "recog_phi: 0.1504205024340851\n",
      "recog_b: 0.014971460768885617\n",
      "gener_theta: 0.1416350898551016\n",
      "gener_b: 0.01571550527085809\n",
      "\n",
      "recog_phi: 0.12676913111752297\n",
      "recog_b: 0.01072483375808896\n",
      "gener_theta: 0.13080853366409068\n",
      "gener_b: 0.021603372529783352\n",
      "\n",
      "recog_phi: 0.14746676079944845\n",
      "recog_b: 0.022018277247447947\n",
      "gener_theta: 0.14637238940645725\n",
      "gener_b: 0.027012650478250515\n",
      "\n",
      "recog_phi: 0.12388926739597213\n",
      "recog_b: 0.014379768247428237\n",
      "gener_theta: 0.17160728286369203\n",
      "gener_b: 0.032027559418424875\n",
      "\n",
      "recog_phi: 0.11820808590597155\n",
      "recog_b: 0.010684682131234512\n",
      "gener_theta: 0.1671961387462502\n",
      "gener_b: 0.02070139827807714\n",
      "\n",
      "recog_phi: 0.15350886090910262\n",
      "recog_b: 0.01996897892274356\n",
      "gener_theta: 0.18546763230005908\n",
      "gener_b: 0.018699456279942312\n",
      "\n",
      "recog_phi: 0.12883276069173272\n",
      "recog_b: 0.013995569661667385\n",
      "gener_theta: 0.22521812597297927\n",
      "gener_b: 0.05112472582928464\n",
      "\n",
      "recog_phi: 0.1301105026715941\n",
      "recog_b: 0.013715296050608273\n",
      "gener_theta: 0.16863624549541312\n",
      "gener_b: 0.021315798593427075\n",
      "\n",
      "recog_phi: 0.13361223125144717\n",
      "recog_b: 0.010027004831128977\n",
      "gener_theta: 0.14271318720021975\n",
      "gener_b: 0.02635227130303326\n",
      "\n",
      "recog_phi: 0.11703571469335816\n",
      "recog_b: 0.013620360409333156\n",
      "gener_theta: 0.13173399393301577\n",
      "gener_b: 0.031103674057612878\n",
      "\n",
      "recog_phi: 0.11933713520563123\n",
      "recog_b: 0.009288888691459994\n",
      "gener_theta: 0.15064493001215423\n",
      "gener_b: 0.027871313652594265\n",
      "\n",
      "recog_phi: 0.10451925338159786\n",
      "recog_b: 0.018370757185666296\n",
      "gener_theta: 0.19029582683181864\n",
      "gener_b: 0.032533453175201066\n",
      "\n",
      "recog_phi: 0.12716039117051475\n",
      "recog_b: 0.016126887378030946\n",
      "gener_theta: 0.1733812833789255\n",
      "gener_b: 0.02843535595507555\n",
      "\n",
      "recog_phi: 0.09337161317969482\n",
      "recog_b: 0.008618250030300902\n",
      "gener_theta: 0.19506169569672754\n",
      "gener_b: 0.04210907684446041\n",
      "\n",
      "recog_phi: 0.13718210150672067\n",
      "recog_b: 0.01208520518391929\n",
      "gener_theta: 0.13788139335674077\n",
      "gener_b: 0.019460632518209186\n",
      "\n",
      "recog_phi: 0.10113904420753532\n",
      "recog_b: 0.015470781861313967\n",
      "gener_theta: 0.1791446629476855\n",
      "gener_b: 0.026638034912953926\n",
      "\n",
      "recog_phi: 0.13848406788588163\n",
      "recog_b: 0.016662841803772296\n",
      "gener_theta: 0.1393508575753049\n",
      "gener_b: 0.031433949748372145\n",
      "\n",
      "recog_phi: 0.11846989225337809\n",
      "recog_b: 0.015770124540440442\n",
      "gener_theta: 0.20291798436096403\n",
      "gener_b: 0.02716213109151748\n",
      "\n",
      "recog_phi: 0.14751356631708737\n",
      "recog_b: 0.018105191675071984\n",
      "gener_theta: 0.1651769546647119\n",
      "gener_b: 0.03210026047054966\n",
      "\n",
      "recog_phi: 0.12020327481650314\n",
      "recog_b: 0.007505389956979527\n",
      "gener_theta: 0.14246684442511062\n",
      "gener_b: 0.02075243047547292\n",
      "\n",
      "recog_phi: 0.1312458425057049\n",
      "recog_b: 0.010823799820150283\n",
      "gener_theta: 0.12431666917610718\n",
      "gener_b: 0.008913724841254007\n",
      "\n",
      "recog_phi: 0.100140987176582\n",
      "recog_b: 0.0040493643161918485\n",
      "gener_theta: 0.16611811203346755\n",
      "gener_b: 0.025409933979070713\n",
      "\n",
      "recog_phi: 0.15865690061495574\n",
      "recog_b: 0.017131219277543425\n",
      "gener_theta: 0.1372800922843204\n",
      "gener_b: 0.02448436791731687\n",
      "\n",
      "recog_phi: 0.12829083580961131\n",
      "recog_b: 0.011633916785682779\n",
      "gener_theta: 0.14336017775982124\n",
      "gener_b: 0.03229789072594703\n",
      "\n",
      "recog_phi: 0.11590613689661552\n",
      "recog_b: 0.010072005024904834\n",
      "gener_theta: 0.12003705254463644\n",
      "gener_b: 0.022011316071518364\n",
      "\n",
      "recog_phi: 0.10344639119500972\n",
      "recog_b: 0.013212328976246294\n",
      "gener_theta: 0.17766075123002567\n",
      "gener_b: 0.020902398498703633\n",
      "\n",
      "recog_phi: 0.11176869755560488\n",
      "recog_b: 0.010079652634891181\n",
      "gener_theta: 0.1944361399344821\n",
      "gener_b: 0.021780678048084243\n",
      "\n",
      "recog_phi: 0.15284931159303267\n",
      "recog_b: 0.011887551064905086\n",
      "gener_theta: 0.15009139275281103\n",
      "gener_b: 0.023834988178264845\n",
      "\n",
      "recog_phi: 0.1461113088885989\n",
      "recog_b: 0.016896849044367807\n",
      "gener_theta: 0.16141131566862202\n",
      "gener_b: 0.028900917729810266\n",
      "\n",
      "recog_phi: 0.1116869840991143\n",
      "recog_b: 0.012956258859213242\n",
      "gener_theta: 0.14546517847341328\n",
      "gener_b: 0.01989819622090687\n",
      "\n",
      "recog_phi: 0.1228875164587459\n",
      "recog_b: 0.012356742969444948\n",
      "gener_theta: 0.2184364196653326\n",
      "gener_b: 0.03331339652003036\n",
      "\n",
      "recog_phi: 0.12369067035608701\n",
      "recog_b: 0.007536633642037966\n",
      "gener_theta: 0.1633225378921862\n",
      "gener_b: 0.022204984680499997\n",
      "\n",
      "recog_phi: 0.18608504567533954\n",
      "recog_b: 0.02325944425346187\n",
      "gener_theta: 0.18530240215428048\n",
      "gener_b: 0.02631839189825424\n",
      "\n",
      "recog_phi: 0.10495920243974421\n",
      "recog_b: 0.00621526093413521\n",
      "gener_theta: 0.17594574706362548\n",
      "gener_b: 0.030146031953099395\n",
      "\n",
      "recog_phi: 0.11446639220391244\n",
      "recog_b: 0.009667210373171692\n",
      "gener_theta: 0.17344787381156151\n",
      "gener_b: 0.03209871807722743\n",
      "\n",
      "recog_phi: 0.1749944826386016\n",
      "recog_b: 0.02289210043697073\n",
      "gener_theta: 0.20273332563485885\n",
      "gener_b: 0.03816603034409422\n",
      "\n",
      "recog_phi: 0.1267613633794138\n",
      "recog_b: 0.016053444929206448\n",
      "gener_theta: 0.13729664621662718\n",
      "gener_b: 0.0266147304352143\n",
      "\n",
      "recog_phi: 0.111673173208645\n",
      "recog_b: 0.024121421636733684\n",
      "gener_theta: 0.16553880631530815\n",
      "gener_b: 0.023704542570912826\n",
      "\n",
      "recog_phi: 0.11148428112036105\n",
      "recog_b: 0.010416206694079298\n",
      "gener_theta: 0.16425114165452026\n",
      "gener_b: 0.03445978170163809\n",
      "\n",
      "recog_phi: 0.1579412228149046\n",
      "recog_b: 0.01470144035140595\n",
      "gener_theta: 0.18981594098860857\n",
      "gener_b: 0.03358212509471672\n",
      "\n",
      "recog_phi: 0.1802114633771172\n",
      "recog_b: 0.012477931837537343\n",
      "gener_theta: 0.17385672034147276\n",
      "gener_b: 0.029584380692274793\n",
      "\n",
      "recog_phi: 0.14929231714460456\n",
      "recog_b: 0.024999201685980577\n",
      "gener_theta: 0.17542670760531742\n",
      "gener_b: 0.028393380556492778\n",
      "\n",
      "recog_phi: 0.10504905600524918\n",
      "recog_b: 0.01435319069326765\n",
      "gener_theta: 0.16399435151247224\n",
      "gener_b: 0.018368535167447665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample-based training\n",
    "# Local delta rule\n",
    "# Sample environment for salience\n",
    "\n",
    "\n",
    "for i in range(itr):\n",
    "    sample = np.random.randint(init_set.shape[1])\n",
    "    data = init_set[:,sample:sample+1]\n",
    "    q_2,q_3,q_4,x_w,y_w,z_w,Q = wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z)\n",
    "    Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta(z_w,y_w,x_w,data,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "\n",
    "    # check if \"d_s_gen\" is in the well-formed set\n",
    "    flag = 1\n",
    "    while flag == 1:\n",
    "        p_4_gen,p_3_gen,p_2_gen,p_1_gen,z_s_gen,y_s_gen,x_s_gen,d_s_gen,P_gen = sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,gen_size)\n",
    "        d_s,j,flag = check(d_s_gen)\n",
    "\n",
    "\n",
    "    Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta(z_s_gen[:,j:j+1],y_s_gen[:,j:j+1],x_s_gen[:,j:j+1],d_s,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "    init_set = np.append(init_set,d_s,axis=1)\n",
    "\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        \n",
    "        recog_phi = np.sum((Phi_12 - Phi_12_cache)**2) + np.sum((Phi_23 - Phi_23_cache)**2) + np.sum((Phi_34 - Phi_34_cache)**2) \n",
    "        recog_b = np.sum((b_12 - b_12_cache)**2) + np.sum((b_23 - b_23_cache)**2) + np.sum((b_34 - b_34_cache)**2)\n",
    "        gener_theta = np.sum((Theta - Theta_cache)**2) + np.sum((Theta_43 - Theta_43_cache)**2) + np.sum((Theta_32 - Theta_32_cache)**2) + np.sum((Theta_21 - Theta_21_cache)**2)\n",
    "        gener_b = np.sum((b_43 - b_43_cache)**2) + np.sum((b_32 - b_32_cache)**2) + np.sum((b_21 - b_21_cache)**2)\n",
    "\n",
    "        print (\"recog_phi: \" + str(recog_phi))\n",
    "        print (\"recog_b: \" + str(recog_b))\n",
    "        print (\"gener_theta: \" + str(gener_theta))\n",
    "        print (\"gener_b: \" + str(gener_b))\n",
    "        print('')\n",
    "\n",
    "        Phi_12_cache = np.copy(Phi_12)\n",
    "        Phi_23_cache = np.copy(Phi_23)\n",
    "        Phi_34_cache = np.copy(Phi_34)\n",
    "        b_12_cache = np.copy(b_12)\n",
    "        b_23_cache = np.copy(b_23)\n",
    "        b_34_cache = np.copy(b_34)\n",
    "\n",
    "        Theta_cache = np.copy(Theta)\n",
    "        Theta_43_cache = np.copy(Theta_43)\n",
    "        Theta_32_cache = np.copy(Theta_32)\n",
    "        Theta_21_cache = np.copy(Theta_21)\n",
    "        b_43_cache = np.copy(b_43)\n",
    "        b_32_cache = np.copy(b_32)\n",
    "        b_21_cache = np.copy(b_21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 25256)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 272)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(init_set,axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63,  31,  74,  64,  58,  32,  85,  59,  51,  28,  44, 202,  85,\n",
       "       188, 144, 139,  67,  49,  22,  37,  78,  78,  65,  84, 204, 140,\n",
       "       130, 123, 171, 117,   2,  83,  44,  88, 115, 141,  78, 124, 222,\n",
       "       106, 122, 102, 179,  99,  35,  45,  48,  26, 151,  92,  93, 107,\n",
       "       119,  78,   3, 131,  56, 171, 174, 196, 101,  84, 326, 164, 163,\n",
       "       153, 251, 119,  89,  61,  54,  90, 142, 113,  84, 226, 155,  90,\n",
       "        99, 137, 126,  10, 183,  93, 144, 167, 260, 122, 159, 356, 148,\n",
       "       128,  80, 230, 127,  38,  51,  30,   9,  30, 120,  61, 118,  96,\n",
       "        70,  40,  35,  71,  90,  36,  65,  46,  57,  75,  35,  75,  81,\n",
       "        86,  56,  93, 211, 115, 138, 102, 117,  88,  18,  42,  23,  18,\n",
       "        74,  69,  33,  72,  52,  42,   1,  63,  37,  70, 110,  84,  56,\n",
       "        34, 134,  70,  58,  89, 103,  64,  57,  54,  42,  83,  88,  87,\n",
       "        58, 142, 118,  46,  91,  75, 103,   2, 123,  86,  87, 109, 162,\n",
       "       114,  82, 215, 116,  60,  79, 154,  87,  60,  25,  46,  72,  40,\n",
       "        20,  74,  43,  43,  31,  28, 114,  50, 124, 103, 104,  45,  53,\n",
       "        31,  43,  94,  73,  61,  44, 171, 115,  91, 122, 103, 130,   3,\n",
       "        89,  44,  68,  77, 116, 107,  73, 192, 103, 121,  87, 149,  85,\n",
       "        54,  62,  38,  28, 115,  68,  82, 106,  72,  61,   2,  82,  32,\n",
       "       112, 108, 131,  76,  39, 169,  77,  93, 103, 118,  72, 106,  54,\n",
       "        70, 132, 143, 111,  38, 147, 132,  88,  86,  97, 112,   5, 130,\n",
       "        77,  97, 115, 207, 112,  76, 187, 104,  90,  70, 146, 110],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, counts = np.unique(init_set, axis = 1, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 0.05152103  0.04358023  0.31341605 -0.31721318 -0.07051976 -1.15235284\n",
      "   2.00952782 -0.2662573  -0.55111395  0.55151597]\n",
      " [ 0.58025191 -0.60603746 -0.64173172  0.10326585  0.40367584  0.38377239\n",
      "   0.13698299 -0.02474849  0.01427544  0.48149015]\n",
      " [ 0.2185583  -0.74352225 -0.36503998 -0.62573319 -0.23356003  0.38779953\n",
      "   0.65364894 -0.2953449  -0.45272673 -0.45890233]\n",
      " [ 0.53377977 -0.04957013 -0.18397656  0.31656988  0.34731896  0.29672346\n",
      "   0.71513563 -3.55011859  3.02041165 -0.65338094]\n",
      " [ 0.81525751 -0.07490597 -0.32810107  1.10132932 -1.80901259  0.98467912\n",
      "   0.91347524 -0.08291422 -0.42305116 -0.11568631]\n",
      " [ 1.97975956 -0.03293606  0.04911707  0.05431874 -0.41697522 -0.15786845\n",
      "  -1.22045793  1.82529     2.68279344  2.07034337]\n",
      " [ 0.80673712 -0.25066004  1.08832454 -1.46871071 -0.18180382  1.23013941\n",
      "   0.38041021  0.25648345 -0.21664166  0.07199557]\n",
      " [-0.07758344  3.60092447 -3.8726047  -0.56927758  0.0737039   0.53333696\n",
      "   0.20710484 -0.16459643 -0.11053214  0.07368902]]\n",
      "Phi_12_cache: [[ 0.01004959  0.05441991  0.28753605 -0.32001315 -0.07481862 -1.15234457\n",
      "   1.98829115 -0.31130347 -0.5594484   0.56399547]\n",
      " [ 0.6380263  -0.51909151 -0.6476294   0.10787623  0.41473652  0.45320308\n",
      "   0.11926459 -0.07806394  0.04092963  0.43921009]\n",
      " [ 0.20961775 -0.73877376 -0.38368735 -0.61071608 -0.18850863  0.38647233\n",
      "   0.59788142 -0.3313071  -0.45830784 -0.42979021]\n",
      " [ 0.52758478 -0.07746285 -0.18120044  0.32672688  0.35644799  0.28051778\n",
      "   0.67846931 -3.55129456  3.03372566 -0.61520658]\n",
      " [ 0.79788552 -0.00525901 -0.40730777  1.12181932 -1.82459013  0.9849053\n",
      "   0.88298838 -0.10259172 -0.40777376 -0.12319484]\n",
      " [ 2.00980789 -0.02704764  0.06206429  0.08623645 -0.43839062 -0.15101477\n",
      "  -1.18206506  1.81397226  2.69064717  2.0366276 ]\n",
      " [ 0.80305642 -0.25115807  1.06977454 -1.45624059 -0.16990922  1.2295258\n",
      "   0.36537605  0.22971504 -0.16795675  0.10661746]\n",
      " [-0.08038708  3.59753372 -3.87469982 -0.56831484  0.09844355  0.55104887\n",
      "   0.26901804 -0.17667146 -0.10068548  0.09198382]]\n",
      "Phi_23: [[ 1.07893792  0.27193178 -0.62023594 -0.20688459 -0.34498116  0.98258518\n",
      "  -0.40939134 -0.05397608]\n",
      " [-1.69794919  0.21027476 -0.82855937 -0.13100557 -0.25353404  1.51358022\n",
      "  -0.29656114  0.11618622]\n",
      " [ 0.27294069  0.46362406  1.37086719 -0.03819356  0.42794665 -0.1045459\n",
      "   0.71528937 -0.15359432]\n",
      " [-0.05918154  0.24047523  0.13223546  0.70321066 -0.46922197  0.13996717\n",
      "   0.19462034  0.06299111]\n",
      " [ 0.10245146  0.69013176  0.02179804  0.0867086   0.39410952  0.15034713\n",
      "  -1.23469548  1.68149392]]\n",
      "Phi_34: [[-1.34953245  0.32074394  0.44877537 -0.11058337 -0.01295632]\n",
      " [ 0.0291777   1.98548957 -1.47785353 -0.15803549  0.49561037]\n",
      " [ 0.34123372  0.44019651  0.3950237   0.87761879 -0.24350236]]\n",
      "b_12: [[ 0.19374768]\n",
      " [ 0.58982577]\n",
      " [ 0.46507042]\n",
      " [ 0.80942049]\n",
      " [ 1.05240225]\n",
      " [ 2.38047207]\n",
      " [ 1.08102311]\n",
      " [-0.13203543]]\n",
      "b_12_cache: [[ 0.15227623]\n",
      " [ 0.64760017]\n",
      " [ 0.45612988]\n",
      " [ 0.8032255 ]\n",
      " [ 1.03503025]\n",
      " [ 2.4105204 ]\n",
      " [ 1.07734241]\n",
      " [-0.13483907]]\n",
      "b_23: [[ 1.81201217]\n",
      " [ 1.03474925]\n",
      " [ 1.61842573]\n",
      " [ 2.32061001]\n",
      " [-1.93736734]]\n",
      "b_34: [[-0.59113914]\n",
      " [-0.52485878]\n",
      " [ 1.01596245]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_12_cache: \" + str(Phi_12_cache))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_12_cache: \" + str(b_12_cache))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[-0.83110108]\n",
      " [-0.69795167]\n",
      " [ 2.32307054]]\n",
      "Theta_43: [[-1.29007535  0.07934883  0.2488043 ]\n",
      " [ 0.25241686  1.77777638  0.63194415]\n",
      " [ 0.53023933 -1.3267934   0.49224568]\n",
      " [ 0.01865656 -0.12591043  0.80150507]\n",
      " [-0.09526168  0.45808328 -0.17116537]]\n",
      "Theta_32: [[ 1.13356831 -1.62631764  0.28822039  0.03300677  0.0068035 ]\n",
      " [ 0.26957405  0.07493311  0.35938688  0.37931666  0.48631921]\n",
      " [-0.528356   -0.90369408  1.37835993  0.18382254  0.08976363]\n",
      " [ 0.06530103 -0.11038262 -0.03139099  0.73652013  0.20631652]\n",
      " [-0.32124997 -0.24610753  0.32412146 -0.51025285  0.3121798 ]\n",
      " [ 0.89889843  1.5869979  -0.16861106  0.28192362 -0.01158995]\n",
      " [-0.31898271 -0.15831462  0.76779511  0.31862023 -1.12542392]\n",
      " [-0.26625809  0.05390584 -0.1787028   0.0113964   1.64551811]]\n",
      "Theta_21: [[ 0.2762122  -0.23860004  0.12553823  0.17348486  0.12498344  0.69189239\n",
      "   0.33419303 -0.07930188]\n",
      " [ 0.07061874 -0.57230471 -0.75782397 -0.06929255 -0.029113    0.10313956\n",
      "  -0.12281092  3.91804817]\n",
      " [ 0.26622083 -0.80453856 -0.42229634  0.12826773 -0.25194204  0.08640803\n",
      "   1.18374493 -4.15935795]\n",
      " [-0.41976453  0.13034566 -0.76679227  0.13133382  1.16138481  0.08232222\n",
      "  -1.47536957 -0.62436339]\n",
      " [-0.10913624  0.43733068 -0.24087084  0.27231515 -1.9309776  -0.53149547\n",
      "  -0.08683662  0.10555197]\n",
      " [-1.15786241  0.41519812  0.3964055   0.17227256  1.0929355  -0.17398292\n",
      "   1.30511829  0.62146641]\n",
      " [ 2.04394908  0.03444195  0.79566009  0.84403013  0.64467543 -1.14566293\n",
      "   0.27290102  0.24016125]\n",
      " [-0.26322825 -0.11205415 -0.10783677 -3.57945261  0.03006181  1.57150224\n",
      "   0.11973242 -0.08072034]\n",
      " [-0.36527903  0.03997604 -0.35076834  3.27356799 -0.36816379  2.94729893\n",
      "  -0.01790794  0.07258555]\n",
      " [ 0.55230868  0.46884736 -0.44148154 -0.51561234 -0.1658348   2.067857\n",
      "   0.04731772  0.20356159]]\n",
      "b_43: [[ 1.57591624]\n",
      " [ 1.93636158]\n",
      " [ 1.74997866]\n",
      " [ 1.82385969]\n",
      " [-1.4135568 ]]\n",
      "b_32: [[ 0.14466272]\n",
      " [ 0.53603156]\n",
      " [-0.05568823]\n",
      " [ 0.0598256 ]\n",
      " [ 1.63429223]\n",
      " [ 1.58129738]\n",
      " [ 0.71685956]\n",
      " [ 0.75141098]]\n",
      "b_21: [[ 7.50443561]\n",
      " [ 3.36552897]\n",
      " [ 3.2178627 ]\n",
      " [ 0.97956531]\n",
      " [ 2.19592246]\n",
      " [-0.34847172]\n",
      " [ 1.32318209]\n",
      " [ 1.49481568]\n",
      " [-0.83539818]\n",
      " [-2.15007155]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 modes, stochastic or deterministic\n",
    "\n",
    "def generation(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2\n",
    "    # x = np.where(p_2 > 0.5,1,-1)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    #d = ((p_1 > np.random.rand(n_d,batch_size)).astype(int) - 0.5)*2\n",
    "    d = np.where(p_1 > 0.5,1,-1)\n",
    "    \n",
    "    P_4 = np.cumprod(np.where(z == 1,p_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-p_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    P_3 = np.cumprod(np.where(y == 1,p_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-p_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    P_2 = np.cumprod(np.where(x == 1,p_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-p_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    P_1 = np.cumprod(np.where(d == 1,p_1,1),axis=0)[-1] * np.cumprod(np.where(d == -1,1-p_1,1),axis=0)[-1]*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4_gen: [[0.3034123 ]\n",
      " [0.33226652]\n",
      " [0.91076979]]\n",
      "p_3_gen: [[0.61189775 0.61189775 0.61189775 0.64885135 0.95415006 0.95415006\n",
      "  0.96061334 0.95415006 0.64885135 0.96061334]\n",
      " [0.73941808 0.73941808 0.73941808 0.9900334  0.63137322 0.63137322\n",
      "  0.9835956  0.63137322 0.9900334  0.9835956 ]\n",
      " [0.98368558 0.98368558 0.98368558 0.80933119 0.95429558 0.95429558\n",
      "  0.59512464 0.95429558 0.80933119 0.59512464]\n",
      " [0.9410292  0.9410292  0.9410292  0.92540175 0.93892418 0.93892418\n",
      "  0.92278466 0.93892418 0.92540175 0.92278466]\n",
      " [0.10545158 0.10545158 0.10545158 0.22760216 0.12482143 0.12482143\n",
      "  0.26281719 0.12482143 0.22760216 0.26281719]]\n",
      "p_2_gen: [[0.7214842  0.49498618 0.49158506 0.49158506 0.96154203 0.49158506\n",
      "  0.49158506 0.96154203 0.49158506 0.33712844]\n",
      " [0.60919001 0.89144255 0.75637793 0.75637793 0.72771434 0.75637793\n",
      "  0.75637793 0.72771434 0.75637793 0.41472067]\n",
      " [0.94525562 0.54095995 0.49617021 0.49617021 0.85718072 0.49617021\n",
      "  0.49617021 0.85718072 0.49617021 0.04149967]\n",
      " [0.64650688 0.71630162 0.62563986 0.62563986 0.67575296 0.62563986\n",
      "  0.62563986 0.67575296 0.62563986 0.28972878]\n",
      " [0.84597026 0.76727417 0.6384455  0.6384455  0.74285077 0.6384455\n",
      "  0.6384455  0.74285077 0.6384455  0.71927865]\n",
      " [0.31438531 0.98476663 0.98511048 0.98511048 0.73460242 0.98511048\n",
      "  0.98511048 0.73460242 0.98511048 0.98139366]\n",
      " [0.96789141 0.54997103 0.92066388 0.92066388 0.94092362 0.92066388\n",
      "  0.92066388 0.94092362 0.92066388 0.5691958 ]\n",
      " [0.29962981 0.88259847 0.21861329 0.21861329 0.20075577 0.21861329\n",
      "  0.21861329 0.20075577 0.21861329 0.28107147]]\n",
      "p_1_gen: [[0.99954176 0.99954376 0.99963708 0.99959248 0.99954176 0.99990836\n",
      "  0.99975519 0.99985249 0.99969937 0.99971083]\n",
      " [0.10561035 0.99755283 0.39720839 0.49243778 0.10561035 0.67483848\n",
      "  0.99947951 0.13332433 0.99931156 0.68691265]\n",
      " [0.99938315 0.02519573 0.99950906 0.99693199 0.99938315 0.99995536\n",
      "  0.4582044  0.99968637 0.39091215 0.99994063]\n",
      " [0.57021892 0.95207152 0.9280981  0.99070596 0.57021892 0.84816516\n",
      "  0.6152841  0.13292035 0.8280366  0.49359382]\n",
      " [0.72386009 0.62334    0.51401718 0.50287101 0.72386009 0.3793707\n",
      "  0.51222628 0.97730501 0.6924967  0.95449574]\n",
      " [0.80660703 0.88376401 0.90538251 0.06492183 0.80660703 0.36747586\n",
      "  0.76597529 0.24866883 0.97908175 0.31913452]\n",
      " [0.99895672 0.6033966  0.05763498 0.67870636 0.99895672 0.94847613\n",
      "  0.85494916 0.96386414 0.34844527 0.01548164]\n",
      " [0.01967098 0.34520397 0.99920414 0.9982897  0.01967098 0.41922456\n",
      "  0.99841787 0.30452055 0.45386908 0.99932443]\n",
      " [0.16194082 0.99430404 0.29644151 0.17378397 0.16194082 0.99240261\n",
      "  0.19004958 0.99322062 0.9970647  0.44820507]\n",
      " [0.01125143 0.24372571 0.61522737 0.81447004 0.01125143 0.4025232\n",
      "  0.87879623 0.49785964 0.4613865  0.46588166]]\n",
      "z_s_gen: [[ 1.  1.  1.  1. -1. -1. -1. -1.  1. -1.]\n",
      " [-1. -1. -1.  1. -1. -1.  1. -1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "y_s_gen: [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.  1.  1. -1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]\n",
      " [-1.  1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "x_s_gen: [[ 1. -1. -1.  1.  1.  1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1. -1.  1.  1.  1. -1.]\n",
      " [ 1.  1. -1. -1.  1. -1. -1.  1. -1. -1.]\n",
      " [ 1.  1. -1. -1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1. -1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.  1.  1.  1.  1.]\n",
      " [ 1. -1.  1. -1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1. -1. -1. -1. -1.  1. -1.  1. -1.]]\n",
      "d_s_gen: [[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1  1 -1 -1 -1  1  1 -1  1  1]\n",
      " [ 1 -1  1  1  1  1 -1  1 -1  1]\n",
      " [ 1  1  1  1  1  1  1 -1  1 -1]\n",
      " [ 1  1  1  1  1 -1  1  1  1  1]\n",
      " [ 1  1  1 -1  1 -1  1 -1  1 -1]\n",
      " [ 1  1 -1  1  1  1  1  1 -1 -1]\n",
      " [-1 -1  1  1 -1 -1  1 -1 -1  1]\n",
      " [-1  1 -1 -1 -1  1 -1  1  1 -1]\n",
      " [-1 -1  1  1 -1 -1  1 -1 -1 -1]]\n",
      "P_gen: [14.91969601  2.44758494  9.11098885  0.37965129 64.19378974  9.50050618\n",
      "  2.15300207 46.9875497   1.29458448  0.33924556]\n"
     ]
    }
   ],
   "source": [
    "p_4_gen,p_3_gen,p_2_gen,p_1_gen,z_s_gen,y_s_gen,x_s_gen,d_s_gen,P_gen = generation(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,test_size)\n",
    "print (\"p_4_gen: \" + str(p_4_gen[:,0:10]))\n",
    "print (\"p_3_gen: \" + str(p_3_gen[:,0:10]))\n",
    "print (\"p_2_gen: \" + str(p_2_gen[:,0:10]))\n",
    "print (\"p_1_gen: \" + str(p_1_gen[:,0:10]))\n",
    "print (\"z_s_gen: \" + str(z_s_gen[:,0:10]))\n",
    "print (\"y_s_gen: \" + str(y_s_gen[:,0:10]))\n",
    "print (\"x_s_gen: \" + str(x_s_gen[:,0:10]))\n",
    "print (\"d_s_gen: \" + str(d_s_gen[:,0:10]))\n",
    "print (\"P_gen: \" + str(P_gen[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 0., 1., 0., 1., 0.],\n",
       "       [1., 1., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = (d_s_gen+1)/2\n",
    "test_set[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "[ 66  19  26 147  88  15 140 100  65   7   5   3   5   1  98 198 401   4\n",
      " 159  62   9  28  12  36  30   6  24 290   7 184 157 182 175  51  70   1\n",
      "  47   2   2  10  31  38  16  24  56 142  23  23   1  20  30   6  21  28\n",
      "   2  22   7   5  43  57   6  27 154   4  77  17 152   4  31  27  64   5\n",
      "  19  38  23   9  51  45   4  42  29  39   8  18  22   1  14  11  73  58\n",
      "  69 103  22  11  17   5  20  48   7   4   3   3   7  80   2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 105)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, counts = np.unique(test_set, axis=1,return_counts=True)\n",
    "print(st)\n",
    "print(counts)\n",
    "st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_rule1 = 0\n",
    "violation_rule1_index = []\n",
    "violation_rule2 = 0\n",
    "violation_rule2_index = []\n",
    "violation_rule2_bd = 0\n",
    "violation_rule2_bd_index = []\n",
    "violation_rule3 = 0\n",
    "violation_rule3_index = []\n",
    "valid_num = 0\n",
    "valid_index = []\n",
    "\n",
    "pattern_len = test_set.shape[0]\n",
    "for i in range(test_set.shape[1]):\n",
    "    flag = 0\n",
    "    pattern = test_set[:,i]\n",
    "    if pattern[0] != 1:\n",
    "        violation_rule1 += 1\n",
    "        violation_rule1_index.append(i)\n",
    "        flag = 1\n",
    "    if np.array_equal(pattern[0:3], [1,0,0]) or np.array_equal(pattern[-3:], [0,0,1]):\n",
    "        violation_rule2_bd += 1\n",
    "        violation_rule2_bd_index.append(i)\n",
    "        flag = 1\n",
    "    for j in range(pattern_len - 5):\n",
    "        if np.array_equal(pattern[j:j+5],[0,0,1,0,0]):\n",
    "            violation_rule2 += 1\n",
    "            violation_rule2_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    for j in range(pattern_len - 4):\n",
    "        if np.array_equal(pattern[j:j+4],[0,0,0,0]):\n",
    "            violation_rule3 += 1\n",
    "            violation_rule3_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 0:\n",
    "        valid_num += 1\n",
    "        valid_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation_rule1: 0\n",
      "violation_rule1_index: []\n",
      "violation_rule2: 0\n",
      "violation_rule2_index: []\n",
      "violation_rule2_bd: 0\n",
      "violation_rule2_bd_index: []\n",
      "violation_rule3: 19\n",
      "violation_rule3_index: [72, 214, 391, 746, 1105, 1273, 1569, 1722, 1755, 1757, 2282, 2444, 2528, 2940, 3638, 3933, 4011, 4064, 4339]\n",
      "valid_num: 4981\n",
      "valid_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1756, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4807, 4808, 4809, 4810, 4811, 4812, 4813, 4814, 4815, 4816, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4825, 4826, 4827, 4828, 4829, 4830, 4831, 4832, 4833, 4834, 4835, 4836, 4837, 4838, 4839, 4840, 4841, 4842, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4857, 4858, 4859, 4860, 4861, 4862, 4863, 4864, 4865, 4866, 4867, 4868, 4869, 4870, 4871, 4872, 4873, 4874, 4875, 4876, 4877, 4878, 4879, 4880, 4881, 4882, 4883, 4884, 4885, 4886, 4887, 4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4896, 4897, 4898, 4899, 4900, 4901, 4902, 4903, 4904, 4905, 4906, 4907, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4920, 4921, 4922, 4923, 4924, 4925, 4926, 4927, 4928, 4929, 4930, 4931, 4932, 4933, 4934, 4935, 4936, 4937, 4938, 4939, 4940, 4941, 4942, 4943, 4944, 4945, 4946, 4947, 4948, 4949, 4950, 4951, 4952, 4953, 4954, 4955, 4956, 4957, 4958, 4959, 4960, 4961, 4962, 4963, 4964, 4965, 4966, 4967, 4968, 4969, 4970, 4971, 4972, 4973, 4974, 4975, 4976, 4977, 4978, 4979, 4980, 4981, 4982, 4983, 4984, 4985, 4986, 4987, 4988, 4989, 4990, 4991, 4992, 4993, 4994, 4995, 4996, 4997, 4998, 4999]\n",
      "valid_percentage: 0.9962\n"
     ]
    }
   ],
   "source": [
    "print (\"violation_rule1: \" + str(violation_rule1))\n",
    "print (\"violation_rule1_index: \" + str(violation_rule1_index))\n",
    "print (\"violation_rule2: \" + str(violation_rule2))\n",
    "print (\"violation_rule2_index: \" + str(violation_rule2_index))\n",
    "print (\"violation_rule2_bd: \" + str(violation_rule2_bd))\n",
    "print (\"violation_rule2_bd_index: \" + str(violation_rule2_bd_index))\n",
    "print (\"violation_rule3: \" + str(violation_rule3))\n",
    "print (\"violation_rule3_index: \" + str(violation_rule3_index))\n",
    "print (\"valid_num: \" + str(valid_num))\n",
    "print (\"valid_index: \" + str(valid_index))\n",
    "print (\"valid_percentage: \" + str(valid_num/test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.style.use('_mpl-gallery')\n",
    "\n",
    "# make data:\n",
    "np.random.seed(3)\n",
    "x = np.arange(256)\n",
    "y = np.random.uniform(2, 7, len(x))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "ax.bar(x, y)\n",
    "\n",
    "ax.set(xlim=(0, 256))\n",
    "      \n",
    "\n",
    "#ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "#ax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n",
    "#       ylim=(0, 8), yticks=np.arange(1, 8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66,  19,  26, 147,  88,  15, 140, 100,  65,   7,   5,   3,   5,\n",
       "         1,  98, 198, 401,   4, 159,  62,   9,  28,  12,  36,  30,   6,\n",
       "        24, 290,   7, 184, 157, 182, 175,  51,  70,   1,  47,   2,   2,\n",
       "        10,  31,  38,  16,  24,  56, 142,  23,  23,   1,  20,  30,   6,\n",
       "        21,  28,   2,  22,   7,   5,  43,  57,   6,  27, 154,   4,  77,\n",
       "        17, 152,   4,  31,  27,  64,   5,  19,  38,  23,   9,  51,  45,\n",
       "         4,  42,  29,  39,   8,  18,  22,   1,  14,  11,  73,  58,  69,\n",
       "       103,  22,  11,  17,   5,  20,  48,   7,   4,   3,   3,   7,  80,\n",
       "         2], dtype=int64)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.append(counts,np.zeros(256 - counts.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,\n",
       "         1.,   2.,   2.,   2.,   2.,   3.,   3.,   3.,   4.,   4.,   4.,\n",
       "         4.,   4.,   5.,   5.,   5.,   5.,   5.,   6.,   6.,   6.,   7.,\n",
       "         7.,   7.,   7.,   7.,   8.,   9.,   9.,  10.,  11.,  11.,  12.,\n",
       "        14.,  15.,  16.,  17.,  17.,  18.,  19.,  19.,  20.,  20.,  21.,\n",
       "        22.,  22.,  22.,  23.,  23.,  23.,  24.,  24.,  26.,  27.,  27.,\n",
       "        28.,  28.,  29.,  30.,  30.,  31.,  31.,  36.,  38.,  38.,  39.,\n",
       "        42.,  43.,  45.,  47.,  48.,  51.,  51.,  56.,  57.,  58.,  62.,\n",
       "        64.,  65.,  66.,  69.,  70.,  73.,  77.,  80.,  88.,  98., 100.,\n",
       "       103., 140., 142., 147., 152., 154., 157., 159., 175., 182., 184.,\n",
       "       198., 290., 401.])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "         1.,   2.,   2.,   3.,   4.,   4.,   4.,   5.,   5.,   6.,   6.,\n",
       "         7.,   7.,   8.,   9.,  11.,  12.,  15.,  17.,  18.,  19.,  20.,\n",
       "        22.,  22.,  23.,  24.,  26.,  27.,  28.,  30.,  31.,  36.,  38.,\n",
       "        42.,  45.,  48.,  51.,  57.,  62.,  65.,  69.,  73.,  80.,  98.,\n",
       "       103., 142., 152., 157., 175., 184., 290.])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(arr)[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([401., 198., 182., 159., 154., 147., 140., 100.,  88.,  77.,  70.,\n",
       "        66.,  64.,  58.,  56.,  51.,  47.,  43.,  39.,  38.,  31.,  30.,\n",
       "        29.,  28.,  27.,  24.,  23.,  23.,  22.,  21.,  20.,  19.,  17.,\n",
       "        16.,  14.,  11.,  10.,   9.,   7.,   7.,   7.,   6.,   5.,   5.,\n",
       "         5.,   4.,   4.,   3.,   3.,   2.,   2.,   1.,   1.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(arr)[1::2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "         1.,   2.,   2.,   3.,   4.,   4.,   4.,   5.,   5.,   6.,   6.,\n",
       "         7.,   7.,   8.,   9.,  11.,  12.,  15.,  17.,  18.,  19.,  20.,\n",
       "        22.,  22.,  23.,  24.,  26.,  27.,  28.,  30.,  31.,  36.,  38.,\n",
       "        42.,  45.,  48.,  51.,  57.,  62.,  65.,  69.,  73.,  80.,  98.,\n",
       "       103., 142., 152., 157., 175., 184., 290., 401., 198., 182., 159.,\n",
       "       154., 147., 140., 100.,  88.,  77.,  70.,  66.,  64.,  58.,  56.,\n",
       "        51.,  47.,  43.,  39.,  38.,  31.,  30.,  29.,  28.,  27.,  24.,\n",
       "        23.,  23.,  22.,  21.,  20.,  19.,  17.,  16.,  14.,  11.,  10.,\n",
       "         9.,   7.,   7.,   7.,   6.,   5.,   5.,   5.,   4.,   4.,   3.,\n",
       "         3.,   2.,   2.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_plt = np.append(np.sort(arr)[::2], np.sort(arr)[1::2][::-1])\n",
    "new_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x234d669cf88>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.style.use('_mpl-gallery')\n",
    "\n",
    "# make data:\n",
    "\n",
    "x = np.arange(256)\n",
    "y = new_plt/5000\n",
    "z = np.ones(256)/256\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(18, 9))\n",
    "ax.bar(x, z, label = \"Initial Uniform Distribution\", alpha = 0.8)\n",
    "ax.bar(x, y, label = \"Active Sampled Distribution\")\n",
    "\n",
    "\n",
    "ax.set(xlim=(0, 256))\n",
    "      \n",
    "\n",
    "#ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "#ax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n",
    "#       ylim=(0, 8), yticks=np.arange(1, 8))\n",
    "\n",
    "#plt.show()\n",
    "#plt.legend()\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
