{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*Project:* Helmholtz Machine on Niche Construction\n",
    "\n",
    "*Author:* Jingwei Liu, Computer Music Ph.D., UC San Diego\n",
    "\n",
    "*Supervisor:* Shlomo Dubnov, Professor in Music and CSE department, UC San Diego\n",
    "***\n",
    "\n",
    "# <span style=\"background-color:darkorange; color:white; padding:2px 6px\">Document 4</span> \n",
    "\n",
    "# Helmholtz Machine Implementation\n",
    "\n",
    "*Updated:* May 24, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "preferred_set = np.zeros([1,10])\n",
    "preferred_set[0,:2] = 1\n",
    "preferred_set[0,-2:] = 1\n",
    "\n",
    "for i in range(2, n-2):\n",
    "    for j in range(np.shape(preferred_set)[0]):\n",
    "        \n",
    "        prefix = preferred_set[j,i-2:i]\n",
    "        if np.array_equal(prefix, [0,0]) or np.array_equal(prefix, [0,1]):\n",
    "            preferred_set[j,i] = 1\n",
    "        else:\n",
    "            preferred_set = np.append(preferred_set, preferred_set[j:j+1,:], axis=0)\n",
    "            preferred_set[j,i] = 1\n",
    "preferred_set = (preferred_set - 0.5)*2\n",
    "preferred_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(preferred_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 25 elements in the preferred set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1., -1.,  1., ..., -1., -1., -1.],\n",
       "       [ 1.,  1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_formed_set = np.zeros([1,10])\n",
    "well_formed_set[0,0] = 1\n",
    "\n",
    "for i in range(1,n):\n",
    "    for j in range(np.shape(well_formed_set)[0]):\n",
    "        if i == 2 and np.array_equal(well_formed_set[j,i-2:i], [1,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        elif i > 3 and np.array_equal(well_formed_set[j,i-3:i], [0,0,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        elif i > 3 and np.array_equal(well_formed_set[j,i-4:i], [0,0,1,0]):\n",
    "            well_formed_set[j,i] = 1\n",
    "        else:\n",
    "            well_formed_set = np.append(well_formed_set, well_formed_set[j:j+1,:], axis=0)\n",
    "            well_formed_set[j,i] = 1\n",
    "            \n",
    "ind = np.array([], dtype=np.int8)\n",
    "for i in range(well_formed_set.shape[0]):\n",
    "    if np.array_equal(well_formed_set[i,-3:], [0,0,1]):\n",
    "        ind = np.append(ind,i)\n",
    "\n",
    "well_formed_set = np.delete(well_formed_set,ind,0)\n",
    "well_formed_set = (well_formed_set - 0.5)*2\n",
    "well_formed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_formed_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 256 elements in the preferred set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $2^{10} = 1024$ possible sequences in total, thus the Venn diagram for the ground truth is \n",
    "\n",
    "<img src=\"Venn_1.jpg\" style=\"width:550px;height:500px;\">\n",
    "<caption><center> **Figure 2**: Venn Diagram for Ground Truth Data  </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Functions\n",
    "\n",
    "The Helmholtz machine is designed as follows\n",
    "\n",
    "<img src=\"niche.jpg\">\n",
    "<caption><center> **Figure 1**: Helmholtz Machine in Niche Construction  </center></caption>\n",
    "\n",
    "where\n",
    "\n",
    "- Input layer $d_i$ with 10 neurons $i = 1, \\dots, 10, 2^{10} = 1024$ possibilities\n",
    "- Hidden layer $x_l$ wiht 8 neurons $l = 1, \\dots, 8, 2^{8} = 256$ possibilities\n",
    "- Cause layer $y_j$ wiht 5 neurons $j = 1, \\dots, 5, 2^{5} = 32$ possibilities\n",
    "- Hyper layer $z_k$ wiht 3 neurons $k = 1, \\dots, 3, 2^{3} = 8$ possibilities\n",
    "- Generative bias is always $1$ (**Ursatz** in Schenkerian analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 3\n",
    "n_y = 5\n",
    "n_x = 8\n",
    "n_d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_12 = np.random.rand(n_x,n_d) *2-1\n",
    "Phi_23 = np.random.rand(n_y,n_x) *2-1\n",
    "Phi_34 = np.random.rand(n_z,n_y) *2-1\n",
    "b_12 = np.random.rand(n_x,1) *2-1\n",
    "b_23 = np.random.rand(n_y,1) *2-1\n",
    "b_34 = np.random.rand(n_z,1) *2-1\n",
    "\n",
    "Theta = np.random.rand(n_z,1) *2-1\n",
    "Theta_43 = np.random.rand(n_y,n_z) *2-1\n",
    "Theta_32 = np.random.rand(n_x,n_y) *2-1\n",
    "Theta_21 = np.random.rand(n_d,n_x) *2-1\n",
    "b_43 = np.random.rand(n_y,1) *2-1\n",
    "b_32 = np.random.rand(n_x,1) *2-1\n",
    "b_21 = np.random.rand(n_d,1) *2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 0.70046353  0.66337122  0.81162809  0.91505913 -0.70999478 -0.22892445\n",
      "  -0.43162401 -0.24685352  0.96928902 -0.59891461]\n",
      " [-0.30175166  0.90167623 -0.35749612  0.60922608  0.08334442 -0.5727393\n",
      "  -0.47784762  0.03597584 -0.11936152 -0.56561284]\n",
      " [ 0.30065009  0.49038863  0.49222799  0.57652788 -0.18599646 -0.35060745\n",
      "   0.41602025 -0.82638127 -0.00819545 -0.80736668]\n",
      " [-0.39938742 -0.46000916 -0.85419421  0.31628239 -0.71688841 -0.10476997\n",
      "  -0.42615797 -0.52666339  0.4706374   0.18462482]\n",
      " [-0.57058909 -0.34781187  0.42768421  0.22045128 -0.3711668  -0.44448819\n",
      "   0.86315534  0.94549712  0.39262227 -0.12812379]\n",
      " [ 0.72423593  0.63887754  0.08258646 -0.97875025  0.87371566 -0.66692262\n",
      "  -0.47107942  0.36840904 -0.68557307 -0.52381884]\n",
      " [ 0.50127086 -0.49757956 -0.21973637 -0.59182289 -0.58686203  0.96174708\n",
      "  -0.45732905 -0.46815264 -0.06773985  0.01557436]\n",
      " [ 0.35883974  0.6990014  -0.99567695 -0.34225972 -0.59472645 -0.11087274\n",
      "  -0.05386368 -0.94540727  0.22035887 -0.84845901]]\n",
      "Phi_23: [[-0.70643536 -0.1508532  -0.24376632 -0.8539265  -0.97870568 -0.95387962\n",
      "  -0.84183349 -0.73947662]\n",
      " [-0.8614871   0.21015927 -0.35723363 -0.88574291 -0.18076883 -0.43902835\n",
      "  -0.81429231  0.78384388]\n",
      " [ 0.84183463 -0.79563562 -0.95845824 -0.0484323  -0.63391897  0.4303066\n",
      "   0.35941465  0.21330331]\n",
      " [-0.81588763  0.8345121  -0.27932693 -0.55267839  0.88937233 -0.03206188\n",
      "  -0.91643369  0.19818188]\n",
      " [ 0.65597683 -0.29921271 -0.26351984  0.70095729 -0.51397649 -0.02621968\n",
      "   0.32403809  0.02548243]]\n",
      "Phi_34: [[ 0.93282984  0.60061784  0.018992   -0.88019453 -0.21738564]\n",
      " [-0.71874131  0.80011519 -0.55520892  0.22405677  0.61785889]\n",
      " [-0.61443304 -0.75409494 -0.00415523 -0.84963854  0.29618573]]\n",
      "b_12: [[-0.47109784]\n",
      " [-0.09525472]\n",
      " [-0.48168917]\n",
      " [-0.3721083 ]\n",
      " [ 0.58596292]\n",
      " [-0.90553349]\n",
      " [ 0.72146759]\n",
      " [-0.12742696]]\n",
      "b_23: [[-0.98791728]\n",
      " [ 0.75979848]\n",
      " [-0.40059629]\n",
      " [ 0.14446545]\n",
      " [ 0.12095083]]\n",
      "b_34: [[-0.62749177]\n",
      " [ 0.39825945]\n",
      " [-0.58250952]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[ 0.54095459]\n",
      " [-0.02694901]\n",
      " [ 0.26798225]]\n",
      "Theta_43: [[-0.28419503  0.62096252  0.31468793]\n",
      " [ 0.84400597  0.89836389 -0.0661224 ]\n",
      " [ 0.93881866 -0.97329526  0.5959983 ]\n",
      " [ 0.2987372   0.59434997  0.02154112]\n",
      " [-0.87552412 -0.13742513 -0.53410832]]\n",
      "Theta_32: [[ 0.00257584  0.14395475 -0.43012178  0.16706566  0.68971692]\n",
      " [ 0.49041492 -0.24524771 -0.76753757 -0.53633693  0.56715938]\n",
      " [ 0.83413542  0.36312199 -0.96959998 -0.48311253  0.86106507]\n",
      " [ 0.19504268 -0.83019175  0.83037298 -0.44144708 -0.11396123]\n",
      " [-0.6047336   0.42420133  0.46086408  0.08561609  0.70286733]\n",
      " [ 0.39698949 -0.8442142  -0.48116    -0.57128674 -0.02298249]\n",
      " [-0.75458329  0.36702767  0.80536683  0.28457257  0.16978723]\n",
      " [ 0.23140572  0.96043924 -0.33133748  0.22099877  0.24382105]]\n",
      "Theta_21: [[ 0.84309062  0.6799303   0.84063225 -0.09507744 -0.65524239 -0.94284151\n",
      "   0.66691121 -0.43965246]\n",
      " [ 0.92247762 -0.55005819 -0.20365569 -0.0145644  -0.56005376  0.17333551\n",
      "   0.7586334  -0.62438069]\n",
      " [ 0.83076873 -0.58704948  0.23451776 -0.85776411 -0.71176966 -0.87536356\n",
      "   0.08667673 -0.28140952]\n",
      " [ 0.15003178 -0.89564036  0.60257773 -0.64917951 -0.80650181 -0.41436291\n",
      "  -0.68296964 -0.75133554]\n",
      " [-0.44283338 -0.45977197  0.06499856  0.06171918 -0.08528018 -0.80833953\n",
      "  -0.85756752 -0.34804977]\n",
      " [-0.10576747 -0.28147327 -0.33414464 -0.59880993 -0.79675291 -0.51859802\n",
      "   0.12677845 -0.98604358]\n",
      " [ 0.36747152  0.14036218  0.92330739  0.86357762 -0.89581721 -0.87717265\n",
      "  -0.18021693 -0.06322434]\n",
      " [ 0.56218135 -0.19630918  0.94657327 -0.46641575  0.03618278  0.42414352\n",
      "  -0.39908582 -0.3947042 ]\n",
      " [-0.220391   -0.83642056  0.46201188  0.42407047 -0.86474257  0.47051716\n",
      "   0.44040023 -0.32031861]\n",
      " [-0.03258756  0.11625317  0.67514299 -0.24385101 -0.93407216  0.64163468\n",
      "   0.51230647 -0.57286501]]\n",
      "b_43: [[-0.12775149]\n",
      " [ 0.04994629]\n",
      " [-0.17207578]\n",
      " [ 0.87610233]\n",
      " [-0.76464228]]\n",
      "b_32: [[ 0.98673575]\n",
      " [-0.33206876]\n",
      " [ 0.29450618]\n",
      " [ 0.4449014 ]\n",
      " [ 0.72570023]\n",
      " [ 0.19952576]\n",
      " [-0.97680253]\n",
      " [-0.28774796]]\n",
      "b_21: [[ 0.97033964]\n",
      " [ 0.17139085]\n",
      " [-0.05139264]\n",
      " [-0.14198675]\n",
      " [ 0.8287817 ]\n",
      " [-0.18461699]\n",
      " [ 0.14247749]\n",
      " [-0.23650664]\n",
      " [-0.47792812]\n",
      " [ 0.49328339]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of parameters: 135 + 16 + 138 + 23 = 312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As analyzed in *Document 2*, we use binary representatioin {1,-1} instead of {0,1} to replace the local delta rule where gradients vanish when the neuron takes value 0\n",
    "- We use **rejection sampling** for each layer to choose from -1 or 1 (for computation efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z):\n",
    "    q_2 = sigmoid(np.matmul(Phi_12,data) + b_12)\n",
    "    x = ((q_2 > np.random.rand(n_x,1)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    y = ((q_3 > np.random.rand(n_y,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    z = ((q_4 > np.random.rand(n_z,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    Q_2 = (np.cumprod(q_2[np.where(x == 1)])[-1] if q_2[np.where(x == 1)].size != 0 else 1) * (np.cumprod(1-q_2[np.where(x == -1)])[-1] if q_2[np.where(x == -1)].size != 0 else 1)*(1.5**n_x)\n",
    "    Q_3 = (np.cumprod(q_3[np.where(y == 1)])[-1] if q_3[np.where(y == 1)].size != 0 else 1) * (np.cumprod(1-q_3[np.where(y == -1)])[-1] if q_3[np.where(y == -1)].size != 0 else 1)*(1.5**n_y)\n",
    "    Q_4 = (np.cumprod(q_4[np.where(z == 1)])[-1] if q_4[np.where(z == 1)].size != 0 else 1) * (np.cumprod(1-q_4[np.where(z == -1)])[-1] if q_4[np.where(z == -1)].size != 0 else 1)*(1.5**n_z)\n",
    "    Q = Q_2 * Q_3 * Q_4\n",
    "    \n",
    "    return q_2,q_3,q_4,x,y,z,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.transpose(well_formed_set[0:1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03403704],\n",
       "       [0.65332594],\n",
       "       [0.61558687],\n",
       "       [0.44143854],\n",
       "       [0.69878497],\n",
       "       [0.37753688],\n",
       "       [0.0861012 ],\n",
       "       [0.69294601]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_2 = sigmoid(np.matmul(Phi_12,data) + b_12)\n",
    "q_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ((q_2 > np.random.rand(n_x,1)).astype(int) - 0.5)*2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_2: [[0.13352257]\n",
      " [0.746527  ]\n",
      " [0.81201678]\n",
      " [0.13464848]\n",
      " [0.22199253]\n",
      " [0.96318306]\n",
      " [0.51277176]\n",
      " [0.96457059]]\n",
      "q_3: [[0.5756663 ]\n",
      " [0.97586899]\n",
      " [0.11609115]\n",
      " [0.90562918]\n",
      " [0.166656  ]]\n",
      "q_4: [[0.55580529]\n",
      " [0.65498855]\n",
      " [0.04340911]]\n",
      "x_w: [[-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]]\n",
      "y_w: [[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "z_w: [[-1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "Q: 10.966231903455345\n"
     ]
    }
   ],
   "source": [
    "# Find a cause\n",
    "\n",
    "q_2,q_3,q_4,x_w,y_w,z_w,Q = wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z)\n",
    "print (\"q_2: \" + str(q_2))\n",
    "print (\"q_3: \" + str(q_3))\n",
    "print (\"q_4: \" + str(q_4))\n",
    "print (\"x_w: \" + str(x_w))\n",
    "print (\"y_w: \" + str(y_w))\n",
    "print (\"z_w: \" + str(z_w))\n",
    "print (\"Q: \" + str(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_forward_batch(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z,batch_size):\n",
    "    q_2 = sigmoid(np.matmul(Phi_12,data) + b_12)\n",
    "    x = ((q_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    y = ((q_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    z = ((q_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    Q_2 = np.cumprod(np.where(x == 1,q_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-q_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    Q_3 = np.cumprod(np.where(y == 1,q_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-q_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    Q_4 = np.cumprod(np.where(z == 1,q_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-q_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    Q = Q_2 * Q_3 * Q_4\n",
    "    \n",
    "    return q_2,q_3,q_4,x,y,z,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = np.transpose(well_formed_set[0:10])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58058522,  0.58058522,  0.58058522,  0.58058522],\n",
       "       [-1.6092518 ,  0.3907482 , -1.6092518 ,  0.3907482 ],\n",
       "       [ 1.35356431,  1.35356431,  1.35356431,  1.35356431],\n",
       "       [-0.93863738,  1.06136262,  1.06136262,  1.06136262],\n",
       "       [-1.86803148, -1.86803148, -1.86803148, -1.86803148],\n",
       "       [ 1.67987524,  1.67987524,  1.67987524,  1.67987524],\n",
       "       [ 0.86571675,  0.86571675, -1.13428325, -1.13428325],\n",
       "       [-0.13771591, -0.13771591, -0.13771591,  1.86228409]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = data[0:8] + b_12\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.ones([8,4])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(test == -1,q,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        ],\n",
       "       [2.6092518 , 1.        , 2.6092518 , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.93863738, 1.        , 1.        , 1.        ],\n",
       "       [2.86803148, 2.86803148, 2.86803148, 2.86803148],\n",
       "       [1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 2.13428325, 2.13428325],\n",
       "       [1.13771591, 1.13771591, 1.13771591, 1.        ]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(data[0:8] == -1,1-q,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58058522, 0.58058522, 0.58058522, 0.58058522],\n",
       "       [0.58058522, 0.22686263, 0.58058522, 0.22686263],\n",
       "       [0.78585943, 0.30707316, 0.78585943, 0.30707316],\n",
       "       [0.78585943, 0.32591597, 0.83408183, 0.32591597],\n",
       "       [0.78585943, 0.32591597, 0.83408183, 0.32591597],\n",
       "       [1.32014581, 0.54749817, 1.40115341, 0.54749817],\n",
       "       [1.14287234, 0.47397834, 1.40115341, 0.54749817],\n",
       "       [1.14287234, 0.47397834, 1.40115341, 1.01959713]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumprod(np.where(data[0:8] == 1,q,1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14287234, 0.47397834, 1.40115341, 1.01959713])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.cumprod(np.where(data[0:8] == 1,q,1),axis=0)[-1]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30615719, 0.22465547, 1.96323088, 1.03957831])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q * Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0395783075042369"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.01959713 * 1.01959713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_2_batch: [[0.13352257 0.79035505 0.98883703 0.98237116 0.99225912 0.77617067\n",
      "  0.3621196  0.16477452 0.88611348 0.55156464]\n",
      " [0.746527   0.04792253 0.50818526 0.3068445  0.74276523 0.17770593\n",
      "  0.34952719 0.44575866 0.58502072 0.73118235]\n",
      " [0.81201678 0.75421757 0.96285477 0.80880274 0.68357803 0.56206191\n",
      "  0.40901695 0.13934768 0.83461515 0.3390204 ]\n",
      " [0.13464848 0.38146688 0.31631035 0.731364   0.27452364 0.08803513\n",
      "  0.02125021 0.167525   0.0592238  0.27473983]\n",
      " [0.22199253 0.71819009 0.66391284 0.41340507 0.69961473 0.92588038\n",
      "  0.68739074 0.7624029  0.85650132 0.83296682]\n",
      " [0.96318306 0.0910634  0.04831625 0.03502429 0.21391472 0.14504926\n",
      "  0.45693027 0.8295328  0.29473425 0.40728977]\n",
      " [0.51277176 0.97257582 0.80054724 0.96441287 0.7970683  0.56828267\n",
      "  0.36501039 0.27100331 0.643111   0.10218456]\n",
      " [0.96457059 0.78971516 0.88459607 0.67839754 0.56306374 0.08005665\n",
      "  0.03987896 0.53920089 0.42681947 0.37112504]]\n",
      "q_3_batch: [[0.25408314 0.00922898 0.05513893 0.09196148 0.01157535 0.36054729\n",
      "  0.98189732 0.20268699 0.01157535 0.85618531]\n",
      " [0.83901639 0.02247198 0.70366066 0.27578321 0.39327078 0.39921236\n",
      "  0.93020751 0.70192638 0.39327078 0.89398828]\n",
      " [0.5695762  0.54301401 0.14730071 0.73229812 0.66729003 0.79012023\n",
      "  0.15110932 0.25186749 0.66729003 0.07895834]\n",
      " [0.22435008 0.06944509 0.65466841 0.01957943 0.25095523 0.29585594\n",
      "  0.56466918 0.91447688 0.25095523 0.86588265]\n",
      " [0.41023038 0.7810742  0.34864548 0.91707818 0.48025717 0.61052077\n",
      "  0.26705525 0.18044778 0.48025717 0.15969763]]\n",
      "q_4_batch: [[0.52968614 0.26030821 0.53913688 0.17988563 0.43096799 0.69451061\n",
      "  0.87916473 0.55580529 0.87916473 0.27347143]\n",
      " [0.83622569 0.25346079 0.62714575 0.78003951 0.85267145 0.07462513\n",
      "  0.5480826  0.65498855 0.5480826  0.27704035]\n",
      " [0.45895175 0.79171861 0.45688885 0.87391182 0.60336303 0.52658739\n",
      "  0.19886083 0.04340911 0.19886083 0.17015676]]\n",
      "x_w_batch: [[-1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]\n",
      " [-1. -1.  1. -1. -1. -1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1.  1.  1. -1.  1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1.  1.  1. -1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1.  1. -1. -1.  1. -1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1. -1.  1.  1. -1.]\n",
      " [ 1. -1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "y_w_batch: [[-1. -1. -1. -1. -1.  1.  1.  1.  1.  1.]\n",
      " [ 1. -1.  1. -1.  1. -1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1.  1.  1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1.  1. -1.  1.]\n",
      " [-1. -1. -1.  1.  1. -1. -1. -1. -1. -1.]]\n",
      "z_w_batch: [[ 1. -1. -1. -1. -1.  1. -1. -1.  1. -1.]\n",
      " [ 1.  1.  1.  1.  1. -1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1.  1.  1. -1. -1.  1.]]\n",
      "Q_batch: [1.10953444e+00 3.02487739e-02 3.36187353e-01 8.67054206e+00\n",
      " 1.52548380e-01 1.10064204e+00 3.03376481e-02 1.61824925e-01\n",
      " 2.46639401e-03 4.23743874e-03]\n"
     ]
    }
   ],
   "source": [
    "# Find a cause\n",
    "\n",
    "q_2_batch,q_3_batch,q_4_batch,x_w_batch,y_w_batch,z_w_batch,Q_batch = wake_forward_batch(data_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z,batch_size)\n",
    "print (\"q_2_batch: \" + str(q_2_batch))\n",
    "print (\"q_3_batch: \" + str(q_3_batch))\n",
    "print (\"q_4_batch: \" + str(q_4_batch))\n",
    "print (\"x_w_batch: \" + str(x_w_batch))\n",
    "print (\"y_w_batch: \" + str(y_w_batch))\n",
    "print (\"z_w_batch: \" + str(z_w_batch))\n",
    "print (\"Q_batch: \" + str(Q_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,1)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    d = ((p_1 > np.random.rand(n_d,1)).astype(int) - 0.5)*2\n",
    "    \n",
    "    P_4 = (np.cumprod(p_4[np.where(z == 1)])[-1] if p_4[np.where(z == 1)].size != 0 else 1)* (np.cumprod(1-p_4[np.where(z == -1)])[-1] if p_4[np.where(z == -1)].size != 0 else 1)*(1.5**n_z)\n",
    "    P_3 = (np.cumprod(p_3[np.where(y == 1)])[-1] if p_3[np.where(y == 1)].size != 0 else 1)* (np.cumprod(1-p_3[np.where(y == -1)])[-1] if p_3[np.where(y == -1)].size != 0 else 1)*(1.5**n_y)\n",
    "    P_2 = (np.cumprod(p_2[np.where(x == 1)])[-1] if p_2[np.where(x == 1)].size != 0 else 1)* (np.cumprod(1-p_2[np.where(x == -1)])[-1] if p_2[np.where(x == -1)].size != 0 else 1)*(1.5**n_x)\n",
    "    P_1 = (np.cumprod(p_1[np.where(d == 1)])[-1] if p_1[np.where(d == 1)].size != 0 else 1)* (np.cumprod(1-p_1[np.where(d == -1)])[-1] if p_1[np.where(d == -1)].size != 0 else 1)*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4: [[0.63203445]\n",
      " [0.49326315]\n",
      " [0.56659748]]\n",
      "p_3: [[0.62801346]\n",
      " [0.84892491]\n",
      " [0.59614931]\n",
      " [0.85701683]\n",
      " [0.09015861]]\n",
      "p_2: [[0.47188771]\n",
      " [0.07956516]\n",
      " [0.03854843]\n",
      " [0.82962015]\n",
      " [0.679145  ]\n",
      " [0.40547253]\n",
      " [0.58197962]\n",
      " [0.13779183]]\n",
      "p_1: [[0.04214507]\n",
      " [0.3766529 ]\n",
      " [0.25649506]\n",
      " [0.70342562]\n",
      " [0.87176629]\n",
      " [0.66362542]\n",
      " [0.02455951]\n",
      " [0.54279007]\n",
      " [0.30544408]\n",
      " [0.43694914]]\n",
      "z_s: [[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "y_s: [[-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "x_s: [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "d_s: [[-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "P: 0.004736622884412791\n"
     ]
    }
   ],
   "source": [
    "# Generate an instance\n",
    "\n",
    "p_4,p_3,p_2,p_1,z_s,y_s,x_s,d_s,P = sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d)\n",
    "print (\"p_4: \" + str(p_4))\n",
    "print (\"p_3: \" + str(p_3))\n",
    "print (\"p_2: \" + str(p_2))\n",
    "print (\"p_1: \" + str(p_1))\n",
    "print (\"z_s: \" + str(z_s))\n",
    "print (\"y_s: \" + str(y_s))\n",
    "print (\"x_s: \" + str(x_s))\n",
    "print (\"d_s: \" + str(d_s))\n",
    "print (\"P: \" + str(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    d = ((p_1 > np.random.rand(n_d,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    P_4 = np.cumprod(np.where(z == 1,p_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-p_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    P_3 = np.cumprod(np.where(y == 1,p_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-p_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    P_2 = np.cumprod(np.where(x == 1,p_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-p_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    P_1 = np.cumprod(np.where(d == 1,p_1,1),axis=0)[-1] * np.cumprod(np.where(d == -1,1-p_1,1),axis=0)[-1]*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4_batch: [[0.63203445]\n",
      " [0.49326315]\n",
      " [0.56659748]]\n",
      "p_3_batch: [[0.31449084 0.62801346 0.74877583 0.47360657 0.47360657 0.20626352\n",
      "  0.31449084 0.46261216 0.32778483 0.32778483]\n",
      " [0.16433769 0.84892491 0.50954429 0.86511485 0.86511485 0.5154228\n",
      "  0.16433769 0.14697254 0.4823738  0.4823738 ]\n",
      " [0.32440578 0.59614931 0.18419335 0.30948017 0.30948017 0.75842059\n",
      "  0.32440578 0.61263434 0.91181791 0.91181791]\n",
      " [0.4903697  0.85701683 0.76732293 0.85165595 0.85165595 0.63620919\n",
      "  0.4903697  0.50113907 0.64612076 0.64612076]\n",
      " [0.68620043 0.09015861 0.3633967  0.22383027 0.22383027 0.27515307\n",
      "  0.68620043 0.42903207 0.11538792 0.11538792]]\n",
      "p_2_batch: [[0.46166587 0.47188771 0.73799727 0.46166587 0.54372344 0.54372344\n",
      "  0.71867251 0.60193744 0.47188771 0.66851003]\n",
      " [0.29208864 0.07956516 0.1972312  0.29208864 0.05027019 0.05027019\n",
      "  0.67689802 0.5397855  0.07956516 0.41799337]\n",
      " [0.53599041 0.03854843 0.36561274 0.53599041 0.07654206 0.07654206\n",
      "  0.75769749 0.42284534 0.03854843 0.60231975]\n",
      " [0.76772929 0.82962015 0.14954275 0.76772929 0.4806482  0.4806482\n",
      "  0.93264168 0.69106133 0.82962015 0.29832272]\n",
      " [0.55417366 0.679145   0.66296152 0.55417366 0.83177338 0.83177338\n",
      "  0.68457572 0.41505301 0.679145   0.62370114]\n",
      " [0.46640327 0.40547253 0.24809054 0.46640327 0.11193345 0.11193345\n",
      "  0.81874587 0.84840938 0.40547253 0.50843702]\n",
      " [0.26632455 0.58197962 0.36684565 0.26632455 0.74363738 0.74363738\n",
      "  0.19657623 0.13599346 0.58197962 0.24695512]\n",
      " [0.52695876 0.13779183 0.67913528 0.52695876 0.52176768 0.52176768\n",
      "  0.20993842 0.16616209 0.13779183 0.57634896]]\n",
      "p_1_batch: [[0.56296739 0.83089071 0.9145558  0.4829591  0.56417671 0.66989969\n",
      "  0.34976994 0.11886224 0.47646037 0.51342481]\n",
      " [0.21637957 0.92291602 0.60573295 0.12135128 0.72419687 0.26534206\n",
      "  0.47109281 0.64272227 0.65423054 0.7119217 ]\n",
      " [0.36354016 0.69121888 0.87677368 0.09946654 0.6530494  0.27898596\n",
      "  0.02230167 0.20484966 0.29823567 0.34316506]\n",
      " [0.83190463 0.33808387 0.88179951 0.19825288 0.66687713 0.21935586\n",
      "  0.02680712 0.76464356 0.27450028 0.74469657]\n",
      " [0.97783402 0.74192205 0.91494575 0.93918868 0.94109497 0.79827485\n",
      "  0.35558612 0.90120321 0.87453322 0.78320387]\n",
      " [0.46276392 0.63670486 0.32314917 0.4890323  0.57628316 0.13380218\n",
      "  0.30417035 0.74561841 0.68408858 0.19814137]\n",
      " [0.83839381 0.54344514 0.98281619 0.52009794 0.63056787 0.76123149\n",
      "  0.11564391 0.45933995 0.36338016 0.65179149]\n",
      " [0.57043055 0.21698094 0.63325275 0.11897665 0.38103067 0.21349728\n",
      "  0.12433092 0.3028808  0.08258664 0.90518895]\n",
      " [0.50240609 0.38357988 0.65874137 0.06996413 0.20502458 0.56212424\n",
      "  0.31747379 0.85272307 0.49160108 0.62477758]\n",
      " [0.33754841 0.25633858 0.49575026 0.14282547 0.110102   0.31101987\n",
      "  0.62618015 0.75526435 0.26895881 0.63270889]]\n",
      "z_s_batch: [[-1.  1. -1.  1.  1.  1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]\n",
      " [-1.  1.  1. -1. -1. -1. -1.  1.  1.  1.]]\n",
      "y_s_batch: [[ 1. -1. -1.  1. -1. -1.  1. -1. -1. -1.]\n",
      " [ 1. -1.  1.  1.  1.  1. -1. -1. -1.  1.]\n",
      " [ 1.  1. -1.  1.  1.  1.  1. -1.  1. -1.]\n",
      " [-1.  1.  1. -1.  1.  1. -1. -1.  1. -1.]\n",
      " [-1. -1. -1. -1. -1. -1.  1. -1. -1. -1.]]\n",
      "x_s_batch: [[-1.  1.  1. -1.  1. -1. -1. -1. -1.  1.]\n",
      " [-1. -1. -1.  1. -1. -1.  1. -1. -1. -1.]\n",
      " [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1. -1.  1.  1.  1.  1. -1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  1.  1. -1.  1. -1.]\n",
      " [-1. -1.  1. -1. -1.  1. -1. -1. -1. -1.]]\n",
      "d_s_batch: [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1.]\n",
      " [ 1.  1. -1. -1. -1. -1.  1.  1.  1. -1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1. -1. -1. -1.]\n",
      " [ 1. -1.  1. -1.  1.  1. -1. -1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  1. -1.  1. -1.  1.  1.  1. -1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.  1. -1.  1. -1. -1.]\n",
      " [-1. -1. -1. -1.  1. -1.  1. -1. -1. -1.]]\n",
      "P_batch: [9.18168109e-05 9.26280109e-02 6.92165500e-03 2.12871057e-02\n",
      " 9.59862441e-03 1.65989422e-02 6.46402536e-03 2.96182705e-02\n",
      " 8.38967307e-01 1.59580090e-04]\n"
     ]
    }
   ],
   "source": [
    "# Generate an instance\n",
    "\n",
    "p_4_batch,p_3_batch,p_2_batch,p_1_batch,z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch = sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size)\n",
    "print (\"p_4_batch: \" + str(p_4_batch))\n",
    "print (\"p_3_batch: \" + str(p_3_batch))\n",
    "print (\"p_2_batch: \" + str(p_2_batch))\n",
    "print (\"p_1_batch: \" + str(p_1_batch))\n",
    "print (\"z_s_batch: \" + str(z_s_batch))\n",
    "print (\"y_s_batch: \" + str(y_s_batch))\n",
    "print (\"x_s_batch: \" + str(x_s_batch))\n",
    "print (\"d_s_batch: \" + str(d_s_batch))\n",
    "print (\"P_batch: \" + str(P_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta(z,y,x,d,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    Theta -= lr * (p_4 - (1+z)/2)\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    Theta_43 -= lr * np.outer((p_3 - (1+y)/2), z)\n",
    "    b_43 -= lr * (p_3 - (1+y)/2)\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    Theta_32 -= lr * np.outer((p_2 - (1+x)/2), y)\n",
    "    b_32 -= lr * (p_2 - (1+x)/2)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    Theta_21 -= lr * np.outer((p_1 - (1+d)/2), x)\n",
    "    b_21 -= lr * (p_1 - (1+d)/2)\n",
    "    \n",
    "    return Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[ 0.50949988]\n",
      " [-0.00173853]\n",
      " [ 0.23979132]]\n",
      "Theta_43: [[-0.30315111  0.63991859  0.29573185]\n",
      " [ 0.82157972  0.92079014 -0.08854866]\n",
      " [ 0.94201097 -0.97648757  0.59919061]\n",
      " [ 0.28688743  0.60619974  0.00969136]\n",
      " [-0.84489762 -0.16805162 -0.50348183]]\n",
      "Theta_32: [[-0.03350262  0.10787629 -0.39404332  0.13098721  0.72579538]\n",
      " [ 0.51976012 -0.21590251 -0.79688277 -0.50699173  0.53781418]\n",
      " [ 0.84619338  0.37517995 -0.98165793 -0.47105457  0.84900712]\n",
      " [ 0.18493203 -0.84030241  0.84048364 -0.45155773 -0.10385058]\n",
      " [-0.62271958  0.40621535  0.47885006  0.06763011  0.72085331]\n",
      " [ 0.42505334 -0.81615034 -0.50922385 -0.54322289 -0.05104634]\n",
      " [-0.76019336  0.3614176   0.8109769   0.2789625   0.1753973 ]\n",
      " [ 0.24262985  0.97166337 -0.34256161  0.2322229   0.23259692]]\n",
      "Theta_21: [[ 0.83094733  0.69207359  0.85277555 -0.10722073 -0.66738568 -0.93069821\n",
      "   0.65476792 -0.42750917]\n",
      " [ 0.89587527 -0.52345584 -0.17705334 -0.04116675 -0.58665611  0.19993786\n",
      "   0.73203105 -0.59777834]\n",
      " [ 0.83923087 -0.59551161  0.22605563 -0.84930197 -0.70330752 -0.88382569\n",
      "   0.09513886 -0.28987165]\n",
      " [ 0.1675173  -0.91312587  0.58509222 -0.631694   -0.78901629 -0.43184842\n",
      "  -0.66548413 -0.76882105]\n",
      " [-0.45323748 -0.44936787  0.07540266  0.05131508 -0.09568429 -0.79793543\n",
      "  -0.86797162 -0.33764567]\n",
      " [-0.09743427 -0.28980647 -0.34247784 -0.59047673 -0.78841971 -0.52693122\n",
      "   0.13511165 -0.99437678]\n",
      " [ 0.35361592  0.15421778  0.93716299  0.84972202 -0.90967281 -0.86331705\n",
      "  -0.19407253 -0.04936874]\n",
      " [ 0.58254355 -0.21667138  0.92621107 -0.44605355  0.05654498  0.40378132\n",
      "  -0.37872362 -0.4150664 ]\n",
      " [-0.2091739  -0.84763766  0.45079477  0.43528758 -0.85352547  0.45930006\n",
      "   0.45161733 -0.33153571]\n",
      " [-0.0062574   0.08992301  0.64881283 -0.21752085 -0.907742    0.61530452\n",
      "   0.53863663 -0.59919517]]\n",
      "b_43: [[-0.10879542]\n",
      " [ 0.07237254]\n",
      " [-0.17526809]\n",
      " [ 0.8879521 ]\n",
      " [-0.79526877]]\n",
      "b_32: [[ 0.95065729]\n",
      " [-0.30272356]\n",
      " [ 0.30656413]\n",
      " [ 0.43479075]\n",
      " [ 0.70771425]\n",
      " [ 0.22758961]\n",
      " [-0.9824126 ]\n",
      " [-0.27652383]]\n",
      "b_21: [[ 0.98248293]\n",
      " [ 0.1979932 ]\n",
      " [-0.05985478]\n",
      " [-0.15947227]\n",
      " [ 0.8391858 ]\n",
      " [-0.19295019]\n",
      " [ 0.15633309]\n",
      " [-0.25686884]\n",
      " [-0.48914522]\n",
      " [ 0.46695323]]\n"
     ]
    }
   ],
   "source": [
    "Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta(z_w,y_w,x_w,data,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta_batch(z,y,x,d,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    Theta -= lr * np.mean(p_4 - (1+z)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    Theta_43 -= lr * np.matmul((p_3 - (1+y)/2), np.transpose(z))/batch_size\n",
    "    b_43 -= lr * np.mean(p_3 - (1+y)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    Theta_32 -= lr * np.matmul((p_2 - (1+x)/2), np.transpose(y))/batch_size\n",
    "    b_32 -= lr * np.mean(p_2 - (1+x)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    Theta_21 -= lr * np.matmul((p_1 - (1+d)/2), np.transpose(x))/batch_size\n",
    "    b_21 -= lr * np.mean(p_1 - (1+d)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    return Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1+z_s)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67624414],\n",
       "       [0.28825566],\n",
       "       [0.69786985]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32375586, -0.32375586, -0.32375586, -0.32375586, -0.32375586,\n",
       "        -0.32375586,  0.67624414, -0.32375586,  0.67624414, -0.32375586],\n",
       "       [ 0.28825566,  0.28825566,  0.28825566,  0.28825566,  0.28825566,\n",
       "         0.28825566,  0.28825566,  0.28825566,  0.28825566,  0.28825566],\n",
       "       [ 0.69786985, -0.30213015, -0.30213015, -0.30213015, -0.30213015,\n",
       "        -0.30213015,  0.69786985, -0.30213015, -0.30213015, -0.30213015]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_4 - (1+z_s)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36796555],\n",
       "       [-0.50673685],\n",
       "       [-0.43340252]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(p_4 - (1+z_s)/2, axis = 1,keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[0.43475421]\n",
      " [0.05498185]\n",
      " [0.1793641 ]]\n",
      "Theta_43: [[-0.31863751  0.61809282  0.24078584]\n",
      " [ 0.76453844  0.94369926 -0.16423912]\n",
      " [ 0.92459553 -0.94527775  0.61953759]\n",
      " [ 0.26897673  0.60527937 -0.03230998]\n",
      " [-0.77481102 -0.21862447 -0.41869353]]\n",
      "Theta_32: [[-0.12690143  0.0174195  -0.27592045  0.02991207  0.80870596]\n",
      " [ 0.58125748 -0.15270927 -0.84070279 -0.40643257  0.47100116]\n",
      " [ 0.83681425  0.40173974 -0.99314566 -0.47716627  0.81183735]\n",
      " [ 0.15018029 -0.87763364  0.8530995  -0.44910561 -0.04917912]\n",
      " [-0.63651125  0.37415679  0.53696997  0.0312662   0.73620049]\n",
      " [ 0.4722166  -0.7343837  -0.56665039 -0.46809698 -0.10975856]\n",
      " [-0.77523534  0.36036057  0.81018843  0.22612135  0.15335709]\n",
      " [ 0.22657244  0.99860072 -0.35543653  0.22780414  0.22860252]]\n",
      "Theta_21: [[ 0.78568003  0.72584663  0.90472046 -0.17068041 -0.699972   -0.86960011\n",
      "   0.63150702 -0.38780264]\n",
      " [ 0.76210049 -0.39620425 -0.07159881 -0.17697401 -0.69005036  0.31247972\n",
      "   0.61702125 -0.49780604]\n",
      " [ 0.89719786 -0.63710527  0.20596098 -0.81266121 -0.65008142 -0.9151772\n",
      "   0.13758689 -0.31625349]\n",
      " [ 0.25957128 -0.97285116  0.53810754 -0.59214826 -0.70637776 -0.50640519\n",
      "  -0.59008944 -0.80963849]\n",
      " [-0.52135209 -0.40146115  0.08809368 -0.00538863 -0.13473859 -0.74855531\n",
      "  -0.90972524 -0.32133517]\n",
      " [-0.00710679 -0.35377309 -0.33382022 -0.5593208  -0.72448153 -0.56396843\n",
      "   0.20243524 -0.98787152]\n",
      " [ 0.29669027  0.20303757  0.9837882   0.75157038 -0.92366915 -0.78543933\n",
      "  -0.21616669 -0.02477338]\n",
      " [ 0.63675    -0.27686325  0.82274623 -0.39879477  0.13670284  0.33342616\n",
      "  -0.32072767 -0.51039437]\n",
      " [-0.14548637 -0.85597925  0.39865679  0.46008418 -0.77533058  0.41638971\n",
      "   0.51431553 -0.38325055]\n",
      " [ 0.05118658  0.0392764   0.50982204 -0.11046227 -0.82805954  0.50476928\n",
      "   0.58157712 -0.72456224]]\n",
      "b_43: [[-0.06751845]\n",
      " [ 0.12197428]\n",
      " [-0.18195358]\n",
      " [ 0.9038064 ]\n",
      " [-0.86341747]]\n",
      "b_32: [[ 0.87693518]\n",
      " [-0.24530233]\n",
      " [ 0.3378761 ]\n",
      " [ 0.40662579]\n",
      " [ 0.6705521 ]\n",
      " [ 0.28526626]\n",
      " [-0.98405502]\n",
      " [-0.24993913]]\n",
      "b_21: [[ 1.02922934]\n",
      " [ 0.29144546]\n",
      " [-0.08670709]\n",
      " [-0.2165616 ]\n",
      " [ 0.87432528]\n",
      " [-0.21536424]\n",
      " [ 0.21133311]\n",
      " [-0.32888201]\n",
      " [-0.52272135]\n",
      " [ 0.3638196 ]]\n"
     ]
    }
   ],
   "source": [
    "Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_batch(z_w_batch,y_w_batch,x_w_batch,data_batch,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size)\n",
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27753662,  0.696079  ,  0.71544976])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Theta)- (1+z_w)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta(z,y,x,d,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr):\n",
    "    \n",
    "    q_2 = sigmoid(np.matmul(Phi_12,d) + b_12)\n",
    "    Phi_12 -= lr * np.outer((q_2 - (1+x)/2), d)\n",
    "    b_12 -= lr * (q_2 - (1+x)/2)\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    Phi_23 -= lr * np.outer((q_3 - (1+y)/2), x)\n",
    "    b_23 -= lr * (q_3 - (1+y)/2)\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    Phi_34 -= lr * np.outer((q_4 - (1+z)/2), y)\n",
    "    b_34 -= lr * (q_4 - (1+z)/2)\n",
    "    \n",
    "    return Phi_12,Phi_23,Phi_34,b_12,b_23,b_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 0.7180436   0.64579115  0.79404802  0.89747906 -0.72757485 -0.24650451\n",
      "  -0.41404394 -0.26443358  0.95170895 -0.58133454]\n",
      " [-0.28463185  0.88455642 -0.37461593  0.59210627  0.0662246  -0.58985912\n",
      "  -0.4607278   0.01885603 -0.13648134 -0.54849302]\n",
      " [ 0.30951642  0.4815223   0.48336166  0.56766155 -0.19486279 -0.35947379\n",
      "   0.42488659 -0.8352476  -0.01706178 -0.79850034]\n",
      " [-0.39607215 -0.46332444 -0.85750949  0.31296711 -0.72020369 -0.10808524\n",
      "  -0.42284269 -0.52997867  0.46732212  0.1879401 ]\n",
      " [-0.57502039 -0.34338057  0.43211552  0.22488259 -0.36673549 -0.44005689\n",
      "   0.85872404  0.94992842  0.39705357 -0.1325551 ]\n",
      " [ 0.70976576  0.6533477   0.09705663 -0.96428008  0.88818583 -0.65245246\n",
      "  -0.48554959  0.38287921 -0.67110291 -0.53828901]\n",
      " [ 0.50736453 -0.50367323 -0.22583004 -0.59791656 -0.59295569  0.95565341\n",
      "  -0.45123538 -0.47424631 -0.07383352  0.02166803]\n",
      " [ 0.36202871  0.69581243 -0.99886593 -0.34544869 -0.59791542 -0.11406172\n",
      "  -0.05067471 -0.94859625  0.2171699  -0.84527004]]\n",
      "Phi_23: [[-0.69358435 -0.13800219 -0.23091532 -0.84107549 -0.99155669 -0.96673063\n",
      "  -0.82898248 -0.72662562]\n",
      " [-0.84382079  0.22782558 -0.33956732 -0.8680766  -0.19843514 -0.45669466\n",
      "  -0.796626    0.80151019]\n",
      " [ 0.83088113 -0.80658912 -0.96941175 -0.05938581 -0.62296546  0.4412601\n",
      "   0.34846115  0.2023498 ]\n",
      " [-0.81735412  0.83304562 -0.28079341 -0.55414487  0.89083882 -0.03059539\n",
      "  -0.91790018  0.19671539]\n",
      " [ 0.65941904 -0.2957705  -0.26007763  0.7043995  -0.51741871 -0.0296619\n",
      "   0.3274803   0.02892464]]\n",
      "Phi_34: [[ 0.91400241  0.58179041  0.03781943 -0.8613671  -0.23621307]\n",
      " [-0.73171144  0.78714507 -0.5422388   0.23702689  0.60488877]\n",
      " [-0.62614712 -0.76580902  0.00755885 -0.83792446  0.28447165]]\n",
      "b_12: [[-0.4886779 ]\n",
      " [-0.11237453]\n",
      " [-0.49055551]\n",
      " [-0.37542358]\n",
      " [ 0.59039422]\n",
      " [-0.89106332]\n",
      " [ 0.71537392]\n",
      " [-0.13061594]]\n",
      "b_23: [[-1.00076828]\n",
      " [ 0.74213217]\n",
      " [-0.38964279]\n",
      " [ 0.14593193]\n",
      " [ 0.11750862]]\n",
      "b_34: [[-0.60866434]\n",
      " [ 0.41122957]\n",
      " [-0.57079544]]\n"
     ]
    }
   ],
   "source": [
    "Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta(z_s,y_s,x_s,d_s,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta_batch(z,y,x,d,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size):\n",
    "    \n",
    "    q_2 = sigmoid(np.matmul(Phi_12,d) + b_12)\n",
    "    Phi_12 -= lr * np.matmul((q_2 - (1+x)/2), np.transpose(d))/batch_size\n",
    "    b_12 -= lr * np.mean(q_2 - (1+x)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    Phi_23 -= lr * np.matmul((q_3 - (1+y)/2), np.transpose(x))/batch_size\n",
    "    b_23 -= lr * np.mean(q_3 - (1+y)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    Phi_34 -= lr * np.matmul((q_4 - (1+z)/2), np.transpose(y))/batch_size\n",
    "    b_34 -= lr * np.mean(q_4 - (1+z)/2, axis = 1,keepdims = True)\n",
    "    \n",
    "    return Phi_12,Phi_23,Phi_34,b_12,b_23,b_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 7.05062085e-01  6.26109636e-01  7.95101731e-01  9.01460125e-01\n",
      "  -7.22715761e-01 -2.41999691e-01 -3.92321226e-01 -2.80144023e-01\n",
      "   9.22596186e-01 -5.65447121e-01]\n",
      " [-2.59492768e-01  8.64642784e-01 -3.47644356e-01  5.61948185e-01\n",
      "   1.46938958e-02 -6.16103920e-01 -4.50281672e-01  4.04434153e-02\n",
      "  -1.57637400e-01 -4.99793406e-01]\n",
      " [ 3.06819658e-01  4.77456637e-01  4.90890487e-01  5.84753177e-01\n",
      "  -2.04430540e-01 -3.69935912e-01  4.38153998e-01 -8.05687912e-01\n",
      "  -5.11618922e-04 -7.98251515e-01]\n",
      " [-3.96153718e-01 -4.75319429e-01 -8.65163619e-01  3.33988180e-01\n",
      "  -6.67090560e-01 -8.65714030e-02 -4.22226444e-01 -5.76939511e-01\n",
      "   4.74639215e-01  1.51131835e-01]\n",
      " [-5.88992178e-01 -3.21328466e-01  3.84291618e-01  2.11385074e-01\n",
      "  -3.42114043e-01 -4.25293399e-01  8.16706335e-01  9.14071282e-01\n",
      "   3.68889388e-01 -1.50053257e-01]\n",
      " [ 6.71421535e-01  6.56409043e-01  9.70615145e-02 -9.60762427e-01\n",
      "   8.63109717e-01 -6.51676605e-01 -4.67784182e-01  3.84638260e-01\n",
      "  -6.84032998e-01 -5.13789224e-01]\n",
      " [ 5.15955495e-01 -4.92593262e-01 -2.12264086e-01 -5.90886732e-01\n",
      "  -6.22521435e-01  9.36886669e-01 -4.43002663e-01 -4.54311486e-01\n",
      "  -7.32419858e-02  3.82465598e-02]\n",
      " [ 3.97843374e-01  6.52995206e-01 -9.22954381e-01 -3.14541702e-01\n",
      "  -6.28626273e-01 -1.43643041e-01  1.15365084e-02 -9.11229543e-01\n",
      "   2.38979907e-01 -8.15268117e-01]]\n",
      "Phi_23: [[-0.71092777 -0.10733376 -0.23046043 -0.84227644 -0.96966861 -0.9606525\n",
      "  -0.81631097 -0.73457937]\n",
      " [-0.82088697  0.20967096 -0.31112008 -0.85206822 -0.17558516 -0.47297655\n",
      "  -0.82039268  0.8014144 ]\n",
      " [ 0.78975193 -0.80276015 -0.98322949 -0.02591885 -0.56102496  0.40009705\n",
      "   0.36897165  0.17577214]\n",
      " [-0.77727347  0.79136612 -0.27385088 -0.55069477  0.88383972 -0.06728307\n",
      "  -0.89269256  0.22648161]\n",
      " [ 0.64678932 -0.23520814 -0.25574848  0.64832169 -0.53937443  0.0085018\n",
      "   0.35117596  0.05493641]]\n",
      "Phi_34: [[ 0.85999619  0.5835156   0.06104559 -0.81196526 -0.27337585]\n",
      " [-0.71355839  0.78376641 -0.52847438  0.24854213  0.61360765]\n",
      " [-0.66494534 -0.76526565 -0.01223722 -0.81544693  0.25433736]]\n",
      "b_12: [[-0.48804353]\n",
      " [-0.11981748]\n",
      " [-0.49274565]\n",
      " [-0.36517237]\n",
      " [ 0.59841424]\n",
      " [-0.89239233]\n",
      " [ 0.71025174]\n",
      " [-0.13961029]]\n",
      "b_23: [[-1.0009722 ]\n",
      " [ 0.74498414]\n",
      " [-0.38367528]\n",
      " [ 0.14654776]\n",
      " [ 0.10752681]]\n",
      "b_34: [[-0.6043268 ]\n",
      " [ 0.40878703]\n",
      " [-0.56802118]]\n"
     ]
    }
   ],
   "source": [
    "Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_batch(z_s_batch,y_s_batch,x_s_batch,d_s_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size)\n",
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta_weighted(z,y,x,d,Q,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr):\n",
    "    \n",
    "    p_4 = sigmoid(Theta)\n",
    "    Theta -= lr * Q * (p_4 - (1+z)/2)\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    Theta_43 -= lr * Q * np.outer((p_3 - (1+y)/2), z)\n",
    "    b_43 -= lr * Q * (p_3 - (1+y)/2)\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    Theta_32 -= lr * Q * np.outer((p_2 - (1+x)/2), y)\n",
    "    b_32 -= lr * Q * (p_2 - (1+x)/2)\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    Theta_21 -= lr * Q * np.outer((p_1 - (1+d)/2), x)\n",
    "    b_21 -= lr * Q * (p_1 - (1+d)/2)\n",
    "    \n",
    "    return Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[0.43783163]\n",
      " [0.05411711]\n",
      " [0.17880994]]\n",
      "Theta_43: [[-0.32109     0.62390282  0.24186011]\n",
      " [ 0.7652943   0.94602154 -0.16171953]\n",
      " [ 0.92679798 -0.94872408  0.61839683]\n",
      " [ 0.26822875  0.60771457 -0.03089561]\n",
      " [-0.77510713 -0.2200716  -0.42044941]]\n",
      "Theta_32: [[-0.12552554  0.01868611 -0.27948336  0.03227103  0.8082215 ]\n",
      " [ 0.58147541 -0.15278136 -0.84250851 -0.40990849  0.47127415]\n",
      " [ 0.84011704  0.40182764 -0.99458729 -0.47420398  0.81268766]\n",
      " [ 0.1513269  -0.87625193  0.85395959 -0.45120188 -0.05207736]\n",
      " [-0.63887374  0.37343871  0.53536224  0.03102853  0.73842034]\n",
      " [ 0.47342805 -0.73632974 -0.56696267 -0.46957496 -0.10992736]\n",
      " [-0.77504042  0.35934811  0.81140791  0.22973107  0.15644112]\n",
      " [ 0.23035161  0.99855896 -0.35663509  0.23048163  0.22658106]]\n",
      "Theta_21: [[ 0.78584562  0.726584    0.90397321 -0.16891115 -0.70091469 -0.87116418\n",
      "   0.62983123 -0.38752565]\n",
      " [ 0.76533934 -0.39916303 -0.07236738 -0.17353806 -0.68944906  0.31099285\n",
      "   0.61883392 -0.4985207 ]\n",
      " [ 0.89467764 -0.63597362  0.20518146 -0.81331119 -0.65219258 -0.91494663\n",
      "   0.13639451 -0.31640242]\n",
      " [ 0.25699667 -0.97306594  0.53678625 -0.59013978 -0.70815089 -0.50528815\n",
      "  -0.5912866  -0.81148037]\n",
      " [-0.51861052 -0.4024654   0.09017742 -0.00358954 -0.1345195  -0.74968225\n",
      "  -0.90923845 -0.31960162]\n",
      " [-0.01255306 -0.35061568 -0.33702268 -0.5595582  -0.72767078 -0.56317851\n",
      "   0.19897935 -0.99080454]\n",
      " [ 0.29733392  0.20301021  0.98414255  0.75587699 -0.92691124 -0.78798001\n",
      "  -0.21854941 -0.02256876]\n",
      " [ 0.63855584 -0.2779241   0.82530835 -0.39641875  0.13617971  0.3331272\n",
      "  -0.31943935 -0.5083975 ]\n",
      " [-0.14767227 -0.85868016  0.39982609  0.46132685 -0.77881738  0.41681219\n",
      "   0.51217849 -0.38193909]\n",
      " [ 0.0546092   0.03529017  0.51347728 -0.11137115 -0.826653    0.50600772\n",
      "   0.58621729 -0.72204887]]\n",
      "b_43: [[-0.066992  ]\n",
      " [ 0.12091934]\n",
      " [-0.18223486]\n",
      " [ 0.9088288 ]\n",
      " [-0.86192325]]\n",
      "b_32: [[ 0.87682967]\n",
      " [-0.24353104]\n",
      " [ 0.33571682]\n",
      " [ 0.41015917]\n",
      " [ 0.66973357]\n",
      " [ 0.28555047]\n",
      " [-0.98934665]\n",
      " [-0.25034956]]\n",
      "b_21: [[ 1.02696901]\n",
      " [ 0.29145354]\n",
      " [-0.08739136]\n",
      " [-0.21822079]\n",
      " [ 0.87446674]\n",
      " [-0.21767705]\n",
      " [ 0.20803445]\n",
      " [-0.3287129 ]\n",
      " [-0.52465886]\n",
      " [ 0.36789101]]\n"
     ]
    }
   ],
   "source": [
    "Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_weighted(z_w,y_w,x_w,data,Q,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.10953444e+00, 3.02487739e-02, 3.36187353e-01, 8.67054206e+00,\n",
       "       1.52548380e-01, 1.10064204e+00, 3.03376481e-02, 1.61824925e-01,\n",
       "       2.46639401e-03, 4.23743874e-03])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13287303e+00,  3.29670528e-01, -1.06906892e-01,\n",
       "        -2.57993765e-01,  9.81379221e-01],\n",
       "       [-1.54212402e+00,  1.90175442e+00, -2.87949893e+00,\n",
       "        -4.62243977e+00,  3.48379909e+00],\n",
       "       [-8.29220519e-02,  2.73432224e-01, -3.75126651e-01,\n",
       "        -6.10750823e-01,  5.38314791e-01],\n",
       "       [-4.06974766e-03,  4.25071738e-02, -5.58451893e-02,\n",
       "        -9.15231857e-02,  8.60631985e-02],\n",
       "       [ 1.61051705e-03,  1.60037249e-03, -1.60844233e-03,\n",
       "        -2.76142821e-03,  3.71569513e-03]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(Q_batch.reshape((-1,2)),b_21.reshape((2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.10953444e+00, -3.02487739e-02, -3.36187353e-01,\n",
       "        -8.67054206e+00, -1.52548380e-01,  1.10064204e+00,\n",
       "         3.03376481e-02,  1.61824925e-01,  2.46639401e-03,\n",
       "         4.23743874e-03],\n",
       "       [ 1.10953444e+00, -3.02487739e-02,  3.36187353e-01,\n",
       "        -8.67054206e+00,  1.52548380e-01, -1.10064204e+00,\n",
       "         3.03376481e-02,  1.61824925e-01,  2.46639401e-03,\n",
       "        -4.23743874e-03],\n",
       "       [-1.10953444e+00,  3.02487739e-02,  3.36187353e-01,\n",
       "        -8.67054206e+00,  1.52548380e-01,  1.10064204e+00,\n",
       "        -3.03376481e-02, -1.61824925e-01, -2.46639401e-03,\n",
       "        -4.23743874e-03],\n",
       "       [-1.10953444e+00, -3.02487739e-02, -3.36187353e-01,\n",
       "        -8.67054206e+00, -1.52548380e-01, -1.10064204e+00,\n",
       "        -3.03376481e-02,  1.61824925e-01, -2.46639401e-03,\n",
       "         4.23743874e-03],\n",
       "       [-1.10953444e+00, -3.02487739e-02, -3.36187353e-01,\n",
       "         8.67054206e+00,  1.52548380e-01, -1.10064204e+00,\n",
       "        -3.03376481e-02, -1.61824925e-01, -2.46639401e-03,\n",
       "        -4.23743874e-03]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_batch.reshape((1,-1)) * y_w_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta_weighted_batch(z,y,x,d,Q,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size):\n",
    "    \n",
    "    p_4 = sigmoid(Theta)\n",
    "    Theta -= lr *  np.matmul(p_4 - (1+z)/2, Q.reshape((-1,1)))/batch_size\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    Theta_43 -= lr * np.matmul(Q.reshape((1,-1)) * (p_3 - (1+y)/2), np.transpose(z))/batch_size\n",
    "    b_43 -= lr * np.matmul(p_3 - (1+y)/2, Q.reshape((-1,1)))/batch_size\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    Theta_32 -= lr * np.matmul(Q.reshape((1,-1)) * (p_2 - (1+x)/2), np.transpose(y))/batch_size\n",
    "    b_32 -= lr * np.matmul(p_2 - (1+x)/2, Q.reshape((-1,1)))/batch_size\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    Theta_21 -= lr * np.matmul(Q.reshape((1,-1)) * (p_1 - (1+d)/2), np.transpose(x))/batch_size\n",
    "    b_21 -= lr * np.matmul(p_1 - (1+d)/2, Q.reshape((-1,1)))/batch_size\n",
    "    \n",
    "   \n",
    "    return Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[0.42992643]\n",
      " [0.05932647]\n",
      " [0.18303467]]\n",
      "Theta_43: [[-0.31168101  0.60978991  0.23555978]\n",
      " [ 0.76847589  0.93971518 -0.16967594]\n",
      " [ 0.92563398 -0.94685484  0.61817116]\n",
      " [ 0.27434207  0.59788042 -0.03869525]\n",
      " [-0.7808173  -0.21281274 -0.41242933]]\n",
      "Theta_32: [[-0.12689302  0.01517119 -0.27525438  0.0286434   0.80967307]\n",
      " [ 0.58754118 -0.14605329 -0.83403712 -0.3992268   0.46514131]\n",
      " [ 0.83378008  0.40099076 -0.99520208 -0.4794039   0.81346881]\n",
      " [ 0.14681643 -0.88017976  0.84916965 -0.45037394 -0.04475884]\n",
      " [-0.62862     0.37947019  0.54481441  0.03776513  0.72947764]\n",
      " [ 0.47789583 -0.72588119 -0.5610109  -0.46057192 -0.11625308]\n",
      " [-0.78218808  0.35351884  0.80330854  0.21731019  0.15839775]\n",
      " [ 0.21903597  0.99277409 -0.36215403  0.22061234  0.23488071]]\n",
      "Theta_21: [[ 0.78568116  0.72509693  0.90509595 -0.17117194 -0.70022893 -0.86950219\n",
      "   0.63244779 -0.38744953]\n",
      " [ 0.75365331 -0.38795919 -0.07759159 -0.18395233 -0.68368747  0.32091461\n",
      "   0.60925885 -0.5037759 ]\n",
      " [ 0.89888128 -0.6374117   0.20628163 -0.811355   -0.65011995 -0.91672994\n",
      "   0.1380003  -0.3159693 ]\n",
      " [ 0.26361702 -0.97501546  0.54025888 -0.58938644 -0.70782906 -0.51029104\n",
      "  -0.58741392 -0.80746008]\n",
      " [-0.52717368 -0.39696735  0.08262685 -0.01163132 -0.12960342 -0.74282394\n",
      "  -0.91425666 -0.32678344]\n",
      " [-0.00109653 -0.35829077 -0.32903016 -0.55435149 -0.72843825 -0.5696782\n",
      "   0.20729548 -0.98312332]\n",
      " [ 0.28855769  0.21020852  0.97498566  0.74137161 -0.91465044 -0.77734232\n",
      "  -0.22278744 -0.03361476]\n",
      " [ 0.63376789 -0.27321936  0.81771459 -0.40247843  0.14136892  0.33639888\n",
      "  -0.32452595 -0.51539499]\n",
      " [-0.14192841 -0.85698181  0.39869787  0.4612623  -0.77457557  0.41303978\n",
      "   0.51625287 -0.38318469]\n",
      " [ 0.04506461  0.04708973  0.50281271 -0.1150465  -0.82156658  0.51063211\n",
      "   0.57357298 -0.73153304]]\n",
      "b_43: [[-0.07407424]\n",
      " [ 0.1173257 ]\n",
      " [-0.18347396]\n",
      " [ 0.89514245]\n",
      " [-0.85814033]]\n",
      "b_32: [[ 0.87801603]\n",
      " [-0.25235481]\n",
      " [ 0.3398637 ]\n",
      " [ 0.40783394]\n",
      " [ 0.66427736]\n",
      " [ 0.27788569]\n",
      " [-0.97495486]\n",
      " [-0.24300615]]\n",
      "b_21: [[ 1.03017927]\n",
      " [ 0.28371302]\n",
      " [-0.08629155]\n",
      " [-0.21388337]\n",
      " [ 0.86979625]\n",
      " [-0.21050464]\n",
      " [ 0.20472305]\n",
      " [-0.33266041]\n",
      " [-0.52081908]\n",
      " [ 0.35582853]]\n"
     ]
    }
   ],
   "source": [
    "Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_weighted_batch(z_w_batch,y_w_batch,x_w_batch,data_batch,Q_batch,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size)\n",
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39299164,  0.60700836,  0.60700836,  0.60700836,  0.60700836,\n",
       "        -0.39299164,  0.60700836,  0.60700836, -0.39299164,  0.60700836],\n",
       "       [-0.486258  , -0.486258  , -0.486258  , -0.486258  , -0.486258  ,\n",
       "         0.513742  ,  0.513742  ,  0.513742  ,  0.513742  , -0.486258  ],\n",
       "       [ 0.54472119, -0.45527881,  0.54472119, -0.45527881, -0.45527881,\n",
       "        -0.45527881, -0.45527881,  0.54472119,  0.54472119, -0.45527881]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Theta)- (1+z_w_batch)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta_weighted(z,y,x,d,P,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr):\n",
    "    \n",
    "    q_2 = sigmoid(np.matmul(Phi_12,d) + b_12)\n",
    "    Phi_12 -= lr * P * np.outer((q_2 - (1+x)/2), d)\n",
    "    b_12 -= lr * P * (q_2 - (1+x)/2)\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    Phi_23 -= lr * P * np.outer((q_3 - (1+y)/2), x)\n",
    "    b_23 -= lr * P * (q_3 - (1+y)/2)\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    Phi_34 -= lr * P * np.outer((q_4 - (1+z)/2), y)\n",
    "    b_34 -= lr * P * (q_4 - (1+z)/2)\n",
    "    \n",
    "    return Phi_12,Phi_23,Phi_34,b_12,b_23,b_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 7.05102529e-01  6.26069193e-01  7.95061288e-01  9.01419682e-01\n",
      "  -7.22756204e-01 -2.42040134e-01 -3.92280783e-01 -2.80184466e-01\n",
      "   9.22555742e-01 -5.65406678e-01]\n",
      " [-2.59454401e-01  8.64604417e-01 -3.47682723e-01  5.61909817e-01\n",
      "   1.46555286e-02 -6.16142287e-01 -4.50243305e-01  4.04050480e-02\n",
      "  -1.57675767e-01 -4.99755039e-01]\n",
      " [ 3.06840199e-01  4.77436096e-01  4.90869947e-01  5.84732636e-01\n",
      "  -2.04451081e-01 -3.69956453e-01  4.38174539e-01 -8.05708452e-01\n",
      "  -5.32159765e-04 -7.98230974e-01]\n",
      " [-3.96145496e-01 -4.75327652e-01 -8.65171841e-01  3.33979957e-01\n",
      "  -6.67098783e-01 -8.65796254e-02 -4.22218221e-01 -5.76947734e-01\n",
      "   4.74630992e-01  1.51140057e-01]\n",
      " [-5.89002237e-01 -3.21318406e-01  3.84301678e-01  2.11395134e-01\n",
      "  -3.42103984e-01 -4.25283340e-01  8.16696276e-01  9.14081342e-01\n",
      "   3.68899447e-01 -1.50063317e-01]\n",
      " [ 6.71388080e-01  6.56442498e-01  9.70949694e-02 -9.60728972e-01\n",
      "   8.63143172e-01 -6.51643151e-01 -4.67817637e-01  3.84671715e-01\n",
      "  -6.83999543e-01 -5.13822679e-01]\n",
      " [ 5.15969091e-01 -4.92606858e-01 -2.12277681e-01 -5.90900327e-01\n",
      "  -6.22535030e-01  9.36873073e-01 -4.42989068e-01 -4.54325081e-01\n",
      "  -7.32555811e-02  3.82601550e-02]\n",
      " [ 3.97850311e-01  6.52988269e-01 -9.22961318e-01 -3.14548638e-01\n",
      "  -6.28633209e-01 -1.43649978e-01  1.15434450e-02 -9.11236479e-01\n",
      "   2.38972970e-01 -8.15261181e-01]]\n",
      "Phi_23: [[-0.71089817 -0.10730416 -0.23043083 -0.84224684 -0.96969821 -0.9606821\n",
      "  -0.81628136 -0.73454977]\n",
      " [-0.82084582  0.20971211 -0.31107893 -0.85202707 -0.17562631 -0.4730177\n",
      "  -0.82035153  0.80145555]\n",
      " [ 0.78972745 -0.80278463 -0.98325397 -0.02594333 -0.56100048  0.40012153\n",
      "   0.36894717  0.17574766]\n",
      " [-0.77727727  0.79136232 -0.27385468 -0.55069857  0.88384352 -0.06727927\n",
      "  -0.89269636  0.22647781]\n",
      " [ 0.64679706 -0.2352004  -0.25574075  0.64832943 -0.53938216  0.00849406\n",
      "   0.35118369  0.05494414]]\n",
      "Phi_34: [[ 0.85995233  0.58347174  0.06108945 -0.81192141 -0.27341971]\n",
      " [-0.71358848  0.78373632 -0.52844429  0.24857222  0.61357755]\n",
      " [-0.66497162 -0.76529193 -0.01221094 -0.81542065  0.25431108]]\n",
      "b_12: [[-0.48808397]\n",
      " [-0.11985584]\n",
      " [-0.49276619]\n",
      " [-0.36518059]\n",
      " [ 0.5984243 ]\n",
      " [-0.89235888]\n",
      " [ 0.71023814]\n",
      " [-0.13961722]]\n",
      "b_23: [[-1.0010018 ]\n",
      " [ 0.74494299]\n",
      " [-0.3836508 ]\n",
      " [ 0.14655156]\n",
      " [ 0.10751907]]\n",
      "b_34: [[-0.60428294]\n",
      " [ 0.40881712]\n",
      " [-0.56799491]]\n"
     ]
    }
   ],
   "source": [
    "Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_weighted(z_s,y_s,x_s,d_s,P,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta_weighted_batch(z,y,x,d,P,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size):\n",
    "    \n",
    "    q_2 = sigmoid(np.matmul(Phi_12,d) + b_12)\n",
    "    Phi_12 -= lr * np.matmul(P.reshape((1,-1)) * (q_2 - (1+x)/2), np.transpose(d))/batch_size\n",
    "    b_12 -= lr * np.matmul(q_2 - (1+x)/2, P.reshape((-1,1)))/batch_size\n",
    "    \n",
    "    q_3 = sigmoid(np.matmul(Phi_23,x) + b_23)\n",
    "    Phi_23 -= lr * np.matmul(P.reshape((1,-1)) * (q_3 - (1+y)/2), np.transpose(x))/batch_size\n",
    "    b_23 -= lr * np.matmul(q_3 - (1+y)/2, P.reshape((-1,1)))/batch_size\n",
    "    \n",
    "    q_4 = sigmoid(np.matmul(Phi_34,y) + b_34)\n",
    "    Phi_34 -= lr * np.matmul(P.reshape((1,-1)) * (q_4 - (1+z)/2), np.transpose(y))/batch_size\n",
    "    b_34 -= lr * np.matmul(q_4 - (1+z)/2, P.reshape((-1,1)))/batch_size\n",
    "    \n",
    "   \n",
    "    return Phi_12,Phi_23,Phi_34,b_12,b_23,b_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 7.05332011e-01  6.25898368e-01  7.95235797e-01  9.01178553e-01\n",
      "  -7.22939537e-01 -2.42190844e-01 -3.92105975e-01 -2.80000338e-01\n",
      "   9.22773956e-01 -5.65205370e-01]\n",
      " [-2.58720339e-01  8.63761124e-01 -3.46857943e-01  5.61198460e-01\n",
      "   1.38084497e-02 -6.16989980e-01 -4.49418757e-01  4.12462288e-02\n",
      "  -1.57003217e-01 -4.98910362e-01]\n",
      " [ 3.07300612e-01  4.76899924e-01  4.91423047e-01  5.84296137e-01\n",
      "  -2.05006574e-01 -3.70498822e-01  4.38727723e-01 -8.05151267e-01\n",
      "  -7.28680693e-05 -7.97683512e-01]\n",
      " [-3.96428846e-01 -4.74959305e-01 -8.65561179e-01  3.34274492e-01\n",
      "  -6.66664187e-01 -8.61870787e-02 -4.22607450e-01 -5.77384922e-01\n",
      "   4.74347085e-01  1.50719295e-01]\n",
      " [-5.89642154e-01 -3.20509379e-01  3.83454513e-01  2.12030191e-01\n",
      "  -3.41264479e-01 -4.24476907e-01  8.15849190e-01  9.13230435e-01\n",
      "   3.68212458e-01 -1.50896540e-01]\n",
      " [ 6.71592203e-01  6.56089354e-01  9.74879482e-02 -9.60980088e-01\n",
      "   8.62731089e-01 -6.51997829e-01 -4.67424401e-01  3.85073580e-01\n",
      "  -6.83726952e-01 -5.13411129e-01]\n",
      " [ 5.15689679e-01 -4.92303872e-01 -2.12543583e-01 -5.90560119e-01\n",
      "  -6.22268785e-01  9.37154471e-01 -4.43255044e-01 -4.54591968e-01\n",
      "  -7.35473793e-02  3.79827842e-02]\n",
      " [ 3.98465622e-01  6.52194957e-01 -9.22131104e-01 -3.15072022e-01\n",
      "  -6.29427042e-01 -1.44435573e-01  1.23734651e-02 -9.10431839e-01\n",
      "   2.39570009e-01 -8.14468010e-01]]\n",
      "Phi_23: [[-0.71066004 -0.10700999 -0.23017124 -0.84251293 -0.96991917 -0.96044412\n",
      "  -0.81651166 -0.73429026]\n",
      " [-0.82052206  0.21004273 -0.31073503 -0.85235363 -0.17591972 -0.47273162\n",
      "  -0.82066474  0.8017991 ]\n",
      " [ 0.78927081 -0.80322806 -0.98372521 -0.02545106 -0.56045737  0.39959522\n",
      "   0.36944427  0.17527637]\n",
      " [-0.77764353  0.79076317 -0.27437158 -0.55014986  0.88440348 -0.06786123\n",
      "  -0.8921055   0.22596114]\n",
      " [ 0.64722975 -0.23459313 -0.25515525  0.64771598 -0.53994394  0.009074\n",
      "   0.35064895  0.05552989]]\n",
      "Phi_34: [[ 0.8590768   0.58264281  0.0619807  -0.81103037 -0.27430022]\n",
      " [-0.71330376  0.78400597 -0.52867316  0.24831746  0.61383196]\n",
      " [-0.66550437 -0.7658122  -0.01171794 -0.81489945  0.25378646]]\n",
      "b_12: [[-0.4882682 ]\n",
      " [-0.12069719]\n",
      " [-0.49332323]\n",
      " [-0.36474332]\n",
      " [ 0.59927528]\n",
      " [-0.89276079]\n",
      " [ 0.71050496]\n",
      " [-0.14042196]]\n",
      "b_23: [[-1.0012679 ]\n",
      " [ 0.74461643]\n",
      " [-0.38315854]\n",
      " [ 0.14710027]\n",
      " [ 0.10690562]]\n",
      "b_34: [[-0.60340977]\n",
      " [ 0.40855985]\n",
      " [-0.5674786 ]]\n"
     ]
    }
   ],
   "source": [
    "Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_weighted_batch(z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size)\n",
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: We use 256 generated samples in well-formed set to train a baseline using traditional training mathod proposed in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 10)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_formed_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = np.transpose(well_formed_set)\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 3\n",
    "n_y = 5\n",
    "n_x = 8\n",
    "n_d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "\n",
    "Phi_12 = np.random.rand(n_x,n_d) *2-1\n",
    "Phi_23 = np.random.rand(n_y,n_x) *2-1\n",
    "Phi_34 = np.random.rand(n_z,n_y) *2-1\n",
    "b_12 = np.random.rand(n_x,1) *2-1\n",
    "b_23 = np.random.rand(n_y,1) *2-1\n",
    "b_34 = np.random.rand(n_z,1) *2-1\n",
    "\n",
    "Theta = np.random.rand(n_z,1) *2-1\n",
    "Theta_43 = np.random.rand(n_y,n_z) *2-1\n",
    "Theta_32 = np.random.rand(n_x,n_y) *2-1\n",
    "Theta_21 = np.random.rand(n_d,n_x) *2-1\n",
    "b_43 = np.random.rand(n_y,1) *2-1\n",
    "b_32 = np.random.rand(n_x,1) *2-1\n",
    "b_21 = np.random.rand(n_d,1) *2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero initialization\n",
    "\n",
    "Phi_12 = np.zeros((n_x,n_d))\n",
    "Phi_23 = np.zeros((n_y,n_x))\n",
    "Phi_34 = np.zeros((n_z,n_y))\n",
    "b_12 = np.zeros((n_x,1))\n",
    "b_23 = np.zeros((n_y,1))\n",
    "b_34 = np.zeros((n_z,1))\n",
    "\n",
    "Theta = np.zeros((n_z,1))\n",
    "Theta_43 = np.zeros((n_y,n_z))\n",
    "Theta_32 = np.zeros((n_x,n_y))\n",
    "Theta_21 = np.zeros((n_d,n_x))\n",
    "b_43 = np.zeros((n_y,1))\n",
    "b_32 = np.zeros((n_x,1))\n",
    "b_21 = np.zeros((n_d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[-0.36269865  0.89407533 -0.78074121 -0.9085969   0.47307659 -0.34640879\n",
      "   0.08171577  0.66733834  0.18454457 -0.60455422]\n",
      " [-0.60592004 -0.91193836  0.63429869  0.40945908 -0.38371037 -0.15356147\n",
      "  -0.98635784  0.38954447 -0.77398635  0.99572635]\n",
      " [ 0.33387673  0.82140252 -0.01810539 -0.53822077 -0.31279443  0.37863088\n",
      "  -0.55638973 -0.07558082  0.67041084  0.65177607]\n",
      " [ 0.27932081  0.34928344 -0.81500528 -0.95974793  0.91912164 -0.18830971\n",
      "  -0.29256261 -0.08350745 -0.21755799  0.21878296]\n",
      " [ 0.54457568  0.51153638  0.29364467 -0.00137909 -0.34237242 -0.17317923\n",
      "   0.41944222 -0.1848451   0.49615004 -0.30065137]\n",
      " [-0.91697482  0.14440993  0.11931615 -0.94889851 -0.66504829 -0.64973526\n",
      "  -0.30273211 -0.39856389 -0.51251448 -0.72069941]\n",
      " [ 0.54245289 -0.56743709 -0.61365155 -0.54640114 -0.56762551 -0.20997043\n",
      "   0.03250334  0.25735658 -0.38261971 -0.87738157]\n",
      " [ 0.57142081 -0.56336828 -0.48998499 -0.36152764 -0.87118957 -0.74620482\n",
      "  -0.60382577 -0.41740661  0.75410792 -0.80914061]]\n",
      "Phi_23: [[-0.51169509 -0.47267982 -0.68709956  0.64594331  0.73770083 -0.38481322\n",
      "  -0.28513975 -0.49812355]\n",
      " [-0.74170818 -0.60679858  0.40113898  0.84101581 -0.173035    0.26472782\n",
      "   0.19191218  0.98115126]\n",
      " [-0.78651811 -0.08953365  0.49099531 -0.98806771  0.86187574  0.93107007\n",
      "   0.89002005  0.74932772]\n",
      " [-0.76723556 -0.32894672 -0.6438909   0.25553489  0.82041744 -0.45256158\n",
      "  -0.28702134 -0.13914199]\n",
      " [ 0.95099898 -0.96551045 -0.37548306 -0.55215358 -0.74912821  0.43332053\n",
      "   0.20686124  0.40845032]]\n",
      "Phi_34: [[-0.73826421  0.10451433  0.20169222 -0.21593244 -0.78056045]\n",
      " [ 0.69936612 -0.69885849  0.60325144 -0.91367368  0.68585433]\n",
      " [-0.49106356  0.95413711  0.91214547 -0.62387468  0.00667407]]\n",
      "b_12: [[ 0.48597002]\n",
      " [ 0.81950205]\n",
      " [ 0.63943941]\n",
      " [ 0.23242025]\n",
      " [ 0.20763274]\n",
      " [-0.92824124]\n",
      " [-0.21409227]\n",
      " [ 0.65926027]]\n",
      "b_23: [[-0.31232611]\n",
      " [ 0.14260604]\n",
      " [ 0.02927784]\n",
      " [-0.23686978]\n",
      " [-0.49416251]]\n",
      "b_34: [[0.97185086]\n",
      " [0.6109076 ]\n",
      " [0.05029158]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[-0.97082694]\n",
      " [-0.56578044]\n",
      " [-0.80671329]]\n",
      "Theta_43: [[-0.46530804  0.06910619  0.80919499]\n",
      " [ 0.51894606 -0.59611203 -0.73200645]\n",
      " [-0.21750814  0.38857122  0.75174856]\n",
      " [ 0.55688127 -0.05844833 -0.82928573]\n",
      " [ 0.17837977  0.11063671  0.81923425]]\n",
      "Theta_32: [[-0.78137304  0.64239397  0.07243662 -0.25736197  0.11619475]\n",
      " [ 0.94162062 -0.07192714 -0.06958583  0.31732883  0.63248108]\n",
      " [ 0.56455673  0.01757698 -0.47370764 -0.99182941 -0.83338552]\n",
      " [-0.40465956 -0.03710654 -0.49672684 -0.33317992 -0.53654296]\n",
      " [-0.62970959 -0.69844212  0.52770212  0.57504246 -0.65145038]\n",
      " [ 0.97770136 -0.39003214  0.76222649 -0.87462203 -0.74379525]\n",
      " [ 0.23016752  0.47886679 -0.31939635 -0.72761344  0.87212058]\n",
      " [-0.34700673 -0.86133984  0.43733292  0.38130027 -0.98057296]]\n",
      "Theta_21: [[-0.72892024 -0.49753869  0.81181981  0.41622254  0.03771239 -0.650321\n",
      "  -0.71297175 -0.25102488]\n",
      " [-0.51854293 -0.76264014  0.40055592 -0.51373024  0.79439456  0.91378351\n",
      "  -0.87975956 -0.47856546]\n",
      " [-0.34723186 -0.50548674  0.17521953  0.74762547  0.40208945  0.04571007\n",
      "   0.14077427  0.90143915]\n",
      " [ 0.05694383 -0.21049998  0.88730622 -0.20540627  0.64296459  0.97088206\n",
      "   0.74102218 -0.12419722]\n",
      " [-0.81263505  0.94695643  0.65060239  0.53961796 -0.32057196 -0.93232032\n",
      "  -0.40268112  0.56208189]\n",
      " [ 0.88960679 -0.22170322 -0.50805402  0.96326324 -0.15494797 -0.69937622\n",
      "  -0.2314132   0.65482468]\n",
      " [-0.14432835  0.53511531  0.91834908  0.13498024 -0.591378   -0.14203535\n",
      "   0.89783594  0.04525793]\n",
      " [-0.17480399  0.75797211  0.35755573 -0.29275082 -0.44458916 -0.37181901\n",
      "  -0.0895159   0.96819674]\n",
      " [-0.66809464 -0.4331724  -0.91475411  0.44778613 -0.98735874 -0.1595233\n",
      "   0.02232508 -0.68159076]\n",
      " [-0.36702236 -0.53082942  0.17582096  0.01041391 -0.12637363  0.6410777\n",
      "   0.36875904  0.79508466]]\n",
      "b_43: [[ 0.30350384]\n",
      " [ 0.0128515 ]\n",
      " [-0.01943811]\n",
      " [-0.06486581]\n",
      " [ 0.64530483]]\n",
      "b_32: [[-0.1196926 ]\n",
      " [ 0.04589848]\n",
      " [ 0.65818617]\n",
      " [ 0.57518362]\n",
      " [-0.88842869]\n",
      " [-0.22553907]\n",
      " [ 0.69591558]\n",
      " [-0.0450056 ]]\n",
      "b_21: [[-0.00246655]\n",
      " [ 0.38941308]\n",
      " [-0.62445601]\n",
      " [ 0.72163168]\n",
      " [ 0.68164331]\n",
      " [ 0.58459644]\n",
      " [ 0.47139645]\n",
      " [-0.14993822]\n",
      " [-0.50672472]\n",
      " [-0.77480172]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_12_cache = np.copy(Phi_12)\n",
    "Phi_23_cache = np.copy(Phi_23)\n",
    "Phi_34_cache = np.copy(Phi_34)\n",
    "b_12_cache = np.copy(b_12)\n",
    "b_23_cache = np.copy(b_23)\n",
    "b_34_cache = np.copy(b_34)\n",
    "\n",
    "Theta_cache = np.copy(Theta)\n",
    "Theta_43_cache = np.copy(Theta_43)\n",
    "Theta_32_cache = np.copy(Theta_32)\n",
    "Theta_21_cache = np.copy(Theta_21)\n",
    "b_43_cache = np.copy(b_43)\n",
    "b_32_cache = np.copy(b_32)\n",
    "b_21_cache = np.copy(b_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recog_phi: 0.6115233587091153\n",
      "recog_b: 0.05196038648331658\n",
      "gener_theta: 1.1053306682011572\n",
      "gener_b: 0.9325376006996552\n",
      "\n",
      "recog_phi: 0.45634679846066056\n",
      "recog_b: 0.05559485845129042\n",
      "gener_theta: 0.898503641420925\n",
      "gener_b: 0.6789620287678042\n",
      "\n",
      "recog_phi: 0.5994211023053237\n",
      "recog_b: 0.04851267070791189\n",
      "gener_theta: 0.7526419782306422\n",
      "gener_b: 0.7534203530989925\n",
      "\n",
      "recog_phi: 0.4125470852644962\n",
      "recog_b: 0.05516666588797189\n",
      "gener_theta: 0.7200607136091748\n",
      "gener_b: 0.8692110746186464\n",
      "\n",
      "recog_phi: 0.5892958256253538\n",
      "recog_b: 0.045378010919591025\n",
      "gener_theta: 0.8302167794487738\n",
      "gener_b: 0.7493198769036344\n",
      "\n",
      "recog_phi: 0.631544570776467\n",
      "recog_b: 0.029912844901708813\n",
      "gener_theta: 0.5658562209633506\n",
      "gener_b: 0.30630593099855363\n",
      "\n",
      "recog_phi: 0.6452502720943883\n",
      "recog_b: 0.08453958088742428\n",
      "gener_theta: 0.6226291394631347\n",
      "gener_b: 0.2561247260224115\n",
      "\n",
      "recog_phi: 0.49526285915894763\n",
      "recog_b: 0.05450681403284786\n",
      "gener_theta: 0.8898096366508254\n",
      "gener_b: 0.7483248678991568\n",
      "\n",
      "recog_phi: 0.4687913835342336\n",
      "recog_b: 0.05308580619211781\n",
      "gener_theta: 0.7581530021084144\n",
      "gener_b: 1.0172958007705437\n",
      "\n",
      "recog_phi: 0.6471906629541235\n",
      "recog_b: 0.08163110698318078\n",
      "gener_theta: 0.9158189617831785\n",
      "gener_b: 0.8866069722032934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample-based training\n",
    "# Local delta rule\n",
    "for e in range(epoch):\n",
    "    for i in range(train_set.shape[1]):\n",
    "        data = train_set[:,i:i+1]\n",
    "        q_2,q_3,q_4,x_w,y_w,z_w,Q = wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z)\n",
    "        Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta(z_w,y_w,x_w,data,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "        p_4,p_3,p_2,p_1,z_s,y_s,x_s,d_s,P = sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d)\n",
    "        Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta(z_s,y_s,x_s,d_s,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "\n",
    "    recog_phi = np.sum((Phi_12 - Phi_12_cache)**2) + np.sum((Phi_23 - Phi_23_cache)**2) + np.sum((Phi_34 - Phi_34_cache)**2) \n",
    "    recog_b = np.sum((b_12 - b_12_cache)**2) + np.sum((b_23 - b_23_cache)**2) + np.sum((b_34 - b_34_cache)**2)\n",
    "    gener_theta = np.sum((Theta - Theta_cache)**2) + np.sum((Theta_43 - Theta_43_cache)**2) + np.sum((Theta_32 - Theta_32_cache)**2) + np.sum((Theta_21 - Theta_21_cache)**2)\n",
    "    gener_b = np.sum((b_43 - b_43_cache)**2) + np.sum((b_32 - b_32_cache)**2) + np.sum((b_21 - b_21_cache)**2)\n",
    "    print (\"recog_phi: \" + str(recog_phi))\n",
    "    print (\"recog_b: \" + str(recog_b))\n",
    "    print (\"gener_theta: \" + str(gener_theta))\n",
    "    print (\"gener_b: \" + str(gener_b))\n",
    "    print('')\n",
    "    \n",
    "    Phi_12_cache = np.copy(Phi_12)\n",
    "    Phi_23_cache = np.copy(Phi_23)\n",
    "    Phi_34_cache = np.copy(Phi_34)\n",
    "    b_12_cache = np.copy(b_12)\n",
    "    b_23_cache = np.copy(b_23)\n",
    "    b_34_cache = np.copy(b_34)\n",
    "\n",
    "    Theta_cache = np.copy(Theta)\n",
    "    Theta_43_cache = np.copy(Theta_43)\n",
    "    Theta_32_cache = np.copy(Theta_32)\n",
    "    Theta_21_cache = np.copy(Theta_21)\n",
    "    b_43_cache = np.copy(b_43)\n",
    "    b_32_cache = np.copy(b_32)\n",
    "    b_21_cache = np.copy(b_21)\n",
    "    \n",
    "    np.random.shuffle(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_12: [[ 0.25817555  0.3164928  -1.02703235  0.29891417  0.07946648 -0.37401944\n",
      "  -0.15915869 -0.06772254  0.18613879  0.1644277 ]\n",
      " [ 0.36952015  0.10375914 -0.20158691  0.08880081 -0.36772491  0.13143094\n",
      "  -0.57350717 -0.16661315 -0.41672413  0.75439095]\n",
      " [ 0.15901325 -0.21374134  0.32548336  0.65453622  0.33200995 -0.25354196\n",
      "  -0.41417159 -0.93715205  0.281141    0.17139529]\n",
      " [ 0.02581285 -0.40217983 -0.30655154 -0.29362177  0.15646529  0.48912374\n",
      "  -0.67693102  0.54534813  0.27854937 -0.28270075]\n",
      " [ 0.15891551  0.06377039  0.39247674  0.92839659 -0.03732773 -0.27543192\n",
      "  -0.09174925  0.21518005 -0.49557417 -0.25282927]\n",
      " [-0.37051913 -0.0585297  -0.15334527 -0.22364293  0.72180331  0.00891843\n",
      "  -0.00593579  0.07698222 -0.26579795 -0.0372252 ]\n",
      " [-0.23354202 -0.27331169 -0.27278212  0.50034928 -0.11686393  0.25778282\n",
      "   0.62880932 -0.37494928 -0.22792936 -0.57415906]\n",
      " [-0.29712824  0.07653468 -0.20118     0.38876564 -0.19659231  0.08879732\n",
      "   0.00725532  0.02123035 -0.3228604   0.15023519]]\n",
      "Phi_23: [[-0.18416232 -0.83947906 -0.11733564  0.10260526  0.18635425  0.41288648\n",
      "   0.1248552  -0.01727068]\n",
      " [ 0.16410168 -0.0554898  -0.20828354 -0.6948243   0.08324574 -0.10236856\n",
      "   0.12559975  0.55682057]\n",
      " [ 0.2817214   0.15595789  0.15188498  0.49217122  0.08588768  0.13663502\n",
      "   0.42076991  0.51897757]\n",
      " [-0.20409528  0.47595523 -0.4591171   0.36430589 -0.18837524  0.18115648\n",
      "  -0.61956855  0.38402645]\n",
      " [-0.19563977  0.42937312  0.73844413 -0.60192571  0.52842916 -0.070702\n",
      "  -0.087978    0.49040594]]\n",
      "Phi_34: [[-0.48806004 -0.66069567 -0.58565881  0.2785197  -0.46967813]\n",
      " [-0.75443185 -0.0804032   0.34939846  0.38319868  0.20462342]\n",
      " [-0.19639402  0.31913075 -0.13155426 -0.0565233   0.07523903]]\n",
      "b_12: [[ 0.18155199]\n",
      " [-0.22124759]\n",
      " [ 0.12424214]\n",
      " [-1.15288441]\n",
      " [ 0.22755371]\n",
      " [-0.35148196]\n",
      " [ 0.11440324]\n",
      " [ 0.17378854]]\n",
      "b_12_cache: [[ 0.18155199]\n",
      " [-0.22124759]\n",
      " [ 0.12424214]\n",
      " [-1.15288441]\n",
      " [ 0.22755371]\n",
      " [-0.35148196]\n",
      " [ 0.11440324]\n",
      " [ 0.17378854]]\n",
      "b_23: [[-0.90992049]\n",
      " [-0.20646201]\n",
      " [ 0.91935752]\n",
      " [ 1.02527498]\n",
      " [-0.32635762]]\n",
      "b_34: [[ 0.10266909]\n",
      " [-0.12687832]\n",
      " [ 0.07842927]]\n",
      "Phi_12_cache: [[ 0.25817555  0.3164928  -1.02703235  0.29891417  0.07946648 -0.37401944\n",
      "  -0.15915869 -0.06772254  0.18613879  0.1644277 ]\n",
      " [ 0.36952015  0.10375914 -0.20158691  0.08880081 -0.36772491  0.13143094\n",
      "  -0.57350717 -0.16661315 -0.41672413  0.75439095]\n",
      " [ 0.15901325 -0.21374134  0.32548336  0.65453622  0.33200995 -0.25354196\n",
      "  -0.41417159 -0.93715205  0.281141    0.17139529]\n",
      " [ 0.02581285 -0.40217983 -0.30655154 -0.29362177  0.15646529  0.48912374\n",
      "  -0.67693102  0.54534813  0.27854937 -0.28270075]\n",
      " [ 0.15891551  0.06377039  0.39247674  0.92839659 -0.03732773 -0.27543192\n",
      "  -0.09174925  0.21518005 -0.49557417 -0.25282927]\n",
      " [-0.37051913 -0.0585297  -0.15334527 -0.22364293  0.72180331  0.00891843\n",
      "  -0.00593579  0.07698222 -0.26579795 -0.0372252 ]\n",
      " [-0.23354202 -0.27331169 -0.27278212  0.50034928 -0.11686393  0.25778282\n",
      "   0.62880932 -0.37494928 -0.22792936 -0.57415906]\n",
      " [-0.29712824  0.07653468 -0.20118     0.38876564 -0.19659231  0.08879732\n",
      "   0.00725532  0.02123035 -0.3228604   0.15023519]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Phi_12: \" + str(Phi_12))\n",
    "print (\"Phi_23: \" + str(Phi_23))\n",
    "print (\"Phi_34: \" + str(Phi_34))\n",
    "print (\"b_12: \" + str(b_12))\n",
    "print (\"b_12_cache: \" + str(b_12_cache))\n",
    "print (\"b_23: \" + str(b_23))\n",
    "print (\"b_34: \" + str(b_34))\n",
    "print (\"Phi_12_cache: \" + str(Phi_12_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[ 0.10810326]\n",
      " [ 0.35930207]\n",
      " [-0.31405824]]\n",
      "Theta_43: [[-0.09575273  0.14007702 -0.39469428]\n",
      " [ 0.44650337  0.28564228  0.52337354]\n",
      " [ 0.24678362  0.51557779 -0.90670904]\n",
      " [ 0.49337953 -0.37200851  0.56883611]\n",
      " [-0.24565591  0.22592884  0.76289209]]\n",
      "Theta_32: [[-0.38991613  0.40975452 -0.25297272 -0.13736693  0.03465881]\n",
      " [ 0.16633522  0.42036017 -0.46594193  0.18229528 -0.04399158]\n",
      " [ 0.70085579  0.9517073   0.11474516  0.35057096 -0.0607529 ]\n",
      " [ 0.34409427 -0.2085122   0.45461835  0.01078571  0.48475153]\n",
      " [-0.10280801 -0.3667067   0.03267916  0.24170922 -0.45970471]\n",
      " [ 0.04159141  0.28744414 -0.72313816 -0.42226192 -0.16174755]\n",
      " [-0.12434905 -0.32674417 -0.21529194 -0.05896704  0.39738625]\n",
      " [-0.16669404  0.0938111   0.52784378 -0.08935549 -0.37406569]]\n",
      "Theta_21: [[ 0.19241651 -0.41044561  0.05779248  0.0997436   0.01223997  0.12874296\n",
      "  -0.07624183 -0.26322726]\n",
      " [-0.786116   -0.07383121  0.69068188  0.03278605  0.49494039 -0.2110568\n",
      "   0.4087714  -0.33534604]\n",
      " [ 0.18399694 -0.33757753 -0.31018414  0.27157082 -0.4230767   0.15091332\n",
      "   0.31470535 -0.37975974]\n",
      " [-0.33413979 -0.58860248 -0.60150399  0.20779774  0.35725625 -0.51866156\n",
      "   0.37333045 -0.240898  ]\n",
      " [ 0.95257738 -0.08468186  0.39790311 -0.01472309 -0.07078849  0.81853819\n",
      "  -0.39620933 -0.25259619]\n",
      " [-0.34589091 -0.37253326  0.45202376  0.27629156 -0.96753596  0.11015504\n",
      "  -0.05723039 -0.2955055 ]\n",
      " [-0.19728337  0.25084107  0.55741491 -0.50182226 -0.09966223  0.14902966\n",
      "   0.11004866  0.16716212]\n",
      " [ 0.68497661 -0.63726627 -0.78043342 -0.04567493 -0.14236039 -0.26457858\n",
      "   0.13176392  0.56445483]\n",
      " [-0.0686061  -0.68523033  0.24280832 -0.84877921  0.79420212 -0.68829042\n",
      "  -0.71938406  0.69815879]\n",
      " [-0.368984    0.0273707  -0.89256688  0.38145053  0.44146845 -0.18857207\n",
      "   0.5388895  -0.25057731]]\n",
      "b_43: [[ 0.21785839]\n",
      " [ 0.05317594]\n",
      " [ 0.41866548]\n",
      " [-0.62627398]\n",
      " [-0.7111807 ]]\n",
      "b_32: [[ 0.37999304]\n",
      " [-0.56521584]\n",
      " [-0.55735933]\n",
      " [-0.313464  ]\n",
      " [ 0.61429093]\n",
      " [-0.70793749]\n",
      " [ 0.28337246]\n",
      " [ 0.64042017]]\n",
      "b_21: [[ 0.52021799]\n",
      " [ 0.77490295]\n",
      " [ 0.29055637]\n",
      " [-0.13016904]\n",
      " [ 0.28119751]\n",
      " [ 0.1631581 ]\n",
      " [-0.31424871]\n",
      " [ 0.10521457]\n",
      " [ 0.16561028]\n",
      " [-0.4208121 ]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Theta: \" + str(Theta))\n",
    "print (\"Theta_43: \" + str(Theta_43))\n",
    "print (\"Theta_32: \" + str(Theta_32))\n",
    "print (\"Theta_21: \" + str(Theta_21))\n",
    "print (\"b_43: \" + str(b_43))\n",
    "print (\"b_32: \" + str(b_32))\n",
    "print (\"b_21: \" + str(b_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection of Functions\n",
    "1. q_2,q_3,q_4,x_w,y_w,z_w,Q = wake_forward(data,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z)\n",
    "2. p_4,p_3,p_2,p_1,z_s,y_s,x_s,d_s,P = sleep_forward(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d)\n",
    "3. Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta(z_w,y_w,x_w,data,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "4. Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta(z_s,y_s,x_s,d_s,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "5. Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_weighted(z_w,y_w,x_w,data,Q,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr)\n",
    "6. Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_weighted(z_s,y_s,x_s,d_s,P,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr)\n",
    "\n",
    "\n",
    "1. q_2_batch,q_3_batch,q_4_batch,x_w_batch,y_w_batch,z_w_batch,Q_batch = wake_forward_batch(data_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,n_x,n_y,n_z,batch_size)\n",
    "2. p_4_batch,p_3_batch,p_2_batch,p_1_batch,z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch = sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size)\n",
    "3. Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_batch(z_w_batch,y_w_batch,x_w_batch,data_batch,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size)\n",
    "4. Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_batch(z_s_batch,y_s_batch,x_s_batch,d_s_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size)\n",
    "5. Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21 = wake_update_delta_weighted_batch(z_w_batch,y_w_batch,x_w_batch,data_batch,Q_batch,Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,lr,batch_size)\n",
    "6. Phi_12,Phi_23,Phi_34,b_12,b_23,b_34 = sleep_update_delta_weighted_batch(z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch,Phi_12,Phi_23,Phi_34,b_12,b_23,b_34,lr,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4_batch: [[0.51993293]\n",
      " [0.5533909 ]\n",
      " [0.51478194]]\n",
      "p_3_batch: [[0.18033514 0.28154926 0.38576719 0.18033514 0.42953435 0.42953435\n",
      "  0.15505819 0.42953435 0.18033514 0.57286198 0.42953435 0.3196456\n",
      "  0.15505819 0.42953435 0.57286198 0.38576719 0.42953435 0.3196456\n",
      "  0.15505819 0.3196456  0.57286198 0.38576719 0.28154926 0.61654909\n",
      "  0.28154926 0.15505819 0.18033514 0.42953435 0.28154926 0.18033514\n",
      "  0.42953435 0.18033514 0.38576719 0.42953435 0.18033514 0.15505819\n",
      "  0.57286198 0.61654909 0.15505819 0.3196456  0.57286198 0.42953435\n",
      "  0.28154926 0.28154926 0.15505819 0.18033514 0.15505819 0.3196456\n",
      "  0.57286198 0.61654909 0.15505819 0.18033514 0.38576719 0.61654909\n",
      "  0.38576719 0.28154926 0.57286198 0.3196456  0.61654909 0.61654909\n",
      "  0.57286198 0.15505819 0.57286198 0.18033514 0.3196456  0.3196456\n",
      "  0.61654909 0.3196456  0.61654909 0.57286198 0.28154926 0.15505819\n",
      "  0.57286198 0.18033514 0.57286198 0.3196456  0.3196456  0.61654909\n",
      "  0.28154926 0.15505819 0.3196456  0.28154926 0.18033514 0.42953435\n",
      "  0.15505819 0.28154926 0.15505819 0.61654909 0.38576719 0.15505819\n",
      "  0.28154926 0.42953435 0.28154926 0.38576719 0.28154926 0.18033514\n",
      "  0.3196456  0.15505819 0.18033514 0.38576719]\n",
      " [0.28678057 0.77874084 0.52676932 0.28678057 0.31002169 0.31002169\n",
      "  0.49903146 0.31002169 0.28678057 0.7972828  0.31002169 0.58689545\n",
      "  0.49903146 0.31002169 0.7972828  0.52676932 0.31002169 0.58689545\n",
      "  0.49903146 0.58689545 0.7972828  0.52676932 0.77874084 0.61353593\n",
      "  0.77874084 0.49903146 0.28678057 0.31002169 0.77874084 0.28678057\n",
      "  0.31002169 0.28678057 0.52676932 0.31002169 0.28678057 0.49903146\n",
      "  0.7972828  0.61353593 0.49903146 0.58689545 0.7972828  0.31002169\n",
      "  0.77874084 0.77874084 0.49903146 0.28678057 0.49903146 0.58689545\n",
      "  0.7972828  0.61353593 0.49903146 0.28678057 0.52676932 0.61353593\n",
      "  0.52676932 0.77874084 0.7972828  0.58689545 0.61353593 0.61353593\n",
      "  0.7972828  0.49903146 0.7972828  0.28678057 0.58689545 0.58689545\n",
      "  0.61353593 0.58689545 0.61353593 0.7972828  0.77874084 0.49903146\n",
      "  0.7972828  0.28678057 0.7972828  0.58689545 0.58689545 0.61353593\n",
      "  0.77874084 0.49903146 0.58689545 0.77874084 0.28678057 0.31002169\n",
      "  0.49903146 0.77874084 0.49903146 0.61353593 0.52676932 0.49903146\n",
      "  0.77874084 0.31002169 0.77874084 0.52676932 0.77874084 0.28678057\n",
      "  0.58689545 0.49903146 0.28678057 0.52676932]\n",
      " [0.64983362 0.79399784 0.39273011 0.64983362 0.49606654 0.49606654\n",
      "  0.5493863  0.49606654 0.64983362 0.67153856 0.49606654 0.85437192\n",
      "  0.5493863  0.49606654 0.67153856 0.39273011 0.49606654 0.85437192\n",
      "  0.5493863  0.85437192 0.67153856 0.39273011 0.79399784 0.75680987\n",
      "  0.79399784 0.5493863  0.64983362 0.49606654 0.79399784 0.64983362\n",
      "  0.49606654 0.64983362 0.39273011 0.49606654 0.64983362 0.5493863\n",
      "  0.67153856 0.75680987 0.5493863  0.85437192 0.67153856 0.49606654\n",
      "  0.79399784 0.79399784 0.5493863  0.64983362 0.5493863  0.85437192\n",
      "  0.67153856 0.75680987 0.5493863  0.64983362 0.39273011 0.75680987\n",
      "  0.39273011 0.79399784 0.67153856 0.85437192 0.75680987 0.75680987\n",
      "  0.67153856 0.5493863  0.67153856 0.64983362 0.85437192 0.85437192\n",
      "  0.75680987 0.85437192 0.75680987 0.67153856 0.79399784 0.5493863\n",
      "  0.67153856 0.64983362 0.67153856 0.85437192 0.85437192 0.75680987\n",
      "  0.79399784 0.5493863  0.85437192 0.79399784 0.64983362 0.49606654\n",
      "  0.5493863  0.79399784 0.5493863  0.75680987 0.39273011 0.5493863\n",
      "  0.79399784 0.49606654 0.79399784 0.39273011 0.79399784 0.64983362\n",
      "  0.85437192 0.5493863  0.64983362 0.39273011]\n",
      " [0.78175682 0.64054615 0.58763236 0.78175682 0.62517404 0.62517404\n",
      "  0.75371998 0.62517404 0.78175682 0.45347743 0.62517404 0.67592724\n",
      "  0.75371998 0.62517404 0.45347743 0.58763236 0.62517404 0.67592724\n",
      "  0.75371998 0.67592724 0.45347743 0.58763236 0.64054615 0.4926885\n",
      "  0.64054615 0.75371998 0.78175682 0.62517404 0.64054615 0.78175682\n",
      "  0.62517404 0.78175682 0.58763236 0.62517404 0.78175682 0.75371998\n",
      "  0.45347743 0.4926885  0.75371998 0.67592724 0.45347743 0.62517404\n",
      "  0.64054615 0.64054615 0.75371998 0.78175682 0.75371998 0.67592724\n",
      "  0.45347743 0.4926885  0.75371998 0.78175682 0.58763236 0.4926885\n",
      "  0.58763236 0.64054615 0.45347743 0.67592724 0.4926885  0.4926885\n",
      "  0.45347743 0.75371998 0.45347743 0.78175682 0.67592724 0.67592724\n",
      "  0.4926885  0.67592724 0.4926885  0.45347743 0.64054615 0.75371998\n",
      "  0.45347743 0.78175682 0.45347743 0.67592724 0.67592724 0.4926885\n",
      "  0.64054615 0.75371998 0.67592724 0.64054615 0.78175682 0.62517404\n",
      "  0.75371998 0.64054615 0.75371998 0.4926885  0.58763236 0.75371998\n",
      "  0.64054615 0.62517404 0.64054615 0.58763236 0.64054615 0.78175682\n",
      "  0.67592724 0.75371998 0.78175682 0.58763236]\n",
      " [0.37053407 0.69996027 0.34302379 0.37053407 0.29024455 0.29024455\n",
      "  0.42908686 0.29024455 0.37053407 0.61841788 0.29024455 0.64628751\n",
      "  0.42908686 0.29024455 0.61841788 0.34302379 0.29024455 0.64628751\n",
      "  0.42908686 0.64628751 0.61841788 0.34302379 0.69996027 0.55934143\n",
      "  0.69996027 0.42908686 0.37053407 0.29024455 0.69996027 0.37053407\n",
      "  0.29024455 0.37053407 0.34302379 0.29024455 0.37053407 0.42908686\n",
      "  0.61841788 0.55934143 0.42908686 0.64628751 0.61841788 0.29024455\n",
      "  0.69996027 0.69996027 0.42908686 0.37053407 0.42908686 0.64628751\n",
      "  0.61841788 0.55934143 0.42908686 0.37053407 0.34302379 0.55934143\n",
      "  0.34302379 0.69996027 0.61841788 0.64628751 0.55934143 0.55934143\n",
      "  0.61841788 0.42908686 0.61841788 0.37053407 0.64628751 0.64628751\n",
      "  0.55934143 0.64628751 0.55934143 0.61841788 0.69996027 0.42908686\n",
      "  0.61841788 0.37053407 0.61841788 0.64628751 0.64628751 0.55934143\n",
      "  0.69996027 0.42908686 0.64628751 0.69996027 0.37053407 0.29024455\n",
      "  0.42908686 0.69996027 0.42908686 0.55934143 0.34302379 0.42908686\n",
      "  0.69996027 0.29024455 0.69996027 0.34302379 0.69996027 0.37053407\n",
      "  0.64628751 0.42908686 0.37053407 0.34302379]]\n",
      "p_2_batch: [[0.67338169 0.3504963  0.3504963  0.60026252 0.2649983  0.44838505\n",
      "  0.73312206 0.2649983  0.64730862 0.62586788 0.59826474 0.69207755\n",
      "  0.3504963  0.39942329 0.57782706 0.47728873 0.54923229 0.4487502\n",
      "  0.75524991 0.57782706 0.3504963  0.3504963  0.62781379 0.4276175\n",
      "  0.75524991 0.4988556  0.73312206 0.54886679 0.75524991 0.2649983\n",
      "  0.4276175  0.49873726 0.39742937 0.75524991 0.49873726 0.44838505\n",
      "  0.42558257 0.54923229 0.57746691 0.62781379 0.59826474 0.44838505\n",
      "  0.54886679 0.73312206 0.49873726 0.73312206 0.4276175  0.73312206\n",
      "  0.62586788 0.54923229 0.39942329 0.67338169 0.47765703 0.49873726\n",
      "  0.75524991 0.71629159 0.42558257 0.64730862 0.28825809 0.49873726\n",
      "  0.75524991 0.47728873 0.73312206 0.44838505 0.4487502  0.49873726\n",
      "  0.57782706 0.64730862 0.69207755 0.28825809 0.64730862 0.49873726\n",
      "  0.71629159 0.30587434 0.59826474 0.62781379 0.73312206 0.3311057\n",
      "  0.69207755 0.64730862 0.62586788 0.62781379 0.49873726 0.54923229\n",
      "  0.4988556  0.4487502  0.60026252 0.54923229 0.3311057  0.64730862\n",
      "  0.52789915 0.44838505 0.49873726 0.60026252 0.60026252 0.73312206\n",
      "  0.69207755 0.4988556  0.73312206 0.39942329]\n",
      " [0.37281207 0.20655718 0.20655718 0.75837005 0.25404252 0.52765305\n",
      "  0.50386077 0.25404252 0.57054637 0.0553894  0.11587032 0.70581136\n",
      "  0.20655718 0.72520093 0.12167094 0.33324888 0.23641265 0.28826787\n",
      "  0.31242445 0.12167094 0.20655718 0.20655718 0.58407189 0.54144374\n",
      "  0.31242445 0.66858038 0.50386077 0.46060381 0.31242445 0.25404252\n",
      "  0.54144374 0.14635318 0.09925878 0.31242445 0.14635318 0.52765305\n",
      "  0.04698779 0.23641265 0.27644503 0.58407189 0.11587032 0.52765305\n",
      "  0.46060381 0.50386077 0.14635318 0.50386077 0.54144374 0.50386077\n",
      "  0.0553894  0.23641265 0.72520093 0.37281207 0.15341501 0.14635318\n",
      "  0.31242445 0.51771118 0.04698779 0.57054637 0.13222593 0.14635318\n",
      "  0.31242445 0.33324888 0.50386077 0.52765305 0.28826787 0.14635318\n",
      "  0.12167094 0.57054637 0.70581136 0.13222593 0.57054637 0.14635318\n",
      "  0.51771118 0.12599429 0.11587032 0.58407189 0.50386077 0.06059111\n",
      "  0.70581136 0.57054637 0.0553894  0.58407189 0.14635318 0.23641265\n",
      "  0.66858038 0.28826787 0.75837005 0.23641265 0.06059111 0.57054637\n",
      "  0.47440212 0.52765305 0.14635318 0.75837005 0.75837005 0.50386077\n",
      "  0.70581136 0.66858038 0.50386077 0.72520093]\n",
      " [0.6740059  0.46595221 0.46595221 0.74538761 0.5631519  0.30599349\n",
      "  0.33581512 0.5631519  0.42760397 0.51076812 0.2739021  0.66458538\n",
      "  0.46595221 0.633411   0.80358841 0.54960521 0.59649491 0.68594896\n",
      "  0.58321695 0.80358841 0.46595221 0.46595221 0.89013837 0.82705126\n",
      "  0.58321695 0.53904834 0.33581512 0.22982783 0.58321695 0.5631519\n",
      "  0.82705126 0.35788678 0.18209794 0.58321695 0.35788678 0.30599349\n",
      "  0.38125974 0.59649491 0.4523227  0.89013837 0.2739021  0.30599349\n",
      "  0.22982783 0.33581512 0.35788678 0.33581512 0.82705126 0.33581512\n",
      "  0.51076812 0.59649491 0.633411   0.6740059  0.85805651 0.35788678\n",
      "  0.58321695 0.84576826 0.38125974 0.42760397 0.78107759 0.35788678\n",
      "  0.58321695 0.54960521 0.33581512 0.30599349 0.68594896 0.35788678\n",
      "  0.80358841 0.42760397 0.66458538 0.78107759 0.42760397 0.35788678\n",
      "  0.84576826 0.24752954 0.2739021  0.89013837 0.33581512 0.47655755\n",
      "  0.66458538 0.42760397 0.51076812 0.89013837 0.35788678 0.59649491\n",
      "  0.53904834 0.68594896 0.74538761 0.59649491 0.47655755 0.42760397\n",
      "  0.7639584  0.30599349 0.35788678 0.74538761 0.74538761 0.33581512\n",
      "  0.66458538 0.53904834 0.33581512 0.633411  ]\n",
      " [0.45999098 0.07445317 0.07445317 0.32236304 0.19222572 0.42149984\n",
      "  0.39672382 0.19222572 0.66048747 0.27776538 0.46761366 0.13853214\n",
      "  0.07445317 0.15122567 0.08596144 0.24186794 0.17680762 0.38852285\n",
      "  0.22357016 0.08596144 0.07445317 0.07445317 0.17239044 0.0723683\n",
      "  0.22357016 0.05680642 0.39672382 0.19762235 0.22357016 0.19222572\n",
      "  0.0723683  0.72209453 0.2475329  0.22357016 0.72209453 0.42149984\n",
      "  0.12590515 0.17680762 0.09734599 0.17239044 0.46761366 0.42149984\n",
      "  0.19762235 0.39672382 0.72209453 0.39672382 0.0723683  0.39672382\n",
      "  0.27776538 0.17680762 0.15122567 0.45999098 0.21765716 0.72209453\n",
      "  0.22357016 0.06578089 0.12590515 0.66048747 0.09436564 0.72209453\n",
      "  0.22357016 0.24186794 0.39672382 0.42149984 0.38852285 0.72209453\n",
      "  0.08596144 0.66048747 0.13853214 0.09436564 0.66048747 0.72209453\n",
      "  0.06578089 0.49319749 0.46761366 0.17239044 0.39672382 0.29879177\n",
      "  0.13853214 0.66048747 0.27776538 0.17239044 0.72209453 0.17680762\n",
      "  0.05680642 0.38852285 0.32236304 0.17680762 0.29879177 0.66048747\n",
      "  0.02569399 0.42149984 0.72209453 0.32236304 0.32236304 0.39672382\n",
      "  0.13853214 0.05680642 0.39672382 0.15122567]\n",
      " [0.45622312 0.58430148 0.58430148 0.62553886 0.53687463 0.28567435\n",
      "  0.40843075 0.53687463 0.36281976 0.50127859 0.4055301  0.66947586\n",
      "  0.58430148 0.53986157 0.74675621 0.37077416 0.66681102 0.62271941\n",
      "  0.50428313 0.74675621 0.58430148 0.58430148 0.71109636 0.63352629\n",
      "  0.50428313 0.58721772 0.40843075 0.32655753 0.50428313 0.53687463\n",
      "  0.63352629 0.36004589 0.32391996 0.50428313 0.36004589 0.28567435\n",
      "  0.41381275 0.66681102 0.41673111 0.71109636 0.4055301  0.28567435\n",
      "  0.32655753 0.40843075 0.36004589 0.40843075 0.63352629 0.40843075\n",
      "  0.50127859 0.66681102 0.53986157 0.45622312 0.70862104 0.36004589\n",
      "  0.50428313 0.74902232 0.41381275 0.36281976 0.63073148 0.36004589\n",
      "  0.50428313 0.37077416 0.40843075 0.28567435 0.62271941 0.36004589\n",
      "  0.74675621 0.36281976 0.66947586 0.63073148 0.36281976 0.36004589\n",
      "  0.74902232 0.28322812 0.4055301  0.71109636 0.40843075 0.3679746\n",
      "  0.66947586 0.36281976 0.50127859 0.71109636 0.36004589 0.66681102\n",
      "  0.58721772 0.62271941 0.62553886 0.66681102 0.3679746  0.36281976\n",
      "  0.67701001 0.28567435 0.36004589 0.62553886 0.62553886 0.40843075\n",
      "  0.66947586 0.58721772 0.40843075 0.53986157]\n",
      " [0.44131828 0.56750724 0.56750724 0.51253461 0.59828804 0.43848202\n",
      "  0.52248307 0.59828804 0.55394967 0.6105661  0.71139073 0.48088429\n",
      "  0.56750724 0.39799697 0.5703304  0.33186087 0.67604498 0.70314181\n",
      "  0.41036355 0.5703304  0.56750724 0.56750724 0.40075826 0.29603025\n",
      "  0.41036355 0.36807891 0.52248307 0.4075811  0.41036355 0.59828804\n",
      "  0.29603025 0.73668263 0.60782552 0.41036355 0.73668263 0.43848202\n",
      "  0.49643141 0.67604498 0.30440052 0.40075826 0.71139073 0.43848202\n",
      "  0.4075811  0.52248307 0.73668263 0.52248307 0.29603025 0.52248307\n",
      "  0.6105661  0.67604498 0.39799697 0.44131828 0.60105152 0.73668263\n",
      "  0.41036355 0.37076047 0.49643141 0.55394967 0.48647364 0.73668263\n",
      "  0.41036355 0.33186087 0.52248307 0.43848202 0.70314181 0.73668263\n",
      "  0.5703304  0.55394967 0.48088429 0.48647364 0.55394967 0.73668263\n",
      "  0.37076047 0.63756939 0.71139073 0.40075826 0.52248307 0.52806409\n",
      "  0.48088429 0.55394967 0.6105661  0.40075826 0.73668263 0.67604498\n",
      "  0.36807891 0.70314181 0.51253461 0.67604498 0.52806409 0.55394967\n",
      "  0.27033515 0.43848202 0.73668263 0.51253461 0.51253461 0.52248307\n",
      "  0.48088429 0.36807891 0.52248307 0.39799697]\n",
      " [0.72553012 0.42731025 0.42731025 0.44082123 0.37166133 0.27422248\n",
      "  0.48496241 0.37166133 0.42740883 0.83172886 0.58259561 0.49860818\n",
      "  0.42731025 0.28522233 0.83923284 0.57228702 0.59581054 0.53886557\n",
      "  0.76929303 0.83923284 0.42731025 0.42731025 0.73626829 0.58559617\n",
      "  0.76929303 0.33482546 0.48496241 0.32277649 0.76929303 0.37166133\n",
      "  0.58559617 0.52527228 0.41400457 0.76929303 0.52527228 0.27422248\n",
      "  0.71444209 0.59581054 0.62795432 0.73626829 0.58259561 0.27422248\n",
      "  0.32277649 0.48496241 0.52527228 0.48496241 0.58559617 0.48496241\n",
      "  0.83172886 0.59581054 0.28522233 0.72553012 0.80538052 0.52527228\n",
      "  0.76929303 0.77884095 0.71444209 0.42740883 0.67686372 0.52527228\n",
      "  0.76929303 0.57228702 0.48496241 0.27422248 0.53886557 0.52527228\n",
      "  0.83923284 0.42740883 0.49860818 0.67686372 0.42740883 0.52527228\n",
      "  0.77884095 0.35900221 0.58259561 0.73626829 0.48496241 0.66480796\n",
      "  0.49860818 0.42740883 0.83172886 0.73626829 0.52527228 0.59581054\n",
      "  0.33482546 0.53886557 0.44082123 0.59581054 0.66480796 0.42740883\n",
      "  0.64061904 0.27422248 0.52527228 0.44082123 0.44082123 0.48496241\n",
      "  0.49860818 0.33482546 0.48496241 0.28522233]\n",
      " [0.23804467 0.70262748 0.70262748 0.69310384 0.4459055  0.22245558\n",
      "  0.68858335 0.4459055  0.42958004 0.46246819 0.67468558 0.86895377\n",
      "  0.70262748 0.46178016 0.72067755 0.10609372 0.86148628 0.67931385\n",
      "  0.47842337 0.72067755 0.70262748 0.70262748 0.48370716 0.26249458\n",
      "  0.47842337 0.71583431 0.68858335 0.4565241  0.47842337 0.4459055\n",
      "  0.26249458 0.41396095 0.44068219 0.47842337 0.41396095 0.22245558\n",
      "  0.24633442 0.86148628 0.25841774 0.48370716 0.67468558 0.22245558\n",
      "  0.4565241  0.68858335 0.41396095 0.68858335 0.26249458 0.68858335\n",
      "  0.46246819 0.86148628 0.46178016 0.23804467 0.46773379 0.41396095\n",
      "  0.47842337 0.73338692 0.24633442 0.42958004 0.25028498 0.41396095\n",
      "  0.47842337 0.10609372 0.68858335 0.22245558 0.67931385 0.41396095\n",
      "  0.72067755 0.42958004 0.86895377 0.25028498 0.42958004 0.41396095\n",
      "  0.73338692 0.21157407 0.67468558 0.48370716 0.68858335 0.10017081\n",
      "  0.86895377 0.42958004 0.46246819 0.48370716 0.41396095 0.86148628\n",
      "  0.71583431 0.67931385 0.69310384 0.86148628 0.10017081 0.42958004\n",
      "  0.51100483 0.22245558 0.41396095 0.69310384 0.69310384 0.68858335\n",
      "  0.86895377 0.71583431 0.68858335 0.46178016]]\n",
      "p_1_batch: [[0.62473754 0.47397858 0.38315461 0.6525953  0.59834301 0.69599746\n",
      "  0.38315461 0.457285   0.65376155 0.48775975 0.55191372 0.49524447\n",
      "  0.6525953  0.6525953  0.44637701 0.49563089 0.41638609 0.44361918\n",
      "  0.4042741  0.64605481 0.44361918 0.54352288 0.73265524 0.71064975\n",
      "  0.80666219 0.49455919 0.61520995 0.51553736 0.79983836 0.46682274\n",
      "  0.7181633  0.50130734 0.53588382 0.56794939 0.65560259 0.5932047\n",
      "  0.45199488 0.61797298 0.49283965 0.87177607 0.48604112 0.72304596\n",
      "  0.71033178 0.44489022 0.50130734 0.457285   0.74092784 0.49455919\n",
      "  0.49563089 0.48497021 0.76958677 0.59834301 0.72900284 0.378776\n",
      "  0.76261771 0.75592063 0.52339874 0.44489022 0.55001283 0.75464914\n",
      "  0.75058194 0.8250253  0.57859563 0.64419977 0.66681603 0.24280595\n",
      "  0.43691468 0.33345719 0.66251214 0.5690011  0.76750775 0.26381822\n",
      "  0.87726863 0.39062498 0.36352123 0.71676881 0.79055699 0.66421431\n",
      "  0.69250122 0.5932047  0.56338777 0.59075123 0.35299801 0.34467506\n",
      "  0.74929186 0.42464004 0.66681603 0.5690011  0.48604112 0.81768063\n",
      "  0.54629197 0.63264451 0.48312199 0.73265524 0.79983836 0.57068735\n",
      "  0.75592063 0.74010404 0.38315461 0.47397858]\n",
      " [0.77560346 0.65702672 0.78236926 0.66033868 0.66314108 0.76280948\n",
      "  0.78236926 0.69070936 0.57643548 0.72329965 0.65176265 0.46446906\n",
      "  0.66033868 0.66033868 0.52177848 0.64348212 0.48243681 0.62072378\n",
      "  0.32349762 0.65722817 0.62072378 0.72504073 0.71480175 0.74815402\n",
      "  0.59796825 0.76837134 0.36226155 0.82109612 0.48318623 0.65390178\n",
      "  0.5470391  0.65772075 0.33255423 0.71178907 0.42918243 0.50592438\n",
      "  0.5373833  0.56687289 0.73026396 0.49345251 0.68085699 0.72794707\n",
      "  0.58805184 0.53394151 0.65772075 0.69070936 0.53568665 0.76837134\n",
      "  0.64348212 0.79678831 0.80567704 0.66314108 0.47027997 0.56012908\n",
      "  0.58643486 0.74578774 0.76013375 0.53394151 0.54338631 0.70538949\n",
      "  0.74315538 0.63516911 0.5939309  0.82705256 0.59442167 0.41040143\n",
      "  0.56325235 0.43495696 0.79916319 0.57333259 0.64279036 0.54998174\n",
      "  0.65504073 0.71282588 0.72209416 0.49638482 0.82914959 0.3887925\n",
      "  0.75921004 0.50592438 0.46661174 0.74033341 0.42037915 0.60008222\n",
      "  0.70250568 0.39817135 0.59442167 0.57333259 0.68085699 0.47177873\n",
      "  0.63741281 0.71041861 0.48077132 0.71480175 0.48318623 0.62213889\n",
      "  0.74578774 0.67953106 0.78236926 0.65702672]\n",
      " [0.93628041 0.87282602 0.24042084 0.82452268 0.88223882 0.84451983\n",
      "  0.24042084 0.23010739 0.09817497 0.24989766 0.09373291 0.53714181\n",
      "  0.82452268 0.82452268 0.7777429  0.80178948 0.75841593 0.86028191\n",
      "  0.59974164 0.74885324 0.86028191 0.73909885 0.37390197 0.51488128\n",
      "  0.34372926 0.89520154 0.53346244 0.39519202 0.23077798 0.8132687\n",
      "  0.8160728  0.20626528 0.72047156 0.46589604 0.26747733 0.84928032\n",
      "  0.18354059 0.14119258 0.87681282 0.34040041 0.21728149 0.49838399\n",
      "  0.23341417 0.12484472 0.20626528 0.23010739 0.80472457 0.89520154\n",
      "  0.80178948 0.36956441 0.40840616 0.88223882 0.77583118 0.64718199\n",
      "  0.15772467 0.3996397  0.88806587 0.12484472 0.86632503 0.35677532\n",
      "  0.29697264 0.36861284 0.22749747 0.52918527 0.43343898 0.3522059\n",
      "  0.1936392  0.61342213 0.2863922  0.29232444 0.82762845 0.51605997\n",
      "  0.51951891 0.79352421 0.80536591 0.7871016  0.43486933 0.84179387\n",
      "  0.64295352 0.84928032 0.83485316 0.38157453 0.4832703  0.76876409\n",
      "  0.26034483 0.10283073 0.43343898 0.29232444 0.21728149 0.21792528\n",
      "  0.61685438 0.34915586 0.6587864  0.37390197 0.23077798 0.33143538\n",
      "  0.3996397  0.89693121 0.24042084 0.87282602]\n",
      " [0.4377495  0.49155705 0.27632919 0.49716582 0.72669421 0.11733732\n",
      "  0.27632919 0.88650209 0.58150689 0.67193042 0.20575424 0.68252944\n",
      "  0.49716582 0.49716582 0.76753424 0.30744036 0.9264238  0.78664087\n",
      "  0.89308095 0.86009859 0.78664087 0.53405625 0.88498611 0.84438195\n",
      "  0.92077893 0.63771396 0.6913575  0.3748921  0.96476304 0.85737675\n",
      "  0.95288514 0.10075125 0.78698537 0.88268242 0.88289494 0.22098486\n",
      "  0.45453798 0.81437712 0.33142249 0.92372228 0.36579827 0.51314206\n",
      "  0.9633405  0.83822692 0.10075125 0.88650209 0.59895717 0.63771396\n",
      "  0.30744036 0.69578033 0.50849061 0.72669421 0.52524648 0.05204536\n",
      "  0.38064909 0.66861976 0.1150333  0.83822692 0.95186748 0.36233009\n",
      "  0.926177   0.75294994 0.89056759 0.20964899 0.91912665 0.2977115\n",
      "  0.81096126 0.2899478  0.70050885 0.65486916 0.34563831 0.11042232\n",
      "  0.94806526 0.07643602 0.5284687  0.85064792 0.21339114 0.85299744\n",
      "  0.92197858 0.22098486 0.5196483  0.92462808 0.15789482 0.38101726\n",
      "  0.77940129 0.73997977 0.91912665 0.65486916 0.36579827 0.66907466\n",
      "  0.50651997 0.14963746 0.22749361 0.88498611 0.96476304 0.87076346\n",
      "  0.66861976 0.85553514 0.27632919 0.49155705]\n",
      " [0.65899923 0.79180118 0.89966835 0.72720632 0.61953624 0.53483589\n",
      "  0.89966835 0.89900642 0.5123016  0.70425676 0.79820449 0.87695153\n",
      "  0.72720632 0.72720632 0.76216021 0.5802098  0.92295148 0.93428158\n",
      "  0.88288397 0.53520506 0.93428158 0.81259294 0.94450129 0.73551788\n",
      "  0.9342721  0.66097302 0.58567745 0.73863938 0.73986961 0.6216073\n",
      "  0.72575342 0.84833952 0.88197143 0.96044177 0.92733492 0.70347659\n",
      "  0.92841288 0.9240783  0.8597812  0.73817319 0.88220638 0.6750128\n",
      "  0.93481016 0.84853034 0.84833952 0.89900642 0.69006889 0.66097302\n",
      "  0.5802098  0.91352778 0.88009947 0.61953624 0.861424   0.7660994\n",
      "  0.51010378 0.81990668 0.6212582  0.84853034 0.79059324 0.93471967\n",
      "  0.66290671 0.79177571 0.63841335 0.7369378  0.95300445 0.73574208\n",
      "  0.94554654 0.88363789 0.88102454 0.94509188 0.46018512 0.76767182\n",
      "  0.81751599 0.83882729 0.86083824 0.89273844 0.66257503 0.70194911\n",
      "  0.88442145 0.70347659 0.89866608 0.73722537 0.73402843 0.92346983\n",
      "  0.86081973 0.91616178 0.95300445 0.94509188 0.88220638 0.70527595\n",
      "  0.49427726 0.63807072 0.46518693 0.94450129 0.73986961 0.84550605\n",
      "  0.81990668 0.7584939  0.89966835 0.79180118]\n",
      " [0.49941811 0.58447493 0.59198267 0.68188669 0.69534595 0.71699306\n",
      "  0.59198267 0.66576458 0.91424049 0.72833119 0.85227317 0.85858318\n",
      "  0.68188669 0.68188669 0.76291559 0.79180995 0.70508882 0.51102055\n",
      "  0.86184976 0.79478927 0.51102055 0.67700355 0.50203856 0.59097868\n",
      "  0.67440849 0.5262744  0.92751341 0.53957006 0.82938124 0.71763382\n",
      "  0.74637639 0.77272022 0.84854276 0.3981617  0.78005676 0.76723048\n",
      "  0.74203957 0.79353257 0.55261158 0.8136231  0.74879687 0.62235171\n",
      "  0.69756188 0.83864494 0.77272022 0.66576458 0.81494899 0.5262744\n",
      "  0.79180995 0.46543779 0.54371142 0.69534595 0.78867245 0.84303097\n",
      "  0.90542614 0.57572197 0.62441017 0.83864494 0.65883205 0.60139227\n",
      "  0.71029551 0.73599864 0.80762083 0.51276968 0.57613024 0.93188662\n",
      "  0.71607341 0.8196261  0.57023628 0.69371494 0.79867715 0.85674049\n",
      "  0.62589278 0.6730177  0.57901966 0.76591957 0.61594568 0.81901101\n",
      "  0.34826227 0.76723048 0.71005618 0.61669292 0.92473663 0.63523153\n",
      "  0.73161922 0.86808783 0.57613024 0.69371494 0.74879687 0.87914556\n",
      "  0.86584116 0.73305527 0.90845874 0.50203856 0.82938124 0.67073499\n",
      "  0.57572197 0.56262404 0.59198267 0.58447493]\n",
      " [0.85268272 0.79438379 0.85414137 0.54395573 0.96028212 0.71377466\n",
      "  0.85414137 0.94602864 0.67768684 0.95882688 0.34585614 0.83957448\n",
      "  0.54395573 0.54395573 0.94165043 0.97121496 0.92393661 0.74411162\n",
      "  0.78033002 0.892848   0.74411162 0.67693067 0.35695285 0.93729982\n",
      "  0.67502308 0.86597371 0.59300909 0.8479095  0.39230484 0.96427223\n",
      "  0.78119407 0.60538484 0.76089106 0.64259911 0.66302059 0.50301242\n",
      "  0.42322298 0.76391754 0.85875159 0.36640891 0.95635606 0.51137961\n",
      "  0.69867839 0.8367624  0.60538484 0.94602864 0.81695995 0.86597371\n",
      "  0.97121496 0.80755372 0.53715526 0.96028212 0.19041234 0.71274227\n",
      "  0.65320157 0.42445566 0.88983582 0.8367624  0.9204089  0.40966083\n",
      "  0.83745072 0.73401672 0.82993585 0.83317224 0.87059953 0.92044337\n",
      "  0.91289893 0.54270325 0.5643696  0.90374414 0.34322297 0.73473093\n",
      "  0.66414747 0.8945634  0.87157751 0.77061365 0.60659009 0.75183261\n",
      "  0.63123119 0.50301242 0.43240247 0.94346282 0.91200511 0.80229749\n",
      "  0.82899513 0.75400173 0.87059953 0.90374414 0.95635606 0.44660747\n",
      "  0.92081223 0.59358187 0.90797914 0.35695285 0.39230484 0.90890978\n",
      "  0.42445566 0.46083332 0.85414137 0.79438379]\n",
      " [0.89654828 0.48651556 0.84248424 0.38246662 0.76661408 0.75190457\n",
      "  0.84248424 0.79120145 0.71904747 0.62880419 0.88987656 0.21931435\n",
      "  0.38246662 0.38246662 0.26422801 0.63732668 0.44546399 0.67942741\n",
      "  0.64994035 0.71363376 0.67942741 0.88723837 0.535033   0.73177588\n",
      "  0.27314106 0.90957003 0.35172705 0.81716354 0.45720872 0.79220024\n",
      "  0.30497066 0.91417194 0.61534303 0.63772484 0.57057295 0.65359797\n",
      "  0.68520253 0.18918642 0.91205826 0.42054562 0.6359256  0.9432995\n",
      "  0.30368842 0.89752067 0.91417194 0.79120145 0.16823364 0.90957003\n",
      "  0.63732668 0.90907063 0.8491884  0.76661408 0.73396706 0.92766157\n",
      "  0.68800148 0.33967777 0.82258159 0.89752067 0.40164934 0.34658205\n",
      "  0.67424755 0.14383004 0.87978469 0.79385125 0.36502885 0.84942566\n",
      "  0.26305224 0.72380677 0.86728904 0.23521163 0.92904416 0.93704202\n",
      "  0.23897154 0.84729217 0.92329476 0.31150229 0.71568497 0.57205628\n",
      "  0.5953003  0.65359797 0.80845232 0.75998558 0.82936795 0.5313666\n",
      "  0.6809395  0.45205476 0.36502885 0.23521163 0.6359256  0.27968105\n",
      "  0.57140555 0.89899346 0.80243326 0.535033   0.45720872 0.22974589\n",
      "  0.33967777 0.53653938 0.84248424 0.48651556]\n",
      " [0.6441887  0.80805534 0.67552434 0.65684561 0.60119191 0.72041456\n",
      "  0.67552434 0.35641433 0.7197495  0.75158677 0.63862587 0.47730051\n",
      "  0.65684561 0.65684561 0.77803747 0.82513265 0.3908387  0.43520863\n",
      "  0.54500116 0.24151609 0.43520863 0.17972675 0.32595343 0.675392\n",
      "  0.46430148 0.45683935 0.74845562 0.78418956 0.56747361 0.41187233\n",
      "  0.33738457 0.89323546 0.72054318 0.51539768 0.78063978 0.94418972\n",
      "  0.86140085 0.55758846 0.50915385 0.73850552 0.78864646 0.82348121\n",
      "  0.28706083 0.50832922 0.89323546 0.35641433 0.77430403 0.45683935\n",
      "  0.82513265 0.39943881 0.39429486 0.60119191 0.58471511 0.85839019\n",
      "  0.84682122 0.72542029 0.85000927 0.50832922 0.52826571 0.76516394\n",
      "  0.30530865 0.82563714 0.64343206 0.88664446 0.65590934 0.70102037\n",
      "  0.73488211 0.81827932 0.2321949  0.85646076 0.60580621 0.73794576\n",
      "  0.60203085 0.76453438 0.32518485 0.38573436 0.7805304  0.81818953\n",
      "  0.64989595 0.94418972 0.755897   0.49150343 0.83463316 0.70691582\n",
      "  0.35150016 0.83805361 0.65590934 0.85646076 0.78864646 0.898375\n",
      "  0.49917428 0.9359079  0.89805498 0.32595343 0.56747361 0.82870928\n",
      "  0.72542029 0.37946631 0.67552434 0.80805534]\n",
      " [0.55914366 0.79550561 0.79855677 0.94637845 0.26216197 0.92545463\n",
      "  0.79855677 0.33982227 0.6479505  0.47025967 0.89152782 0.86082913\n",
      "  0.94637845 0.94637845 0.5214838  0.43393204 0.38722397 0.69284481\n",
      "  0.22406962 0.66973323 0.69284481 0.90055255 0.90404025 0.24647086\n",
      "  0.67721656 0.6147146  0.69320215 0.76012178 0.49085974 0.30889819\n",
      "  0.69620832 0.59017827 0.18670071 0.67495685 0.17445824 0.58560873\n",
      "  0.67183951 0.85061483 0.61340282 0.43387671 0.468881   0.34792232\n",
      "  0.72521831 0.19043347 0.59017827 0.33982227 0.79717909 0.6147146\n",
      "  0.43393204 0.64756726 0.86888439 0.26216197 0.78803327 0.61003622\n",
      "  0.59400723 0.94202006 0.73235874 0.19043347 0.33560378 0.94171699\n",
      "  0.65117695 0.78346834 0.15827128 0.71582814 0.31620991 0.35537428\n",
      "  0.55655131 0.68982019 0.89289095 0.49942272 0.72448756 0.66305782\n",
      "  0.62645963 0.77391906 0.66621713 0.69503635 0.91954012 0.1550482\n",
      "  0.62404186 0.58560873 0.45037809 0.29151498 0.30470657 0.82954253\n",
      "  0.64991861 0.36448913 0.31620991 0.49942272 0.468881   0.62313687\n",
      "  0.81395467 0.53512981 0.25942949 0.90404025 0.49085974 0.50080651\n",
      "  0.94202006 0.89107373 0.79855677 0.79550561]]\n",
      "z_s_batch: [[ 1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.\n",
      "   1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1. -1.  1.  1.  1.]\n",
      " [ 1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.\n",
      "   1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
      "  -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1. -1.  1. -1.  1.  1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1.\n",
      "   1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.\n",
      "   1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.\n",
      "   1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "   1. -1.  1.  1.  1. -1. -1.  1. -1.  1.]]\n",
      "y_s_batch: [[-1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.\n",
      "   1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.\n",
      "  -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1.\n",
      "  -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.\n",
      "   1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1.\n",
      "   1. -1. -1. -1. -1.  1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.]\n",
      " [-1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  -1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.\n",
      "  -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      "   1. -1. -1.  1.  1. -1.  1.  1. -1.  1.]]\n",
      "x_s_batch: [[-1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.\n",
      "   1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.]\n",
      " [-1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "  -1.  1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
      "   1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      "   1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1.  1.  1. -1. -1.]\n",
      " [-1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.\n",
      "   1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.\n",
      "   1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1. -1.  1.\n",
      "  -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
      "   1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.]\n",
      " [-1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "   1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  -1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.]\n",
      " [-1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.\n",
      "   1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1.  1. -1.  1.  1. -1. -1. -1. -1.]\n",
      " [-1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
      "  -1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      "   1. -1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "d_s_batch: [[-1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "   1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
      "   1. -1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1.\n",
      "   1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      "   1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1.\n",
      "   1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.\n",
      "   1.  1. -1. -1. -1. -1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.\n",
      "   1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.]\n",
      " [-1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.]\n",
      " [ 1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1. -1. -1.  1.  1.  1. -1.]\n",
      " [ 1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      "   1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1. -1. -1.  1. -1. -1.  1. -1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1. -1. -1. -1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1. -1.  1.  1.  1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.\n",
      "  -1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      "   1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1.\n",
      "   1.  1. -1.  1. -1.  1.  1.  1.  1.  1.]]\n",
      "P_batch: [2.33041541e-05 5.16912483e-03 1.26292331e-02 9.77662285e-02\n",
      " 2.38734094e-02 7.36656446e-03 1.66164038e-03 1.76214423e-02\n",
      " 8.02400168e-02 2.11144393e-02 2.53319052e-03 8.32219111e-03\n",
      " 4.09339358e-04 9.73020165e-03 1.78641853e-02 1.36863777e-02\n",
      " 3.33909953e-02 5.65728271e-02 3.43318991e-03 2.84046841e-03\n",
      " 1.92893246e-02 1.43474125e-02 1.34581653e-02 4.30210677e-04\n",
      " 1.11367465e-03 2.52885831e-03 1.09084825e-03 6.86718819e-04\n",
      " 7.44902528e-04 2.02531209e-03 4.04858815e-03 1.62884065e-02\n",
      " 6.26303811e-03 2.51690028e-03 1.67408196e-02 4.62327263e-02\n",
      " 1.14322232e-05 2.15627218e-02 1.17170183e-03 5.03392863e-04\n",
      " 1.58062679e-02 1.49247251e-02 1.06080638e-04 3.85741216e-03\n",
      " 2.30222448e-03 4.70951593e-02 5.86499287e-04 7.86994179e-03\n",
      " 4.49288149e-03 1.60643064e-01 1.21129813e-03 1.05085929e-02\n",
      " 3.12307116e-05 1.60119738e-02 9.74581640e-04 1.20549845e-01\n",
      " 4.96857453e-02 7.09449692e-03 3.26590697e-03 2.65796336e-03\n",
      " 2.40500758e-03 4.26113827e-03 1.56236613e-02 1.29368695e-01\n",
      " 1.58123022e-02 7.16501772e-02 2.48841389e-01 1.72832100e-02\n",
      " 3.71959788e-02 7.83095627e-03 5.35745373e-03 9.30688472e-03\n",
      " 8.55095185e-02 2.03334175e-01 4.98618369e-02 3.37626061e-03\n",
      " 3.02496807e-02 1.00384918e-02 1.60495571e-01 6.70474531e-03\n",
      " 1.07838670e-03 7.49547224e-03 9.67737826e-02 8.43056567e-04\n",
      " 1.93372427e-03 8.88071475e-03 1.65683869e-02 1.72776557e-04\n",
      " 4.01629423e-02 9.81103551e-03 4.80769813e-03 8.78671832e-02\n",
      " 1.32486571e-02 1.76364306e-02 3.30761603e-03 4.16413507e-03\n",
      " 3.62449787e-02 2.51002786e-02 6.01752073e-02 3.69435564e-03]\n"
     ]
    }
   ],
   "source": [
    "p_4_batch,p_3_batch,p_2_batch,p_1_batch,z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch = sleep_forward_batch(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,test_size)\n",
    "print (\"p_4_batch: \" + str(p_4_batch))\n",
    "print (\"p_3_batch: \" + str(p_3_batch))\n",
    "print (\"p_2_batch: \" + str(p_2_batch))\n",
    "print (\"p_1_batch: \" + str(p_1_batch))\n",
    "print (\"z_s_batch: \" + str(z_s_batch))\n",
    "print (\"y_s_batch: \" + str(y_s_batch))\n",
    "print (\"x_s_batch: \" + str(x_s_batch))\n",
    "print (\"d_s_batch: \" + str(d_s_batch))\n",
    "print (\"P_batch: \" + str(P_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_forward_batch_deterministic(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,batch_size):\n",
    "    p_4 = sigmoid(Theta)\n",
    "    z = ((p_4 > np.random.rand(n_z,batch_size)).astype(int) - 0.5)*2    # rejection sampling\n",
    "    \n",
    "    p_3 = sigmoid(np.matmul(Theta_43,z) + b_43)\n",
    "    y = ((p_3 > np.random.rand(n_y,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_2 = sigmoid(np.matmul(Theta_32,y) + b_32)\n",
    "    x = ((p_2 > np.random.rand(n_x,batch_size)).astype(int) - 0.5)*2\n",
    "    \n",
    "    p_1 = sigmoid(np.matmul(Theta_21,x) + b_21)\n",
    "    #d = ((p_1 > np.random.rand(n_d,batch_size)).astype(int) - 0.5)*2\n",
    "    d = np.where(p_1 > 0.5,1,-1)\n",
    "    \n",
    "    P_4 = np.cumprod(np.where(z == 1,p_4,1),axis=0)[-1] * np.cumprod(np.where(z == -1,1-p_4,1),axis=0)[-1]*(1.5**n_z)\n",
    "    P_3 = np.cumprod(np.where(y == 1,p_3,1),axis=0)[-1] * np.cumprod(np.where(y == -1,1-p_3,1),axis=0)[-1]*(1.5**n_y)\n",
    "    P_2 = np.cumprod(np.where(x == 1,p_2,1),axis=0)[-1] * np.cumprod(np.where(x == -1,1-p_2,1),axis=0)[-1]*(1.5**n_x)\n",
    "    P_1 = np.cumprod(np.where(d == 1,p_1,1),axis=0)[-1] * np.cumprod(np.where(d == -1,1-p_1,1),axis=0)[-1]*(1.5**n_d)\n",
    "    \n",
    "    P = P_1 * P_2 * P_3 * P_4\n",
    "    \n",
    "    return p_4,p_3,p_2,p_1,z,y,x,d,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_4_batch: [[0.51993293]\n",
      " [0.5533909 ]\n",
      " [0.51478194]]\n",
      "p_3_batch: [[0.15505819 0.3196456  0.61654909 0.38576719 0.18033514 0.38576719\n",
      "  0.15505819 0.38576719 0.3196456  0.3196456  0.42953435 0.57286198\n",
      "  0.38576719 0.3196456  0.42953435 0.3196456  0.28154926 0.18033514\n",
      "  0.57286198 0.28154926 0.3196456  0.42953435 0.61654909 0.18033514\n",
      "  0.3196456  0.42953435 0.38576719 0.61654909 0.15505819 0.15505819\n",
      "  0.3196456  0.15505819 0.42953435 0.15505819 0.38576719 0.42953435\n",
      "  0.38576719 0.28154926 0.61654909 0.15505819 0.3196456  0.3196456\n",
      "  0.18033514 0.42953435 0.38576719 0.42953435 0.57286198 0.28154926\n",
      "  0.28154926 0.61654909 0.18033514 0.42953435 0.3196456  0.42953435\n",
      "  0.42953435 0.28154926 0.18033514 0.18033514 0.61654909 0.61654909\n",
      "  0.57286198 0.15505819 0.38576719 0.28154926 0.15505819 0.3196456\n",
      "  0.15505819 0.57286198 0.28154926 0.28154926 0.28154926 0.28154926\n",
      "  0.61654909 0.61654909 0.38576719 0.38576719 0.18033514 0.18033514\n",
      "  0.42953435 0.38576719 0.18033514 0.3196456  0.28154926 0.15505819\n",
      "  0.61654909 0.61654909 0.15505819 0.15505819 0.38576719 0.15505819\n",
      "  0.18033514 0.61654909 0.57286198 0.38576719 0.28154926 0.42953435\n",
      "  0.38576719 0.15505819 0.28154926 0.57286198]\n",
      " [0.49903146 0.58689545 0.61353593 0.52676932 0.28678057 0.52676932\n",
      "  0.49903146 0.52676932 0.58689545 0.58689545 0.31002169 0.7972828\n",
      "  0.52676932 0.58689545 0.31002169 0.58689545 0.77874084 0.28678057\n",
      "  0.7972828  0.77874084 0.58689545 0.31002169 0.61353593 0.28678057\n",
      "  0.58689545 0.31002169 0.52676932 0.61353593 0.49903146 0.49903146\n",
      "  0.58689545 0.49903146 0.31002169 0.49903146 0.52676932 0.31002169\n",
      "  0.52676932 0.77874084 0.61353593 0.49903146 0.58689545 0.58689545\n",
      "  0.28678057 0.31002169 0.52676932 0.31002169 0.7972828  0.77874084\n",
      "  0.77874084 0.61353593 0.28678057 0.31002169 0.58689545 0.31002169\n",
      "  0.31002169 0.77874084 0.28678057 0.28678057 0.61353593 0.61353593\n",
      "  0.7972828  0.49903146 0.52676932 0.77874084 0.49903146 0.58689545\n",
      "  0.49903146 0.7972828  0.77874084 0.77874084 0.77874084 0.77874084\n",
      "  0.61353593 0.61353593 0.52676932 0.52676932 0.28678057 0.28678057\n",
      "  0.31002169 0.52676932 0.28678057 0.58689545 0.77874084 0.49903146\n",
      "  0.61353593 0.61353593 0.49903146 0.49903146 0.52676932 0.49903146\n",
      "  0.28678057 0.61353593 0.7972828  0.52676932 0.77874084 0.31002169\n",
      "  0.52676932 0.49903146 0.77874084 0.7972828 ]\n",
      " [0.5493863  0.85437192 0.75680987 0.39273011 0.64983362 0.39273011\n",
      "  0.5493863  0.39273011 0.85437192 0.85437192 0.49606654 0.67153856\n",
      "  0.39273011 0.85437192 0.49606654 0.85437192 0.79399784 0.64983362\n",
      "  0.67153856 0.79399784 0.85437192 0.49606654 0.75680987 0.64983362\n",
      "  0.85437192 0.49606654 0.39273011 0.75680987 0.5493863  0.5493863\n",
      "  0.85437192 0.5493863  0.49606654 0.5493863  0.39273011 0.49606654\n",
      "  0.39273011 0.79399784 0.75680987 0.5493863  0.85437192 0.85437192\n",
      "  0.64983362 0.49606654 0.39273011 0.49606654 0.67153856 0.79399784\n",
      "  0.79399784 0.75680987 0.64983362 0.49606654 0.85437192 0.49606654\n",
      "  0.49606654 0.79399784 0.64983362 0.64983362 0.75680987 0.75680987\n",
      "  0.67153856 0.5493863  0.39273011 0.79399784 0.5493863  0.85437192\n",
      "  0.5493863  0.67153856 0.79399784 0.79399784 0.79399784 0.79399784\n",
      "  0.75680987 0.75680987 0.39273011 0.39273011 0.64983362 0.64983362\n",
      "  0.49606654 0.39273011 0.64983362 0.85437192 0.79399784 0.5493863\n",
      "  0.75680987 0.75680987 0.5493863  0.5493863  0.39273011 0.5493863\n",
      "  0.64983362 0.75680987 0.67153856 0.39273011 0.79399784 0.49606654\n",
      "  0.39273011 0.5493863  0.79399784 0.67153856]\n",
      " [0.75371998 0.67592724 0.4926885  0.58763236 0.78175682 0.58763236\n",
      "  0.75371998 0.58763236 0.67592724 0.67592724 0.62517404 0.45347743\n",
      "  0.58763236 0.67592724 0.62517404 0.67592724 0.64054615 0.78175682\n",
      "  0.45347743 0.64054615 0.67592724 0.62517404 0.4926885  0.78175682\n",
      "  0.67592724 0.62517404 0.58763236 0.4926885  0.75371998 0.75371998\n",
      "  0.67592724 0.75371998 0.62517404 0.75371998 0.58763236 0.62517404\n",
      "  0.58763236 0.64054615 0.4926885  0.75371998 0.67592724 0.67592724\n",
      "  0.78175682 0.62517404 0.58763236 0.62517404 0.45347743 0.64054615\n",
      "  0.64054615 0.4926885  0.78175682 0.62517404 0.67592724 0.62517404\n",
      "  0.62517404 0.64054615 0.78175682 0.78175682 0.4926885  0.4926885\n",
      "  0.45347743 0.75371998 0.58763236 0.64054615 0.75371998 0.67592724\n",
      "  0.75371998 0.45347743 0.64054615 0.64054615 0.64054615 0.64054615\n",
      "  0.4926885  0.4926885  0.58763236 0.58763236 0.78175682 0.78175682\n",
      "  0.62517404 0.58763236 0.78175682 0.67592724 0.64054615 0.75371998\n",
      "  0.4926885  0.4926885  0.75371998 0.75371998 0.58763236 0.75371998\n",
      "  0.78175682 0.4926885  0.45347743 0.58763236 0.64054615 0.62517404\n",
      "  0.58763236 0.75371998 0.64054615 0.45347743]\n",
      " [0.42908686 0.64628751 0.55934143 0.34302379 0.37053407 0.34302379\n",
      "  0.42908686 0.34302379 0.64628751 0.64628751 0.29024455 0.61841788\n",
      "  0.34302379 0.64628751 0.29024455 0.64628751 0.69996027 0.37053407\n",
      "  0.61841788 0.69996027 0.64628751 0.29024455 0.55934143 0.37053407\n",
      "  0.64628751 0.29024455 0.34302379 0.55934143 0.42908686 0.42908686\n",
      "  0.64628751 0.42908686 0.29024455 0.42908686 0.34302379 0.29024455\n",
      "  0.34302379 0.69996027 0.55934143 0.42908686 0.64628751 0.64628751\n",
      "  0.37053407 0.29024455 0.34302379 0.29024455 0.61841788 0.69996027\n",
      "  0.69996027 0.55934143 0.37053407 0.29024455 0.64628751 0.29024455\n",
      "  0.29024455 0.69996027 0.37053407 0.37053407 0.55934143 0.55934143\n",
      "  0.61841788 0.42908686 0.34302379 0.69996027 0.42908686 0.64628751\n",
      "  0.42908686 0.61841788 0.69996027 0.69996027 0.69996027 0.69996027\n",
      "  0.55934143 0.55934143 0.34302379 0.34302379 0.37053407 0.37053407\n",
      "  0.29024455 0.34302379 0.37053407 0.64628751 0.69996027 0.42908686\n",
      "  0.55934143 0.55934143 0.42908686 0.42908686 0.34302379 0.42908686\n",
      "  0.37053407 0.55934143 0.61841788 0.34302379 0.69996027 0.29024455\n",
      "  0.34302379 0.42908686 0.69996027 0.61841788]]\n",
      "p_2_batch: [[0.54886679 0.54923229 0.4988556  0.49873726 0.67338169 0.54923229\n",
      "  0.73312206 0.73312206 0.62586788 0.73312206 0.54886679 0.62586788\n",
      "  0.42558257 0.54923229 0.3311057  0.67338169 0.57782706 0.67338169\n",
      "  0.62781379 0.4988556  0.47765703 0.75524991 0.57782706 0.62781379\n",
      "  0.69207755 0.71629159 0.39742937 0.52789915 0.69207755 0.57746691\n",
      "  0.47765703 0.30587434 0.64730862 0.39942329 0.62586788 0.39742937\n",
      "  0.3311057  0.73312206 0.57782706 0.54886679 0.54923229 0.73312206\n",
      "  0.69207755 0.64730862 0.52778118 0.44838505 0.3504963  0.69207755\n",
      "  0.64730862 0.62781379 0.60026252 0.47728873 0.4487502  0.52778118\n",
      "  0.39742937 0.54886679 0.69207755 0.71629159 0.71629159 0.54923229\n",
      "  0.39942329 0.59826474 0.52789915 0.4988556  0.54886679 0.73312206\n",
      "  0.59826474 0.57746691 0.73312206 0.4988556  0.69207755 0.57782706\n",
      "  0.67338169 0.54886679 0.49873726 0.67338169 0.60026252 0.67338169\n",
      "  0.49873726 0.44838505 0.75524991 0.62781379 0.73312206 0.67338169\n",
      "  0.28825809 0.52778118 0.75524991 0.4988556  0.67338169 0.54886679\n",
      "  0.54886679 0.73312206 0.62781379 0.44838505 0.75524991 0.4487502\n",
      "  0.39942329 0.4276175  0.71629159 0.75524991]\n",
      " [0.46060381 0.23641265 0.66858038 0.14635318 0.37281207 0.23641265\n",
      "  0.50386077 0.50386077 0.0553894  0.50386077 0.46060381 0.0553894\n",
      "  0.04698779 0.23641265 0.06059111 0.37281207 0.12167094 0.37281207\n",
      "  0.58407189 0.66858038 0.15341501 0.31242445 0.12167094 0.58407189\n",
      "  0.70581136 0.51771118 0.09925878 0.47440212 0.70581136 0.27644503\n",
      "  0.15341501 0.12599429 0.57054637 0.72520093 0.0553894  0.09925878\n",
      "  0.06059111 0.50386077 0.12167094 0.46060381 0.23641265 0.50386077\n",
      "  0.70581136 0.57054637 0.07124322 0.52765305 0.20655718 0.70581136\n",
      "  0.57054637 0.58407189 0.75837005 0.33324888 0.28826787 0.07124322\n",
      "  0.09925878 0.46060381 0.70581136 0.51771118 0.51771118 0.23641265\n",
      "  0.72520093 0.11587032 0.47440212 0.66858038 0.46060381 0.50386077\n",
      "  0.11587032 0.27644503 0.50386077 0.66858038 0.70581136 0.12167094\n",
      "  0.37281207 0.46060381 0.14635318 0.37281207 0.75837005 0.37281207\n",
      "  0.14635318 0.52765305 0.31242445 0.58407189 0.50386077 0.37281207\n",
      "  0.13222593 0.07124322 0.31242445 0.66858038 0.37281207 0.46060381\n",
      "  0.46060381 0.50386077 0.58407189 0.52765305 0.31242445 0.28826787\n",
      "  0.72520093 0.54144374 0.51771118 0.31242445]\n",
      " [0.22982783 0.59649491 0.53904834 0.35788678 0.6740059  0.59649491\n",
      "  0.33581512 0.33581512 0.51076812 0.33581512 0.22982783 0.51076812\n",
      "  0.38125974 0.59649491 0.47655755 0.6740059  0.80358841 0.6740059\n",
      "  0.89013837 0.53904834 0.85805651 0.58321695 0.80358841 0.89013837\n",
      "  0.66458538 0.84576826 0.18209794 0.7639584  0.66458538 0.4523227\n",
      "  0.85805651 0.24752954 0.42760397 0.633411   0.51076812 0.18209794\n",
      "  0.47655755 0.33581512 0.80358841 0.22982783 0.59649491 0.33581512\n",
      "  0.66458538 0.42760397 0.60669606 0.30599349 0.46595221 0.66458538\n",
      "  0.42760397 0.89013837 0.74538761 0.54960521 0.68594896 0.60669606\n",
      "  0.18209794 0.22982783 0.66458538 0.84576826 0.84576826 0.59649491\n",
      "  0.633411   0.2739021  0.7639584  0.53904834 0.22982783 0.33581512\n",
      "  0.2739021  0.4523227  0.33581512 0.53904834 0.66458538 0.80358841\n",
      "  0.6740059  0.22982783 0.35788678 0.6740059  0.74538761 0.6740059\n",
      "  0.35788678 0.30599349 0.58321695 0.89013837 0.33581512 0.6740059\n",
      "  0.78107759 0.60669606 0.58321695 0.53904834 0.6740059  0.22982783\n",
      "  0.22982783 0.33581512 0.89013837 0.30599349 0.58321695 0.68594896\n",
      "  0.633411   0.82705126 0.84576826 0.58321695]\n",
      " [0.19762235 0.17680762 0.05680642 0.72209453 0.45999098 0.17680762\n",
      "  0.39672382 0.39672382 0.27776538 0.39672382 0.19762235 0.27776538\n",
      "  0.12590515 0.17680762 0.29879177 0.45999098 0.08596144 0.45999098\n",
      "  0.17239044 0.05680642 0.21765716 0.22357016 0.08596144 0.17239044\n",
      "  0.13853214 0.06578089 0.2475329  0.02569399 0.13853214 0.09734599\n",
      "  0.21765716 0.49319749 0.66048747 0.15122567 0.27776538 0.2475329\n",
      "  0.29879177 0.39672382 0.08596144 0.19762235 0.17680762 0.39672382\n",
      "  0.13853214 0.66048747 0.53221252 0.42149984 0.07445317 0.13853214\n",
      "  0.66048747 0.17239044 0.32236304 0.24186794 0.38852285 0.53221252\n",
      "  0.2475329  0.19762235 0.13853214 0.06578089 0.06578089 0.17680762\n",
      "  0.15122567 0.46761366 0.02569399 0.05680642 0.19762235 0.39672382\n",
      "  0.46761366 0.09734599 0.39672382 0.05680642 0.13853214 0.08596144\n",
      "  0.45999098 0.19762235 0.72209453 0.45999098 0.32236304 0.45999098\n",
      "  0.72209453 0.42149984 0.22357016 0.17239044 0.39672382 0.45999098\n",
      "  0.09436564 0.53221252 0.22357016 0.05680642 0.45999098 0.19762235\n",
      "  0.19762235 0.39672382 0.17239044 0.42149984 0.22357016 0.38852285\n",
      "  0.15122567 0.0723683  0.06578089 0.22357016]\n",
      " [0.32655753 0.66681102 0.58721772 0.36004589 0.45622312 0.66681102\n",
      "  0.40843075 0.40843075 0.50127859 0.40843075 0.32655753 0.50127859\n",
      "  0.41381275 0.66681102 0.3679746  0.45622312 0.74675621 0.45622312\n",
      "  0.71109636 0.58721772 0.70862104 0.50428313 0.74675621 0.71109636\n",
      "  0.66947586 0.74902232 0.32391996 0.67701001 0.66947586 0.41673111\n",
      "  0.70862104 0.28322812 0.36281976 0.53986157 0.50127859 0.32391996\n",
      "  0.3679746  0.40843075 0.74675621 0.32655753 0.66681102 0.40843075\n",
      "  0.66947586 0.36281976 0.45324311 0.28567435 0.58430148 0.66947586\n",
      "  0.36281976 0.71109636 0.62553886 0.37077416 0.62271941 0.45324311\n",
      "  0.32391996 0.32655753 0.66947586 0.74902232 0.74902232 0.66681102\n",
      "  0.53986157 0.4055301  0.67701001 0.58721772 0.32655753 0.40843075\n",
      "  0.4055301  0.41673111 0.40843075 0.58721772 0.66947586 0.74675621\n",
      "  0.45622312 0.32655753 0.36004589 0.45622312 0.62553886 0.45622312\n",
      "  0.36004589 0.28567435 0.50428313 0.71109636 0.40843075 0.45622312\n",
      "  0.63073148 0.45324311 0.50428313 0.58721772 0.45622312 0.32655753\n",
      "  0.32655753 0.40843075 0.71109636 0.28567435 0.50428313 0.62271941\n",
      "  0.53986157 0.63352629 0.74902232 0.50428313]\n",
      " [0.4075811  0.67604498 0.36807891 0.73668263 0.44131828 0.67604498\n",
      "  0.52248307 0.52248307 0.6105661  0.52248307 0.4075811  0.6105661\n",
      "  0.49643141 0.67604498 0.52806409 0.44131828 0.5703304  0.44131828\n",
      "  0.40075826 0.36807891 0.60105152 0.41036355 0.5703304  0.40075826\n",
      "  0.48088429 0.37076047 0.60782552 0.27033515 0.48088429 0.30440052\n",
      "  0.60105152 0.63756939 0.55394967 0.39799697 0.6105661  0.60782552\n",
      "  0.52806409 0.52248307 0.5703304  0.4075811  0.67604498 0.52248307\n",
      "  0.48088429 0.55394967 0.64022515 0.43848202 0.56750724 0.48088429\n",
      "  0.55394967 0.40075826 0.51253461 0.33186087 0.70314181 0.64022515\n",
      "  0.60782552 0.4075811  0.48088429 0.37076047 0.37076047 0.67604498\n",
      "  0.39799697 0.71139073 0.27033515 0.36807891 0.4075811  0.52248307\n",
      "  0.71139073 0.30440052 0.52248307 0.36807891 0.48088429 0.5703304\n",
      "  0.44131828 0.4075811  0.73668263 0.44131828 0.51253461 0.44131828\n",
      "  0.73668263 0.43848202 0.41036355 0.40075826 0.52248307 0.44131828\n",
      "  0.48647364 0.64022515 0.41036355 0.36807891 0.44131828 0.4075811\n",
      "  0.4075811  0.52248307 0.40075826 0.43848202 0.41036355 0.70314181\n",
      "  0.39799697 0.29603025 0.37076047 0.41036355]\n",
      " [0.32277649 0.59581054 0.33482546 0.52527228 0.72553012 0.59581054\n",
      "  0.48496241 0.48496241 0.83172886 0.48496241 0.32277649 0.83172886\n",
      "  0.71444209 0.59581054 0.66480796 0.72553012 0.83923284 0.72553012\n",
      "  0.73626829 0.33482546 0.80538052 0.76929303 0.83923284 0.73626829\n",
      "  0.49860818 0.77884095 0.41400457 0.64061904 0.49860818 0.62795432\n",
      "  0.80538052 0.35900221 0.42740883 0.28522233 0.83172886 0.41400457\n",
      "  0.66480796 0.48496241 0.83923284 0.32277649 0.59581054 0.48496241\n",
      "  0.49860818 0.42740883 0.79667925 0.27422248 0.42731025 0.49860818\n",
      "  0.42740883 0.73626829 0.44082123 0.57228702 0.53886557 0.79667925\n",
      "  0.41400457 0.32277649 0.49860818 0.77884095 0.77884095 0.59581054\n",
      "  0.28522233 0.58259561 0.64061904 0.33482546 0.32277649 0.48496241\n",
      "  0.58259561 0.62795432 0.48496241 0.33482546 0.49860818 0.83923284\n",
      "  0.72553012 0.32277649 0.52527228 0.72553012 0.44082123 0.72553012\n",
      "  0.52527228 0.27422248 0.76929303 0.73626829 0.48496241 0.72553012\n",
      "  0.67686372 0.79667925 0.76929303 0.33482546 0.72553012 0.32277649\n",
      "  0.32277649 0.48496241 0.73626829 0.27422248 0.76929303 0.53886557\n",
      "  0.28522233 0.58559617 0.77884095 0.76929303]\n",
      " [0.4565241  0.86148628 0.71583431 0.41396095 0.23804467 0.86148628\n",
      "  0.68858335 0.68858335 0.46246819 0.68858335 0.4565241  0.46246819\n",
      "  0.24633442 0.86148628 0.10017081 0.23804467 0.72067755 0.23804467\n",
      "  0.48370716 0.71583431 0.46773379 0.47842337 0.72067755 0.48370716\n",
      "  0.86895377 0.73338692 0.44068219 0.51100483 0.86895377 0.25841774\n",
      "  0.46773379 0.21157407 0.42958004 0.46178016 0.46246819 0.44068219\n",
      "  0.10017081 0.68858335 0.72067755 0.4565241  0.86148628 0.68858335\n",
      "  0.86895377 0.42958004 0.22662286 0.22245558 0.70262748 0.86895377\n",
      "  0.42958004 0.48370716 0.69310384 0.10609372 0.67931385 0.22662286\n",
      "  0.44068219 0.4565241  0.86895377 0.73338692 0.73338692 0.86148628\n",
      "  0.46178016 0.67468558 0.51100483 0.71583431 0.4565241  0.68858335\n",
      "  0.67468558 0.25841774 0.68858335 0.71583431 0.86895377 0.72067755\n",
      "  0.23804467 0.4565241  0.41396095 0.23804467 0.69310384 0.23804467\n",
      "  0.41396095 0.22245558 0.47842337 0.48370716 0.68858335 0.23804467\n",
      "  0.25028498 0.22662286 0.47842337 0.71583431 0.23804467 0.4565241\n",
      "  0.4565241  0.68858335 0.48370716 0.22245558 0.47842337 0.67931385\n",
      "  0.46178016 0.26249458 0.73338692 0.47842337]]\n",
      "p_1_batch: [[0.48604112 0.69250122 0.39226372 0.6934134  0.57838569 0.37139412\n",
      "  0.61358016 0.64419977 0.57068735 0.74109307 0.67103778 0.44361918\n",
      "  0.47226374 0.59075123 0.76532659 0.7062428  0.36610877 0.74708991\n",
      "  0.87726863 0.69916668 0.55838131 0.77080436 0.57068735 0.69992382\n",
      "  0.71033178 0.36610877 0.457285   0.75058194 0.71033178 0.48604112\n",
      "  0.3200223  0.66951742 0.50302712 0.76168447 0.39062498 0.39226372\n",
      "  0.57733988 0.49524447 0.4042741  0.68781776 0.33345719 0.67847127\n",
      "  0.56794939 0.56613255 0.76532659 0.75464914 0.62699028 0.59075123\n",
      "  0.48273598 0.74092784 0.66834265 0.52339874 0.42464004 0.35299801\n",
      "  0.51381903 0.51381903 0.51584294 0.6934134  0.51584294 0.56794939\n",
      "  0.61256317 0.25212777 0.6525953  0.67103778 0.73295792 0.62558169\n",
      "  0.65715418 0.79055699 0.56425935 0.63723173 0.71676881 0.48497021\n",
      "  0.53588382 0.39226372 0.72900284 0.44467761 0.75058194 0.71652035\n",
      "  0.6054321  0.3271036  0.33345719 0.49524447 0.65715418 0.66681603\n",
      "  0.55001283 0.68853345 0.55838131 0.74010404 0.55668426 0.36610877\n",
      "  0.60522641 0.44489022 0.62538001 0.75464914 0.68266912 0.56794939\n",
      "  0.65103404 0.74929186 0.66834265 0.49563089]\n",
      " [0.68085699 0.75921004 0.75256211 0.6317486  0.53202063 0.6484116\n",
      "  0.31675233 0.82705256 0.62213889 0.59747886 0.77098287 0.62072378\n",
      "  0.60990114 0.74033341 0.48977064 0.60710664 0.63400121 0.50614787\n",
      "  0.65504073 0.68524349 0.4578935  0.83552984 0.62213889 0.42273769\n",
      "  0.58805184 0.63400121 0.69070936 0.74315538 0.58805184 0.68085699\n",
      "  0.46080672 0.73315592 0.7018931  0.66949299 0.71282588 0.75256211\n",
      "  0.67631451 0.46446906 0.32349762 0.79172383 0.43495696 0.70496635\n",
      "  0.71178907 0.36837267 0.48977064 0.70538949 0.52545316 0.74033341\n",
      "  0.30792752 0.53568665 0.64232057 0.76013375 0.39817135 0.42037915\n",
      "  0.78928418 0.78928418 0.60029676 0.6317486  0.60029676 0.71178907\n",
      "  0.46005793 0.57570255 0.66033868 0.77098287 0.8391199  0.53760556\n",
      "  0.47950845 0.82914959 0.78486715 0.69384761 0.49638482 0.79678831\n",
      "  0.33255423 0.75256211 0.47027997 0.47103088 0.74315538 0.75075233\n",
      "  0.71973403 0.43155921 0.43495696 0.46446906 0.47950845 0.59442167\n",
      "  0.54338631 0.52760001 0.4578935  0.67953106 0.40805752 0.63400121\n",
      "  0.66622518 0.53394151 0.47470294 0.70538949 0.46810913 0.71178907\n",
      "  0.6134004  0.70250568 0.64232057 0.64348212]\n",
      " [0.21728149 0.64295352 0.82181927 0.46026223 0.85753607 0.13124454\n",
      "  0.48790958 0.52918527 0.33143538 0.16778862 0.85397505 0.86028191\n",
      "  0.85116388 0.38157453 0.42981033 0.44391359 0.70163656 0.70998126\n",
      "  0.51951891 0.95626478 0.19134011 0.45310403 0.33143538 0.12688812\n",
      "  0.23341417 0.70163656 0.23010739 0.29697264 0.23341417 0.21728149\n",
      "  0.62895276 0.82972835 0.23773006 0.88989882 0.79352421 0.82181927\n",
      "  0.92706587 0.53714181 0.59974164 0.27153553 0.61342213 0.17594726\n",
      "  0.46589604 0.74180066 0.42981033 0.35677532 0.70550999 0.38157453\n",
      "  0.35645492 0.80472457 0.47865985 0.88806587 0.10283073 0.4832703\n",
      "  0.35252458 0.35252458 0.59089612 0.46026223 0.59089612 0.46589604\n",
      "  0.66799316 0.53252121 0.82452268 0.85397505 0.67549869 0.08897491\n",
      "  0.30469524 0.43486933 0.17810213 0.16986416 0.7871016  0.36956441\n",
      "  0.72047156 0.82181927 0.77583118 0.74462352 0.29697264 0.62582143\n",
      "  0.36612494 0.50173268 0.61342213 0.53714181 0.30469524 0.43343898\n",
      "  0.86632503 0.91255635 0.19134011 0.89693121 0.16468874 0.70163656\n",
      "  0.92191056 0.12484472 0.66624596 0.35677532 0.28927398 0.46589604\n",
      "  0.79655063 0.26034483 0.47865985 0.80178948]\n",
      " [0.36579827 0.92197858 0.22713288 0.74875242 0.59355559 0.20211162\n",
      "  0.38681012 0.20964899 0.87076346 0.89273526 0.64288178 0.78664087\n",
      "  0.21399859 0.92462808 0.92212619 0.36664188 0.5009108  0.64335316\n",
      "  0.94806526 0.71919989 0.81717459 0.78603348 0.87076346 0.94574764\n",
      "  0.9633405  0.5009108  0.88650209 0.926177   0.9633405  0.36579827\n",
      "  0.67764769 0.33641304 0.28461348 0.30426003 0.07643602 0.22713288\n",
      "  0.85273972 0.68252944 0.89308095 0.14728423 0.2899478  0.28920408\n",
      "  0.88268242 0.49207037 0.92212619 0.36233009 0.77151372 0.92462808\n",
      "  0.58783335 0.59895717 0.97582003 0.1150333  0.73997977 0.15789482\n",
      "  0.14448843 0.14448843 0.79651463 0.74875242 0.79651463 0.88268242\n",
      "  0.71439541 0.38988051 0.49716582 0.64288178 0.61372212 0.84124655\n",
      "  0.96399224 0.21339114 0.28083862 0.88874023 0.85064792 0.69578033\n",
      "  0.78698537 0.22713288 0.52524648 0.48181452 0.926177   0.4659912\n",
      "  0.7043995  0.71744201 0.2899478  0.68252944 0.96399224 0.91912665\n",
      "  0.95186748 0.62950443 0.81717459 0.85553514 0.55727425 0.5009108\n",
      "  0.29953116 0.83822692 0.48741869 0.36233009 0.66408783 0.88268242\n",
      "  0.21779698 0.77940129 0.97582003 0.30744036]\n",
      " [0.88220638 0.88442145 0.62332558 0.84435361 0.76056212 0.84946771\n",
      "  0.81637303 0.7369378  0.84550605 0.5530896  0.57744924 0.93428158\n",
      "  0.92284589 0.73722537 0.80088225 0.8020457  0.58235062 0.41803266\n",
      "  0.81751599 0.81622332 0.77498345 0.70004914 0.84550605 0.90024298\n",
      "  0.93481016 0.58235062 0.89900642 0.66290671 0.93481016 0.88220638\n",
      "  0.91045439 0.8112498  0.6400995  0.72545796 0.83882729 0.62332558\n",
      "  0.81753903 0.87695153 0.88288397 0.86169344 0.88363789 0.55489622\n",
      "  0.96044177 0.66655642 0.80088225 0.93471967 0.69194691 0.73722537\n",
      "  0.81768791 0.69006889 0.86573065 0.6212582  0.91616178 0.73402843\n",
      "  0.89887161 0.89887161 0.78510871 0.84435361 0.78510871 0.96044177\n",
      "  0.86247063 0.81563759 0.72720632 0.57744924 0.76746615 0.79702418\n",
      "  0.80228119 0.66257503 0.86273836 0.8618702  0.89273844 0.91352778\n",
      "  0.88197143 0.62332558 0.861424   0.90973471 0.66290671 0.86555806\n",
      "  0.67693935 0.7663652  0.88363789 0.87695153 0.80228119 0.95300445\n",
      "  0.79059324 0.73649964 0.77498345 0.7584939  0.91548371 0.58235062\n",
      "  0.79034746 0.84853034 0.87599926 0.93471967 0.77344591 0.96044177\n",
      "  0.89343658 0.86081973 0.86573065 0.5802098 ]\n",
      " [0.74879687 0.34826227 0.64926998 0.64656842 0.74292153 0.79104854\n",
      "  0.93432705 0.51276968 0.67073499 0.86481943 0.62866162 0.51102055\n",
      "  0.60997441 0.61669292 0.74124343 0.6760151  0.80897939 0.90075191\n",
      "  0.62589278 0.43119224 0.84165591 0.51730795 0.67073499 0.85751527\n",
      "  0.69756188 0.80897939 0.66576458 0.71029551 0.69756188 0.74879687\n",
      "  0.79935804 0.65305909 0.75356213 0.65812142 0.6730177  0.64926998\n",
      "  0.45773449 0.85858318 0.86184976 0.66506104 0.8196261  0.82331734\n",
      "  0.3981617  0.88291189 0.74124343 0.60139227 0.83061836 0.61669292\n",
      "  0.94062445 0.81494899 0.55005027 0.62441017 0.86808783 0.92473663\n",
      "  0.56577794 0.56577794 0.82744055 0.64656842 0.82744055 0.3981617\n",
      "  0.80603726 0.83982787 0.68188669 0.62866162 0.38709317 0.88789973\n",
      "  0.76132607 0.61594568 0.68857219 0.7521991  0.76591957 0.46543779\n",
      "  0.84854276 0.64926998 0.78867245 0.78155732 0.71029551 0.44433888\n",
      "  0.64727081 0.89142694 0.8196261  0.85858318 0.76132607 0.57613024\n",
      "  0.65883205 0.66420748 0.84165591 0.56262404 0.8552808  0.80897939\n",
      "  0.55814792 0.83864494 0.84501811 0.60139227 0.82679469 0.3981617\n",
      "  0.70443131 0.73161922 0.55005027 0.79180995]\n",
      " [0.95635606 0.63123119 0.9001673  0.89938191 0.93530341 0.63134075\n",
      "  0.57824179 0.83317224 0.90890978 0.60106278 0.66608731 0.74411162\n",
      "  0.78426504 0.94346282 0.65195041 0.38491525 0.97413632 0.68582287\n",
      "  0.66414747 0.71264589 0.74476983 0.5522472  0.90890978 0.40408483\n",
      "  0.69867839 0.97413632 0.94602864 0.83745072 0.69867839 0.95635606\n",
      "  0.94429364 0.65241741 0.61982659 0.51655853 0.8945634  0.9001673\n",
      "  0.73463918 0.83957448 0.78033002 0.61825824 0.54270325 0.3348199\n",
      "  0.64259911 0.80871414 0.65195041 0.40966083 0.83284204 0.94346282\n",
      "  0.60481762 0.81695995 0.87730241 0.88983582 0.75400173 0.91200511\n",
      "  0.83989395 0.83989395 0.8974612  0.89938191 0.8974612  0.64259911\n",
      "  0.2079522  0.97534646 0.54395573 0.66608731 0.78159954 0.61279022\n",
      "  0.67648026 0.60659009 0.64386553 0.84403231 0.77061365 0.80755372\n",
      "  0.76089106 0.9001673  0.19041234 0.93821527 0.83745072 0.68151632\n",
      "  0.53880827 0.89236411 0.54270325 0.83957448 0.67648026 0.87059953\n",
      "  0.9204089  0.42037931 0.74476983 0.46083332 0.73303004 0.97413632\n",
      "  0.77583121 0.8367624  0.82419704 0.40966083 0.72329993 0.64259911\n",
      "  0.52882277 0.82899513 0.87730241 0.97121496]\n",
      " [0.6359256  0.5953003  0.8432863  0.20445237 0.23630287 0.92516052\n",
      "  0.35874319 0.79385125 0.22974589 0.82710568 0.86798459 0.67942741\n",
      "  0.49417083 0.75998558 0.52612791 0.61046177 0.67100388 0.83228958\n",
      "  0.23897154 0.60410771 0.40806889 0.84522319 0.22974589 0.50199933\n",
      "  0.30368842 0.67100388 0.79120145 0.67424755 0.30368842 0.6359256\n",
      "  0.30058249 0.87145537 0.91173772 0.3479549  0.84729217 0.8432863\n",
      "  0.63912292 0.21931435 0.64994035 0.75077304 0.72380677 0.87100776\n",
      "  0.63772484 0.41696022 0.52612791 0.34658205 0.19011721 0.75998558\n",
      "  0.39367889 0.16823364 0.3579584  0.82258159 0.45205476 0.82936795\n",
      "  0.82169597 0.82169597 0.74888616 0.20445237 0.74888616 0.63772484\n",
      "  0.76202126 0.70936689 0.38246662 0.86798459 0.87801958 0.85130005\n",
      "  0.56305156 0.71568497 0.77759202 0.71239445 0.31150229 0.90907063\n",
      "  0.61534303 0.8432863  0.73396706 0.2702263  0.67424755 0.40406913\n",
      "  0.95075974 0.91337941 0.72380677 0.21931435 0.56305156 0.36502885\n",
      "  0.40164934 0.77909542 0.40806889 0.53653938 0.4154886  0.67100388\n",
      "  0.44944832 0.89752067 0.19487871 0.34658205 0.37264102 0.63772484\n",
      "  0.38972731 0.6809395  0.3579584  0.63732668]\n",
      " [0.78864646 0.64989595 0.72472253 0.91238994 0.8829772  0.79536283\n",
      "  0.78584934 0.88664446 0.82870928 0.45069494 0.27663235 0.43520863\n",
      "  0.83850092 0.49150343 0.86132876 0.95893276 0.68672488 0.56132967\n",
      "  0.60203085 0.74326444 0.90032029 0.34547553 0.82870928 0.42912531\n",
      "  0.28706083 0.68672488 0.35641433 0.30530865 0.28706083 0.78864646\n",
      "  0.66758765 0.32048684 0.87152739 0.80470005 0.76453438 0.72472253\n",
      "  0.57354775 0.47730051 0.54500116 0.67079619 0.81827932 0.75516961\n",
      "  0.51539768 0.93371526 0.86132876 0.76516394 0.61446293 0.49150343\n",
      "  0.6302806  0.77430403 0.60716826 0.85000927 0.83805361 0.83463316\n",
      "  0.817566   0.817566   0.15428809 0.91238994 0.15428809 0.51539768\n",
      "  0.39543936 0.55672482 0.65684561 0.27663235 0.71419213 0.31976871\n",
      "  0.74263432 0.7805304  0.48628439 0.20115099 0.38573436 0.39943881\n",
      "  0.72054318 0.72472253 0.58471511 0.81213744 0.30530865 0.92596709\n",
      "  0.68426649 0.42826802 0.81827932 0.47730051 0.74263432 0.65590934\n",
      "  0.52826571 0.84386698 0.90032029 0.37946631 0.91762307 0.68672488\n",
      "  0.90061601 0.50832922 0.66280157 0.76516394 0.95108191 0.51539768\n",
      "  0.70244361 0.35150016 0.60716826 0.82513265]\n",
      " [0.468881   0.62404186 0.77488607 0.44367501 0.46418688 0.64432566\n",
      "  0.69202371 0.71582814 0.50080651 0.46036009 0.87862016 0.69284481\n",
      "  0.79460369 0.29151498 0.14451248 0.56539306 0.49091604 0.42418485\n",
      "  0.62645963 0.58904415 0.31434496 0.8695137  0.50080651 0.54670992\n",
      "  0.72521831 0.49091604 0.33982227 0.65117695 0.72521831 0.468881\n",
      "  0.57687046 0.87802862 0.59151637 0.93346685 0.77391906 0.77488607\n",
      "  0.64325081 0.86082913 0.22406962 0.93462872 0.68982019 0.86789707\n",
      "  0.67495685 0.2836134  0.14451248 0.94171699 0.83177258 0.29151498\n",
      "  0.73867319 0.79717909 0.31740795 0.73235874 0.36448913 0.30470657\n",
      "  0.75911106 0.75911106 0.71726391 0.44367501 0.71726391 0.67495685\n",
      "  0.82384199 0.54676575 0.94637845 0.87862016 0.53865404 0.51625879\n",
      "  0.17525687 0.91954012 0.94732756 0.70018266 0.69503635 0.64756726\n",
      "  0.18670071 0.77488607 0.78803327 0.52010241 0.65117695 0.74004239\n",
      "  0.40162518 0.20352061 0.68982019 0.86082913 0.17525687 0.31620991\n",
      "  0.33560378 0.39577653 0.31434496 0.89107373 0.31315318 0.49091604\n",
      "  0.75564525 0.19043347 0.83099664 0.94171699 0.26710315 0.67495685\n",
      "  0.94609687 0.64991861 0.31740795 0.43393204]]\n",
      "z_s_batch: [[ 1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "   1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.\n",
      "   1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
      "   1. -1. -1.  1. -1.  1.  1.  1. -1. -1.]\n",
      " [ 1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  -1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  -1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.\n",
      "   1. -1. -1. -1.  1. -1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.\n",
      "   1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.]]\n",
      "y_s_batch: [[-1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.\n",
      "  -1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
      "   1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.\n",
      "   1.  1. -1. -1.  1. -1. -1. -1.  1.  1.]\n",
      " [-1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  -1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.]\n",
      " [ 1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1. -1. -1.]\n",
      " [-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
      "  -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.]]\n",
      "x_s_batch: [[ 1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1. -1.\n",
      "   1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.\n",
      "  -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.]\n",
      " [-1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      "  -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.]\n",
      " [-1.  1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
      "   1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1.  1. -1.]\n",
      " [-1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1.  1. -1.  1.\n",
      "  -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.\n",
      "  -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.]\n",
      " [-1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      "   1. -1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  -1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
      "   1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1.  1. -1.  1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "   1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.]\n",
      " [-1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.\n",
      "  -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.\n",
      "  -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.]]\n",
      "d_s_batch: [[-1  1 -1  1  1 -1  1  1  1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1  1\n",
      "   1 -1 -1  1  1 -1 -1  1  1  1 -1 -1  1 -1 -1  1 -1  1  1  1  1  1  1  1\n",
      "  -1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1 -1\n",
      "   1 -1  1 -1  1  1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1 -1  1  1  1  1\n",
      "   1  1  1 -1]\n",
      " [ 1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1 -1\n",
      "   1  1  1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1 -1  1  1 -1 -1  1  1  1\n",
      "  -1  1  1  1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1 -1  1\n",
      "  -1  1 -1 -1  1  1  1 -1 -1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1  1 -1  1\n",
      "   1  1  1  1]\n",
      " [-1  1  1 -1  1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1\n",
      "  -1  1 -1 -1 -1 -1  1  1 -1  1  1  1  1  1  1 -1  1 -1 -1  1 -1 -1  1 -1\n",
      "  -1  1 -1  1 -1 -1 -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1 -1 -1 -1  1 -1\n",
      "   1  1  1  1 -1  1 -1  1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1 -1\n",
      "   1 -1 -1  1]\n",
      " [-1  1 -1  1  1 -1 -1 -1  1  1  1  1 -1  1  1 -1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1  1 -1  1  1\n",
      "   1  1  1 -1  1 -1 -1 -1  1  1  1  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1\n",
      "   1 -1  1 -1  1 -1  1  1 -1  1  1  1  1  1  1  1  1  1 -1  1 -1 -1  1  1\n",
      "  -1  1  1 -1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1]\n",
      " [ 1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1 -1\n",
      "   1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1\n",
      "   1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1 -1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1 -1  1  1  1  1  1  1  1  1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1\n",
      "   1  1  1  1]\n",
      " [ 1  1  1 -1 -1  1 -1  1 -1  1  1  1 -1  1  1  1  1  1 -1  1 -1  1 -1  1\n",
      "  -1  1  1  1 -1  1 -1  1  1 -1  1  1  1 -1  1  1  1  1  1 -1  1 -1 -1  1\n",
      "  -1 -1 -1  1 -1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1\n",
      "   1  1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1 -1  1\n",
      "  -1  1 -1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1 -1 -1 -1  1 -1  1  1  1  1  1  1  1 -1  1 -1\n",
      "  -1  1 -1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1 -1\n",
      "   1  1  1  1  1  1  1  1 -1  1 -1  1 -1  1  1 -1  1 -1  1  1 -1 -1 -1 -1\n",
      "   1  1  1  1 -1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1\n",
      "   1 -1  1  1]\n",
      " [-1  1  1 -1 -1  1  1  1  1 -1  1  1  1 -1 -1  1 -1 -1  1  1 -1  1  1  1\n",
      "   1 -1 -1  1  1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1 -1 -1  1  1 -1\n",
      "   1  1 -1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1\n",
      "  -1  1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1 -1 -1  1 -1  1  1 -1  1\n",
      "   1  1 -1 -1]]\n",
      "P_batch: [1.18114819e-01 1.44972821e-01 2.79254685e-02 9.66199163e-03\n",
      " 1.03350042e-01 9.71349997e-03 9.46908218e-03 5.18442862e-02\n",
      " 4.97771216e-02 5.85388038e-02 4.91105192e-02 1.83293632e-02\n",
      " 5.54091226e-02 1.55081306e-01 2.40343286e-02 1.86362400e-02\n",
      " 1.51149150e-02 1.18609042e-02 9.92435497e-02 4.57153150e-02\n",
      " 1.35474401e-02 6.64815518e-03 2.67460314e-01 2.23086362e-02\n",
      " 1.43616019e+00 1.10151697e-03 8.31321531e-02 2.60265403e-02\n",
      " 8.29571494e-01 7.48223998e-02 6.53563012e-02 1.24922231e-02\n",
      " 7.35003351e-02 3.29345629e-01 2.71363663e-02 1.45659308e-01\n",
      " 3.94667701e-03 2.73645883e-02 7.44007265e-02 4.08399214e-01\n",
      " 2.56410939e-02 1.88731158e-01 6.00801564e-02 2.74081773e-02\n",
      " 4.30810764e-02 9.48557914e-02 1.95163474e-02 2.68425926e-01\n",
      " 8.23006556e-03 5.96369736e-02 9.64251974e-02 2.38076275e-01\n",
      " 8.00165353e-02 1.60685010e-01 1.84516988e-01 1.03774201e-01\n",
      " 7.91129561e-02 2.05229797e-02 2.57969109e-02 1.57816216e-01\n",
      " 3.25404282e-03 4.72690883e-02 1.67963185e-02 2.61036085e-01\n",
      " 1.89201025e-01 9.23021063e-02 1.04489800e-02 3.19213497e-02\n",
      " 2.71863751e-01 1.43016810e-01 1.01090705e-01 2.56013579e-02\n",
      " 2.90827676e-02 4.54988907e-02 5.13197272e-03 3.22810751e-02\n",
      " 1.86000209e-01 6.48561677e-02 1.83089813e-02 6.27358715e-03\n",
      " 1.44020717e-03 3.56825745e-02 4.55966178e-02 8.81870659e-02\n",
      " 3.85403799e-02 1.35577305e-02 4.72610811e-02 2.73349337e-01\n",
      " 7.88930889e-02 6.16602488e-02 4.71233473e-02 4.97475575e-02\n",
      " 1.75757535e-02 7.79193630e-02 6.83168184e-02 3.28536395e-02\n",
      " 8.92598813e-02 1.54694672e-02 1.03289340e+00 3.04814056e-02]\n"
     ]
    }
   ],
   "source": [
    "p_4_batch,p_3_batch,p_2_batch,p_1_batch,z_s_batch,y_s_batch,x_s_batch,d_s_batch,P_batch = sleep_forward_batch_deterministic(Theta,Theta_43,Theta_32,Theta_21,b_43,b_32,b_21,n_z,n_y,n_x,n_d,test_size)\n",
    "print (\"p_4_batch: \" + str(p_4_batch))\n",
    "print (\"p_3_batch: \" + str(p_3_batch))\n",
    "print (\"p_2_batch: \" + str(p_2_batch))\n",
    "print (\"p_1_batch: \" + str(p_1_batch))\n",
    "print (\"z_s_batch: \" + str(z_s_batch))\n",
    "print (\"y_s_batch: \" + str(y_s_batch))\n",
    "print (\"x_s_batch: \" + str(x_s_batch))\n",
    "print (\"d_s_batch: \" + str(d_s_batch))\n",
    "print (\"P_batch: \" + str(P_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check with the rules (well-formedness rules)\n",
    "\n",
    "1. Start with 1\n",
    "2. Forbid 00100 (no 100, 001 on the boundary)\n",
    "3. Forbid 0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = (d_s_batch+1)/2\n",
    "np.array_equal(test_set[0:3,4], [0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 1.],\n",
       "       [0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      "  1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      "  0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      "  1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      "  1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      "  0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      "  1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      "  1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      "  1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      "  0. 1. 1.]]\n",
      "[1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 5 1 3 1 1 4 4 1 1 1 1 1 1 2 2 1 5 3 2 5 2\n",
      " 3 6 1 1 4 1 2 1 4 1 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 51)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, counts = np.unique(test_set, axis=1,return_counts=True)\n",
    "print(st)\n",
    "print(counts)\n",
    "st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_rule1 = 0\n",
    "violation_rule1_index = []\n",
    "violation_rule2 = 0\n",
    "violation_rule2_index = []\n",
    "violation_rule3 = 0\n",
    "violation_rule3_index = []\n",
    "valid_num = 0\n",
    "valid_index = []\n",
    "\n",
    "for i in range(test_set.shape[1]):\n",
    "    flag = 0\n",
    "    pattern = test_set[:,i]\n",
    "    if pattern[0] != 1:\n",
    "        violation_rule1 += 1\n",
    "        violation_rule1_index.append(i)\n",
    "        flag = 1\n",
    "    if np.array_equal(pattern[0:3], [1,0,0]) or np.array_equal(pattern[-3:], [0,0,1]):\n",
    "        violation_rule2 += 1\n",
    "        violation_rule2_index.append(i)\n",
    "        flag = 1\n",
    "    for j in range(5):\n",
    "        if np.array_equal(pattern[j:j+5],[0,0,1,0,0]):\n",
    "            violation_rule2 += 1\n",
    "            violation_rule2_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    for j in range(6):\n",
    "        if np.array_equal(pattern[j:j+4],[0,0,0,0]):\n",
    "            violation_rule3 += 1\n",
    "            violation_rule3_index.append(i)\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 0:\n",
    "        valid_num += 1\n",
    "        valid_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation_rule1: 28\n",
      "violation_rule1_index: [0, 2, 5, 11, 12, 16, 25, 26, 29, 30, 34, 35, 37, 38, 40, 48, 52, 53, 61, 71, 73, 75, 79, 80, 81, 89, 91, 99]\n",
      "violation_rule2: 15\n",
      "violation_rule2_index: [6, 14, 20, 23, 24, 28, 37, 44, 66, 70, 81, 82, 86, 88, 94]\n",
      "violation_rule3: 1\n",
      "violation_rule3_index: [53]\n",
      "valid_num: 59\n",
      "valid_index: [1, 3, 4, 7, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22, 27, 31, 32, 33, 36, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 72, 74, 76, 77, 78, 83, 84, 85, 87, 90, 92, 93, 95, 96, 97, 98]\n",
      "valid_percentage: 0.59\n"
     ]
    }
   ],
   "source": [
    "print (\"violation_rule1: \" + str(violation_rule1))\n",
    "print (\"violation_rule1_index: \" + str(violation_rule1_index))\n",
    "print (\"violation_rule2: \" + str(violation_rule2))\n",
    "print (\"violation_rule2_index: \" + str(violation_rule2_index))\n",
    "print (\"violation_rule3: \" + str(violation_rule3))\n",
    "print (\"violation_rule3_index: \" + str(violation_rule3_index))\n",
    "print (\"valid_num: \" + str(valid_num))\n",
    "print (\"valid_index: \" + str(valid_index))\n",
    "print (\"valid_percentage: \" + str(valid_num/test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1.])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[-3:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1., 2.]), array([3., 4.]), array([5., 6., 7.])]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(8.0)\n",
    "np.split(x, [3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1., -1., ...,  1., -1.,  1.],\n",
       "       [-1.,  1.,  1., ..., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1., -1., -1.],\n",
       "       ...,\n",
       "       [-1., -1., -1., ..., -1.,  1.,  1.],\n",
       "       [-1.,  1.,  1., ..., -1.,  1.,  1.],\n",
       "       [-1., -1.,  1., ..., -1.,  1.,  1.]])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
