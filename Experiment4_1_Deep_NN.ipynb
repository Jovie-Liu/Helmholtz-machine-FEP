{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d61b41c",
   "metadata": {},
   "source": [
    "***\n",
    "*Project:* Helmholtz Machine on Niche Construction\n",
    "\n",
    "*Author:* Jingwei Liu, Computer Music Ph.D., UC San Diego\n",
    "***\n",
    "\n",
    "# <span style=\"background-color:darkorange; color:white; padding:2px 6px\">Experiment 4_1</span> \n",
    "\n",
    "# Helmholtz Machine Test on Deep Structure\n",
    "\n",
    "Instead of the toy model on well-formed set, we and more randomness to the dataset with Baysian mixture of Gaussians.\n",
    "\n",
    "*Created:* December 24, 2023\n",
    "\n",
    "*Updated:* December 24, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690d8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd127c6",
   "metadata": {},
   "source": [
    "<img src=\"muti-bernoulli.jpg\" style=\"width:800px\">\n",
    "<caption><center> **Figure 2**: Multivariate Bernoulli Distribution. In wake phase, we go from input $\\mathbf{x}$ to output $\\mathbf{y}$ by weight $\\Phi$. Blue neurons represent instantiation layers, where each neuron takes binary value and is computed as an independent Bernoulli variable. Orange neurons are inserted activations, which transform a shallow neural network with one-step prameter updating to deep neural network with backpropogation.\n",
    "</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0da6a",
   "metadata": {},
   "source": [
    "Notations: \n",
    "- Bold lower-case math symbols represent column vectors\n",
    "- Bold upper-case math symbols represent matrices\n",
    "- “$\\centerdot$” represents element-wise multiplication\n",
    "- \"$\\times$\" or \"\" represents matrix multiplication\n",
    "- $\\otimes$ represents outer product\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log Q &= \\sum_{n} \\frac{y_n-b}{a-b} \\log [q_n] + \\frac{a-y_n}{a-b} \\log [1-q_n] \\\\\n",
    "\\frac{\\partial \\log Q}{\\partial \\mathbf{q}} &= \\frac{\\mathbf{y}-b}{a-b} \\centerdot \\frac{1}{\\mathbf{q}} - \\frac{a-\\mathbf{y}}{a-b} \\centerdot \\frac{1}{1-\\mathbf{q}} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "\\mathbf{q} = \\sigma(\\Phi^{l3,y}\\times\\mathbf{z^3})\n",
    "$$\n",
    "\n",
    "where $\\Phi^{l3,y}$ is a matrix and $\\sigma'(\\centerdot) = \\sigma(\\centerdot)(1-\\sigma(\\centerdot))$，\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{q}}{\\partial \\sigma(\\mathbf{\\centerdot})} = \\mathbf{q}\\centerdot(1-\\mathbf{q})\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log Q}{\\partial \\sigma(\\mathbf{\\centerdot})} = \\frac{\\partial \\log Q}{\\partial \\mathbf{q}} \\centerdot \\frac{\\partial \\mathbf{q}}{\\partial \\sigma(\\mathbf{\\centerdot})} = \\frac{\\mathbf{y}-b}{a-b} - \\mathbf{q}\n",
    "$$\n",
    "\n",
    "The objective cross entropy is $L = -\\log Q$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\sigma(\\mathbf{\\centerdot})} = \\mathbf{q} - \\frac{\\mathbf{y}-b}{a-b}\n",
    "$$\n",
    "\n",
    "Let's denote $\\mathbf{q} - \\frac{\\mathbf{y}-b}{a-b}$ as $\\mathbf{u}$, which in more general represents the **element-wise** product of all previous derivative computations $\\frac{\\partial L}{\\partial \\mathbf{q}}$ and the derivative of the activation function $\\frac{\\partial \\mathbf{q}}{\\partial g(\\mathbf{\\centerdot})}$ (times $c$) if the activation layer is scaled by $c$. The activation function can be replaced by $tanh(\\centerdot)$, whose derivative is $tanh'(\\centerdot) = 1-tanh^2(\\centerdot)$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\Phi} &= \\mathbf{u} \\otimes \\mathbf{z} \\\\\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}} &= \\Phi^T \\mathbf{u}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878beb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c40a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_Bernoulli_update(x,y,parameter_set,lr,value_set,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- input instantiation layer, numpy array of shape (n,1)\n",
    "    y -- target instantiation layer, numpy array of shape (m,1)\n",
    "    parameter_set -- parameters from x to y. Python dictionary of length l+1, l is the number of inserted layers. \n",
    "    The keys are ordered sequentially from layer x to y.\n",
    "    lr -- learning rate, decimals\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation (data) bias, MLP bias], taking binary value in {True, False}. For example, \n",
    "    [False,True] means no instantiation bias but has MLP (data) bias\n",
    "    \n",
    "    Returns:\n",
    "    parameter_set -- updated parameters\n",
    "    loss -- value of loss function before updating, a number\n",
    "    \"\"\"\n",
    "    \n",
    "    inst_bias = bias[0]\n",
    "    mlp_bias = bias[1]\n",
    "    a = value_set[0]\n",
    "    b = value_set[1]\n",
    "    l = len(parameter_set)\n",
    "    keys = [*parameter_set]\n",
    "    G = {'z0': x}\n",
    "    g = x\n",
    "    \n",
    "    for i in range(l-1):\n",
    "        phi = parameter_set[keys[i]]\n",
    "        if activation_type == \"sigmoid\":\n",
    "            if mlp_bias == True:\n",
    "                g = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)+b  # scale to [b,a]\n",
    "            else:\n",
    "                g = sigmoid(np.matmul(phi[:,:-1],g))*(a-b)+b\n",
    "        elif activation_type == \"tanh\":\n",
    "            if mlp_bias == True:\n",
    "                g = np.tanh(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)/2+(a+b)/2 # scale to [b,a]\n",
    "            else:\n",
    "                g = np.tanh(np.matmul(phi[:,:-1],g))*(a-b)/2+(a+b)/2\n",
    "        G['z'+str(i+1)] = g\n",
    "\n",
    "    phi = parameter_set[keys[l-1]]\n",
    "    if inst_bias == True:\n",
    "        q = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))\n",
    "    else:\n",
    "        q = sigmoid(np.matmul(phi[:,:-1],g))\n",
    "        \n",
    "    # derivatives\n",
    "    u = q - (y-b)/(a-b)\n",
    "    loss = np.sum(np.abs(u))  # for visulization\n",
    "    for i in range(l-1,0,-1):\n",
    "        phi = parameter_set[keys[i]][:,:-1]\n",
    "        dz = np.matmul(phi.T,u)\n",
    "        z = G['z'+str(i)]\n",
    "        parameter_set[keys[i]] -= lr * np.outer(u,np.append(z,[[1]], axis=0))\n",
    "        if activation_type == \"sigmoid\":\n",
    "            u = dz * z * (1-z) * (a-b)\n",
    "        elif activation_type == \"tanh\":\n",
    "            u = dz * (1-z**2) * (a-b)/2\n",
    "            \n",
    "    parameter_set[keys[0]] -= lr * np.outer(u,np.append(x,[[1]], axis=0))\n",
    "    \n",
    "    return parameter_set,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e30c2a",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f44f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 4\n",
    "value_set = [1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d75a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "        -1.,  1., -1.],\n",
       "       [ 1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1., -1., -1.],\n",
       "       [ 1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1., -1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_set = ut.all_comb(n_y, value_set)\n",
    "y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e916c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1],\n",
       "       [ 1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1],\n",
       "       [ 1, -1,  1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1],\n",
       "       [ 1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1],\n",
       "       [-1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1],\n",
       "       [-1, -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1,  1,  1],\n",
       "       [ 1,  1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1,  1],\n",
       "       [-1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1, -1, -1, -1,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_x = 8\n",
    "x_set = ut.random_generate(3,n_x,2**n_y,value_set)\n",
    "x_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5f8ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 4, 1],\n",
       "       [6, 0, 0],\n",
       "       [5, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure = [[8,4,1],\n",
    "             [6,0,0],\n",
    "             [5,0,0]]\n",
    "n_dz = np.array(structure)\n",
    "n_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f188b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_type = \"random\"\n",
    "Phi, Theta = ut.parameter_initialization(init_type,n_dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "15ac3df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Phi_01_1': array([[ 1.03600516, -1.4494836 , -0.04444709, -0.21871712, -0.19183653,\n",
       "         -1.4078667 , -1.08134628,  1.22709755,  0.1136707 ],\n",
       "        [ 0.59347517, -0.10852673,  0.92424733,  1.54242032,  0.7231468 ,\n",
       "          0.21907053, -0.1525631 ,  0.06557071,  1.38991575],\n",
       "        [-0.67111943,  0.70027428, -0.65541812, -1.16465332, -1.26014503,\n",
       "          1.25329573,  0.06115812, -1.05875072,  0.96773782],\n",
       "        [ 2.45908271, -0.65074003,  2.4798748 , -0.46928134, -0.16622484,\n",
       "         -1.81304637, -0.48427655, -0.4585939 , -0.45546152],\n",
       "        [-0.12193521, -0.90515638, -0.18679707, -1.25647995,  0.0433639 ,\n",
       "          1.36869443, -0.20043603,  0.62497758,  0.93427925],\n",
       "        [-0.00583617, -0.54156307, -0.75461135, -1.15417641, -0.14525051,\n",
       "         -0.54347223,  1.12043731,  2.05341483,  0.76629276]]),\n",
       " 'Phi_01_2': array([[ 0.43405654,  1.63621071, -1.00711939,  0.20765131, -0.10994907,\n",
       "         -2.3777785 , -0.86381285],\n",
       "        [ 1.6245528 ,  1.35600366,  1.06126593, -1.35723596,  1.16552685,\n",
       "          0.27287841,  0.50822337],\n",
       "        [-1.02568115,  0.75983988,  0.4486129 ,  0.90856906,  0.81135775,\n",
       "         -0.70337398,  1.12173037],\n",
       "        [ 0.14317318, -0.78164823,  0.16553907, -0.03994141, -0.9411777 ,\n",
       "         -0.70572386, -1.254127  ],\n",
       "        [-2.08588035, -0.39606594, -0.07706901, -0.33760788,  1.32148468,\n",
       "          1.42583606, -1.03042695]]),\n",
       " 'Phi_01_3': array([[ 1.14605298,  0.57540549,  1.54840523,  0.34904392,  1.29391549,\n",
       "         -0.66476659],\n",
       "        [ 1.21931999, -2.60846617,  1.14475856, -1.22249784,  0.94208039,\n",
       "          0.90672524],\n",
       "        [-0.53980535, -0.03192418,  2.36020906,  0.2749873 ,  0.29852554,\n",
       "          0.56737232],\n",
       "        [ 0.05154551, -1.14512692,  0.04011595, -0.85260989, -1.95677179,\n",
       "         -0.30153381]]),\n",
       " 'Phi_12': array([[-0.18056634,  1.10325816,  0.37075963,  0.15426227,  2.37839564]])}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5feef7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Phi_01_1': array([[ 1.03600516, -1.4494836 , -0.04444709, -0.21871712, -0.19183653,\n",
       "         -1.4078667 , -1.08134628,  1.22709755,  0.1136707 ],\n",
       "        [ 0.59347517, -0.10852673,  0.92424733,  1.54242032,  0.7231468 ,\n",
       "          0.21907053, -0.1525631 ,  0.06557071,  1.38991575],\n",
       "        [-0.67111943,  0.70027428, -0.65541812, -1.16465332, -1.26014503,\n",
       "          1.25329573,  0.06115812, -1.05875072,  0.96773782],\n",
       "        [ 2.45908271, -0.65074003,  2.4798748 , -0.46928134, -0.16622484,\n",
       "         -1.81304637, -0.48427655, -0.4585939 , -0.45546152],\n",
       "        [-0.12193521, -0.90515638, -0.18679707, -1.25647995,  0.0433639 ,\n",
       "          1.36869443, -0.20043603,  0.62497758,  0.93427925],\n",
       "        [-0.00583617, -0.54156307, -0.75461135, -1.15417641, -0.14525051,\n",
       "         -0.54347223,  1.12043731,  2.05341483,  0.76629276]]),\n",
       " 'Phi_01_2': array([[ 0.43405654,  1.63621071, -1.00711939,  0.20765131, -0.10994907,\n",
       "         -2.3777785 , -0.86381285],\n",
       "        [ 1.6245528 ,  1.35600366,  1.06126593, -1.35723596,  1.16552685,\n",
       "          0.27287841,  0.50822337],\n",
       "        [-1.02568115,  0.75983988,  0.4486129 ,  0.90856906,  0.81135775,\n",
       "         -0.70337398,  1.12173037],\n",
       "        [ 0.14317318, -0.78164823,  0.16553907, -0.03994141, -0.9411777 ,\n",
       "         -0.70572386, -1.254127  ],\n",
       "        [-2.08588035, -0.39606594, -0.07706901, -0.33760788,  1.32148468,\n",
       "          1.42583606, -1.03042695]]),\n",
       " 'Phi_01_3': array([[ 1.14605298,  0.57540549,  1.54840523,  0.34904392,  1.29391549,\n",
       "         -0.66476659],\n",
       "        [ 1.21931999, -2.60846617,  1.14475856, -1.22249784,  0.94208039,\n",
       "          0.90672524],\n",
       "        [-0.53980535, -0.03192418,  2.36020906,  0.2749873 ,  0.29852554,\n",
       "          0.56737232],\n",
       "        [ 0.05154551, -1.14512692,  0.04011595, -0.85260989, -1.95677179,\n",
       "         -0.30153381]])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_set = {k: Phi[k] for k in [\"Phi_\" + str(0) + str(1) + \"_\" + str(j) for j in range(1,4)]}\n",
    "parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d51136e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "activation_type = 'tanh'\n",
    "bias = [True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1d7a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_set,loss = multi_Bernoulli_update(x_set[:,2:3],y_set[:,2:3],parameter_set,lr,value_set,activation_type,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b1efd656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Phi_01_1': array([[ 1.03412822, -1.44685152, -0.04181501, -0.22059406, -0.19371347,\n",
       "         -1.40523463, -1.08397835,  1.22446547,  0.11179376],\n",
       "        [ 0.55498396, -0.07003808,  0.96273598,  1.50392911,  0.68465559,\n",
       "          0.25755917, -0.19105174,  0.02708206,  1.35142454],\n",
       "        [-0.64770932,  0.72368753, -0.63200486, -1.14124321, -1.23673491,\n",
       "          1.27670899,  0.03774486, -1.08216398,  0.99114793],\n",
       "        [ 2.61151027, -0.80555735,  2.32505748, -0.31685379, -0.01379728,\n",
       "         -1.96786369, -0.32945923, -0.30377658, -0.30303397],\n",
       "        [-0.12730666, -0.90768393, -0.18932461, -1.26185141,  0.03799245,\n",
       "          1.36616689, -0.19790849,  0.62750512,  0.9289078 ],\n",
       "        [-0.00441149, -0.54299024, -0.75603852, -1.15275173, -0.14382582,\n",
       "         -0.5448994 ,  1.12186447,  2.05484199,  0.76771744]]),\n",
       " 'Phi_01_2': array([[ 1.27599386e-01,  1.35363115e+00, -6.99961185e-01,\n",
       "         -8.53874352e-02,  1.40069870e-01, -2.68426834e+00,\n",
       "         -1.17142371e+00],\n",
       "        [ 1.31804387e+00,  1.09324365e+00,  1.35921502e+00,\n",
       "         -1.60838407e+00,  1.40381825e+00, -3.38806373e-02,\n",
       "          2.23057771e-01],\n",
       "        [-5.76269246e-01,  1.17664010e+00, -1.37076748e-03,\n",
       "          1.32333797e+00,  4.38661112e-01, -2.53910368e-01,\n",
       "          1.57173189e+00],\n",
       "        [-3.29238525e-02, -8.87973188e-01,  3.18349493e-01,\n",
       "         -1.50126942e-01, -8.34888264e-01, -8.82406928e-01,\n",
       "         -1.37332791e+00],\n",
       "        [-2.10926424e+00, -4.13128406e-01, -5.54754701e-02,\n",
       "         -3.56078825e-01,  1.33757523e+00,  1.40240530e+00,\n",
       "         -1.04941864e+00]]),\n",
       " 'Phi_01_3': array([[ 1.23367238,  0.82005166,  1.40688678,  0.58479476,  1.58843116,\n",
       "         -0.96295443],\n",
       "        [ 1.15985057, -2.66367541,  1.13146391, -1.29985227,  0.83855895,\n",
       "          1.01032475],\n",
       "        [-0.41561922, -0.37860241,  2.36249898, -0.10884447, -0.22212432,\n",
       "          1.09722865],\n",
       "        [ 0.02191283, -1.27498028,  0.11721797, -0.9802114 , -2.11364342,\n",
       "         -0.14201402]])}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74a6093f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.832358851943358"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "242a19fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11482468038672713\n",
      "0.11385079074403776\n",
      "0.11289317666926531\n",
      "0.1119514360514471\n",
      "0.111025179836501\n",
      "0.11011403150474905\n",
      "0.10921762657318702\n",
      "0.10833561212114713\n",
      "0.10746764633808939\n",
      "0.10661339809233239\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    parameter_set,loss = multi_Bernoulli_update(x_set[:,2:3],y_set[:,2:3],parameter_set,lr,value_set,activation_type,bias)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6e63a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96514144],\n",
       "       [ 0.99996008],\n",
       "       [ 0.96935636],\n",
       "       [ 0.94893083],\n",
       "       [-0.27967865],\n",
       "       [-0.99997004]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = np.tanh(np.matmul(parameter_set['Phi_01_1'],np.append(x_set[:,2:3],[[1]], axis=0)))\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b48fdd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97043077],\n",
       "       [ 0.93691366],\n",
       "       [ 0.99983195],\n",
       "       [ 0.8304695 ],\n",
       "       [-0.9841447 ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = np.tanh(np.matmul(parameter_set['Phi_01_2'],np.append(z1,[[1]], axis=0)))\n",
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "54b18a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97399504],\n",
       "       [0.02226595],\n",
       "       [0.97908443],\n",
       "       [0.96341393]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sigmoid(np.matmul(parameter_set['Phi_01_3'],np.append(z2,[[1]], axis=0)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "60de1dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_set[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7cab3d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Phi_01_1': array([[ 1.06573372, -1.41478322, -0.00974671, -0.18898856, -0.16210797,\n",
       "         -1.37316633, -1.11604665,  1.19239717,  0.14339926],\n",
       "        [ 0.5535548 , -0.06856137,  0.96421269,  1.50249995,  0.68322643,\n",
       "          0.25903589, -0.19252846,  0.02560535,  1.34999538],\n",
       "        [-0.4585309 ,  0.91299425, -0.44269815, -0.95206479, -1.04755649,\n",
       "          1.4660157 , -0.15156185, -1.27147069,  1.18032635],\n",
       "        [ 2.5885674 , -0.85555704,  2.2750578 , -0.33979666, -0.03674015,\n",
       "         -2.01786338, -0.27945954, -0.2537769 , -0.32597684],\n",
       "        [-0.18425157, -0.80305546, -0.08469615, -1.31879631, -0.01895246,\n",
       "          1.47079535, -0.30253695,  0.52287666,  0.87196289],\n",
       "        [-0.00444796, -0.54304856, -0.75609685, -1.1527882 , -0.1438623 ,\n",
       "         -0.54495772,  1.1219228 ,  2.05490032,  0.76768096]]),\n",
       " 'Phi_01_2': array([[ 9.60050537e-02,  1.37463868e+00, -6.68313921e-01,\n",
       "         -6.54621095e-02,  1.37786036e-01, -2.71674185e+00,\n",
       "         -1.15046003e+00],\n",
       "        [ 8.50457374e-01,  1.39934084e+00,  1.77774011e+00,\n",
       "         -1.31325558e+00,  1.36957440e+00, -5.11176924e-01,\n",
       "          5.28504220e-01],\n",
       "        [-5.75317584e-01,  1.17819781e+00, -2.32153311e-03,\n",
       "          1.32483335e+00,  4.37760251e-01, -2.52967786e-01,\n",
       "          1.57329940e+00],\n",
       "        [-4.00884210e-01, -5.15364367e-01,  6.25021562e-01,\n",
       "          2.08960993e-01, -9.12419907e-01, -1.25949815e+00,\n",
       "         -1.00072165e+00],\n",
       "        [-1.97310097e+00, -5.56189725e-01, -1.91907924e-01,\n",
       "         -4.92964274e-01,  1.33758033e+00,  1.54251394e+00,\n",
       "         -1.19249715e+00]]),\n",
       " 'Phi_01_3': array([[ 1.82715594,  1.18685018,  1.80337109,  0.84624279,  1.22011211,\n",
       "         -0.56706561],\n",
       "        [ 0.48876701, -3.0297572 ,  0.61755962, -1.50060964,  1.30671974,\n",
       "          0.49688307],\n",
       "        [-0.2838248 , -0.26164181,  2.60842862, -0.04625607, -0.46089366,\n",
       "          1.34353003],\n",
       "        [ 0.54799568, -0.79671991,  0.80514646, -0.71312095, -2.77016836,\n",
       "          0.54644903]])}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "55da49d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  8,  6,  3,  1],\n",
       "       [ 9,  7,  5,  2,  0],\n",
       "       [ 0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure = [[10,8,6,3,1],\n",
    "             [9, 7,5,2,0],\n",
    "             [0, 0,0,0,0]]\n",
    "n_dz = np.array(structure)\n",
    "n_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ad6abf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi, Theta = ut.parameter_initialization(\"zero\",n_dz)  # \"zero\" or \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3a76d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_set = [1,0] # vanilla Helmholtz machine takes value {0,1}\n",
    "activation_type = \"sigmoid\" # doesn't matter since vanilla Helmholtz machine doesn't have hidden MLP\n",
    "bias = [False,False,False] # vanilla Helmholtz machine has no bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fd35eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 0., 1., ..., 1., 0., 1.],\n",
       "       [1., 1., 0., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_dz[0,0]\n",
    "well_formed_set = ut.well_formed_generate(n,value_set)\n",
    "well_formed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "3b33e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_all_comb(entire_set,dataset):\n",
    "    \"\"\"\n",
    "    This function reorders the entire set with respect to the generated (or given) dataset. Since we are dealing with \n",
    "    categorical distributions, to visualize the result better, we put the datapoints contained in the dataset \n",
    "    (let's say k datapoints) to the first k columns of the entire_set, which are followed by false instances in subsequent\n",
    "    columns.\n",
    "        \n",
    "    Arguments:\n",
    "    entire_set -- a set containing all possible datapoints the input could be, numpy array of shape (n,2^n), \n",
    "    2^n is the number of all possible combinations of n binary neurons\n",
    "    dataset -- generated (or given) dataset, numpy array of shape (n,n_data), n_data is the number of datapoints.\n",
    "    \n",
    "    Returns:\n",
    "    reordered_set -- entire_set reordered as columns 0-k represents valid instances contained in the dataset, \n",
    "    columns k-2^n represents false instances not in the dataset. numpy array of shape (n,2^n)\n",
    "    k -- number of distinct datapoints in dataset, integer\n",
    "    \"\"\"\n",
    "    \n",
    "    values,counts = np.unique(dataset, axis=1, return_counts = True)\n",
    "    reordered_set = np.zeros(entire_set.shape)\n",
    "    \n",
    "    order = np.append(np.argsort(counts)[:int(counts.size/2)],np.flip(np.argsort(counts)[int(counts.size/2):]))\n",
    "    dataset_arranged = values[:,order]\n",
    "\n",
    "    k = counts.size\n",
    "    reordered_set[:,:k] = dataset_arranged\n",
    "    r = k\n",
    "    for i in range(entire_set.shape[1]):\n",
    "        flag = 0\n",
    "        for j in range(k):\n",
    "            if np.array_equal(entire_set[:,i], dataset[:,j]):\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            reordered_set[:,r] = entire_set[:,i]\n",
    "            r += 1\n",
    "    return reordered_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a1fc2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_set = reorder_all_comb(entire_set,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "014e9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(generation,reordered_set,dataset):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    generation -- generated instances after training, numpy array of shape (n,n_sample), n is the length of input layer, \n",
    "    n_sample is the number of datapoints generated\n",
    "    reordered_set -- entire_set reordered as columns 0-k represents valid instances contained in the dataset, \n",
    "    columns k-2^n represents false instances not in the dataset. numpy array of shape (n,2^n)\n",
    "    dataset -- numpy array of shape (n,n_data), n_data is the number of datapoints.\n",
    "    \n",
    "    Returns:\n",
    "    distribution -- assigned category for generated samples based on reordered set, numpy array of shape (n_sample, )\n",
    "    data_dist -- assigned category for dataset  based on reordered set, numpy array of shape (n_data, )\n",
    "    statistics -- python dictionary with keys:\n",
    "        percent -- percentage of positive instances\n",
    "        n_fn -- number of false negative samples, missing evidence\n",
    "        FN -- position of false negative samples, numpy array of shape (k-n_fn, )\n",
    "        n_fp -- number of false positive samples, outliers\n",
    "        FP -- position and counts of false positive samples, numpy array of shape (2,n_fp)\n",
    "    MSE -- mean squared error between the generation Q and the data evidence P on the support of P (on positive instances only).\n",
    "    \"\"\"\n",
    "    n_sample = generation.shape[1]\n",
    "    n_data = dataset.shape[1]\n",
    "    distribution = np.zeros((n_sample, ),dtype = int)\n",
    "    for i in range(n_sample):\n",
    "        for j in range(reordered_set.shape[1]):\n",
    "            if np.array_equal(generation[:,i], reordered_set[:,j]):\n",
    "                distribution[i] = j\n",
    "                break\n",
    "    values_t, counts_t = np.unique(distribution, return_counts=True)\n",
    "    \n",
    "    data_dist = np.zeros((n_data, ),dtype = int)\n",
    "    for i in range(n_data):\n",
    "        for j in range(reordered_set.shape[1]):\n",
    "            if np.array_equal(dataset[:,i], reordered_set[:,j]):\n",
    "                data_dist[i] = j\n",
    "                break\n",
    "    values_d, counts_d  = np.unique(data_dist, return_counts=True)\n",
    "    k = counts_d.size\n",
    "    \n",
    "    \n",
    "    # statistics\n",
    "    percent = np.sum(counts_t[values_t < k])/n_sample\n",
    "    n_fn = k-values_t[values_t < k].size\n",
    "    FN = np.zeros((n_fn,),dtype = int)\n",
    "    dist_positive = np.array([values_t[values_t < k], counts_t[values_t < k]])\n",
    "    s = 0\n",
    "    values_t[values_t < k]\n",
    "    dist_values = np.append(np.append(-1,values_t[values_t < k]),k)   # append 0 and k in the range\n",
    "    \n",
    "    for i in range(dist_values.size-1):\n",
    "        diff = dist_values[i+1] - dist_values[i]\n",
    "        for j in range(1,diff):\n",
    "            FN[s] = dist_values[i]+j\n",
    "            dist_positive = np.append(dist_positive, np.array([[dist_values[i]+j],[0]]),axis = 1)\n",
    "            s += 1\n",
    "    dist_positive = np.unique(dist_positive,axis = 1)\n",
    "    n_fp = values_t[values_t >= k].size\n",
    "    FP = np.array([values_t[values_t >= k], counts_t[values_t >= k]])\n",
    "    statistics = {'percent': percent, 'FN': FN, 'n_fn':n_fn, 'FP': FP, 'n_fp':n_fp}\n",
    "    \n",
    "    # metric 2: distribution difference. Since our ditributions are discrete, we calculate a mean squared error (MSE) between \n",
    "    #           the generation Q and the data evidence P on the support of P (on positive instances only).\n",
    "    \n",
    "    counts_t = counts_t/n_sample*n_data  # distribution in the same scale as dataset\n",
    "    MSE = np.sum((dist_positive[1,:]/n_sample*n_data - counts_d)**2)/k\n",
    "    ABS_Error = np.abs(dist_positive[1,:]/n_sample*n_data - counts_d).sum()/k\n",
    "    \n",
    "    return distribution,data_dist,statistics, MSE,ABS_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "95f85ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution,data_dist,statistics, MSE,ABS_Error = metrics(entire_set,reordered_set,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3def291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "k = 5\n",
    "n_data = 1000\n",
    "random_set = ut.random_generate(k,n,n_data,value_set)\n",
    "random_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a2b0712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,counts = np.unique(random_set, axis=1, return_counts = True)\n",
    "counts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "8370b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "2cf13209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(counts.size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f0c2a8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([582, 461, 254, 462, 252, 463, 250, 249, 248, 256, 247, 465, 244,\n",
       "       243, 242, 241, 240, 239, 238, 246, 460, 458, 260, 282, 281, 444,\n",
       "       279, 446, 447, 276, 448, 274, 273, 272, 271, 450, 451, 268, 454,\n",
       "       264, 457, 261, 466, 283, 236, 233, 207, 206, 484, 485, 203, 201,\n",
       "       200, 487, 210, 490, 389, 194, 492, 493, 190, 187, 186, 185, 196,\n",
       "       480, 212, 213, 232, 231, 230, 229, 228, 470, 471, 225, 224, 472,\n",
       "       473, 474, 475, 476, 477, 217, 478, 215, 479, 468, 184, 442, 287,\n",
       "       359, 407, 357, 355, 409, 353, 410, 411, 360, 350, 412, 347, 345,\n",
       "       415, 417, 419, 340, 420, 349, 405, 364, 366, 391, 387, 386, 385,\n",
       "       384, 383, 382, 381, 380, 377, 376, 374, 373, 395, 396, 397, 369,\n",
       "       398, 399, 422, 285, 337, 334, 307, 306, 305, 304, 303, 302, 301,\n",
       "       299, 308, 435, 296, 294, 293, 292, 438, 439, 289, 288, 436, 433,\n",
       "       310, 311, 425, 427, 331, 330, 328, 327, 430, 324, 432, 321, 320,\n",
       "       319, 318, 317, 316, 315, 314, 313, 312, 335, 179, 491,  88,  75,\n",
       "        74,  73,  72, 555,  70, 556,  68, 557,  65,  64,  62,  61, 561,\n",
       "        59, 563,  57,  55, 565,  76,  53,  77,  79,  99, 551,  97,  96,\n",
       "        95,  94,  93,  92, 552,  90,  89, 178,  87,  86,  85,  83, 554,\n",
       "        81,  80,  78, 566,  51,  50,  20,  19,  18,  17,  16,  15,  14,\n",
       "        13,  12,  11, 579,   9,   8,   7,   6,   5,   4,   3,   2,  21,\n",
       "        22, 578,  24, 567, 568,  47, 569, 571,  42,  41,  40,  38, 100,\n",
       "        37,  35,  34,  33,  32,  31, 574, 577,  26,  25,  36, 101, 390,\n",
       "       103, 516, 153, 151, 518, 149, 148, 147, 155, 102, 144, 519, 142,\n",
       "       141, 139, 138, 137, 145], dtype=int64)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(counts)[:int(counts.size/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c23b961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145, 137, 138, 139, 141, 142, 519, 144, 102, 155, 147, 148, 149,\n",
       "       518, 151, 153, 516, 103, 390, 101,  36,  25,  26, 577, 574,  31,\n",
       "        32,  33,  34,  35,  37, 100,  38,  40,  41,  42, 571, 569,  47,\n",
       "       568, 567,  24, 578,  22,  21,   2,   3,   4,   5,   6,   7,   8,\n",
       "         9, 579,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  50,\n",
       "        51, 566,  78,  80,  81, 554,  83,  85,  86,  87, 178,  89,  90,\n",
       "       552,  92,  93,  94,  95,  96,  97, 551,  99,  79,  77,  53,  76,\n",
       "       565,  55,  57, 563,  59, 561,  61,  62,  64,  65, 557,  68, 556,\n",
       "        70, 555,  72,  73,  74,  75,  88, 491, 179, 335, 312, 313, 314,\n",
       "       315, 316, 317, 318, 319, 320, 321, 432, 324, 430, 327, 328, 330,\n",
       "       331, 427, 425, 311, 310, 433, 436, 288, 289, 439, 438, 292, 293,\n",
       "       294, 296, 435, 308, 299, 301, 302, 303, 304, 305, 306, 307, 334,\n",
       "       337, 285, 422, 399, 398, 369, 397, 396, 395, 373, 374, 376, 377,\n",
       "       380, 381, 382, 383, 384, 385, 386, 387, 391, 366, 364, 405, 349,\n",
       "       420, 340, 419, 417, 415, 345, 347, 412, 350, 360, 411, 410, 353,\n",
       "       409, 355, 357, 407, 359, 287, 442, 184, 468, 479, 215, 478, 217,\n",
       "       477, 476, 475, 474, 473, 472, 224, 225, 471, 470, 228, 229, 230,\n",
       "       231, 232, 213, 212, 480, 196, 185, 186, 187, 190, 493, 492, 194,\n",
       "       389, 490, 210, 487, 200, 201, 203, 485, 484, 206, 207, 233, 236,\n",
       "       283, 466, 261, 457, 264, 454, 268, 451, 450, 271, 272, 273, 274,\n",
       "       448, 276, 447, 446, 279, 444, 281, 282, 260, 458, 460, 246, 238,\n",
       "       239, 240, 241, 242, 243, 244, 465, 247, 256, 248, 249, 250, 463,\n",
       "       252, 462, 254, 461, 582], dtype=int64)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.argsort(counts)[int(counts.size/2)]:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "6daa114d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       [1, 1, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[:,np.argsort(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca58f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "63252c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = well_formed_set # well_formed_set or random_set\n",
    "entire_set = ut.all_comb(n, value_set)\n",
    "reordered_set = ut.reorder_all_comb(entire_set,dataset)\n",
    "reordered_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e08dc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1dcf02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_sample(n_dz,d0,value_set,Phi,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    n_dz -- number of neurons for each layer, numpy array of shape (n+1,m), where m is the number of instantiation layers, \n",
    "    n is the maximum number of inserted layers between adjacent instantiation layers\n",
    "    d0 -- input pattern, numpy array of shape (n_d, 1)\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    Phi -- Recognition parameter set, Python dictionary of length m-1 with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i+1}, n_zi+1), where the last column represents bias b's\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation bias, MLP bias], taking binary value in {True, False}. For example, [False,True] means \n",
    "    no instantiation bias but has MLP bias\n",
    "    \n",
    "    Returns:\n",
    "    Alpha_Q -- assignment of each neuron (binary value), Python dictionary of length m-1 with each key-value pair being \n",
    "    a numpy array of shape (n_dz[0,i], 1),i = 0,...m-1\n",
    "    \"\"\"\n",
    "    \n",
    "    m = n_dz.shape[1]\n",
    "    S = d0  # assignment of each layer\n",
    "    Alpha_Q = {\"z0\":d0}\n",
    "    inst_bias = bias[0]\n",
    "    mlp_bias = bias[1]\n",
    "    a = value_set[0]\n",
    "    b = value_set[1]\n",
    "    \n",
    "    for i in range(m-2):\n",
    "        n = np.where(n_dz[1:,i] != 0)[0].size  # number of inserted layers between i and i+1\n",
    "        if n == 0:\n",
    "            phi = Phi[\"Phi_\" + str(i) + str(i+1)]\n",
    "            if inst_bias == True:\n",
    "                q = sigmoid(np.matmul(phi,np.append(S,[[1]], axis=0)))\n",
    "            else:\n",
    "                q = sigmoid(np.matmul(phi[:,:-1],S))\n",
    "            S = ((q > np.random.rand(len(q),1)).astype(int))*(a-b)+b   # rejection sampling as a or b\n",
    "            Alpha_Q[\"z\"+str(i+1)] = S\n",
    "        else:\n",
    "            g = S\n",
    "            for j in range(1,n+1):\n",
    "                phi = Phi[\"Phi_\" + str(i) + str(i+1) + \"_\" + str(j)]\n",
    "                if activation_type == \"sigmoid\":\n",
    "                    if mlp_bias == True:\n",
    "                        g = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)+b  # scale to [b,a]\n",
    "                    else:\n",
    "                        g = sigmoid(np.matmul(phi[:,:-1],g))*(a-b)+b\n",
    "                elif activation_type == \"tanh\":\n",
    "                    if mlp_bias == True:\n",
    "                        g = np.tanh(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)/2+(a+b)/2 # scale to [b,a]\n",
    "                    else:\n",
    "                        g = np.tanh(np.matmul(phi[:,:-1],g))*(a-b)/2+(a+b)/2\n",
    "                    \n",
    "            phi = Phi[\"Phi_\" + str(i) + str(i+1) + \"_\" + str(j+1)]\n",
    "            if inst_bias == True:\n",
    "                q = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))\n",
    "            else:\n",
    "                q = sigmoid(np.matmul(phi[:,:-1],g))\n",
    "            S = ((q > np.random.rand(len(q),1)).astype(int))*(a-b)+b\n",
    "            Alpha_Q[\"z\"+str(i+1)] = S\n",
    "    Alpha_Q[\"z\"+str(m-1)] = [[1]]\n",
    "        \n",
    "    return Alpha_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "938a7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_sample(n_dz,value_set,Theta,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    n_dz -- number of neurons for each layer, numpy array of shape (n+1,m), where m is the number of instantiation layers, \n",
    "    n is the maximum number of inserted layers between adjacent instantiation layers\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    Theta -- Generative parameter set, Python dictionary of length m with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i}, n_z{i+1}+1), where the last column represents bias b's\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation bias, MLP bias,data bias], taking binary value in {True, False}. For example, \n",
    "    [False,True,True] means no instantiation bias but has MLP bias and data bias\n",
    "    \n",
    "    Returns:\n",
    "    Alpha_P -- assignment of each neuron (binary value), Python dictionary of length m-1 with each key-value pair being \n",
    "    a numpy array of shape (n_dz[0,i], 1),i = m-1,...,0\n",
    "    \"\"\"\n",
    "    m = n_dz.shape[1]\n",
    "    inst_bias = bias[0]\n",
    "    mlp_bias = bias[1]\n",
    "    data_bias = bias[2]\n",
    "    a = value_set[0]\n",
    "    b = value_set[1]\n",
    "    S = [[1]]\n",
    "    Alpha_P = {\"z\"+str(m-1):S}\n",
    "    \n",
    "    \n",
    "    for i in range(m-1,0,-1):\n",
    "        n = np.where(n_dz[1:,i-1] != 0)[0].size  # number of inserted layers between i and i-1\n",
    "        if n == 0:\n",
    "            theta = Theta[\"Theta_\" + str(i) + str(i-1)]\n",
    "            if i > 1:\n",
    "                if inst_bias == True:\n",
    "                    p = sigmoid(np.matmul(theta,np.append(S,[[1]], axis=0))) #\n",
    "                else:\n",
    "                    p = sigmoid(np.matmul(theta[:,:-1],S))\n",
    "                S = ((p > np.random.rand(len(p),1)).astype(int))*(a-b)+b   # rejection sampling as a or b\n",
    "                Alpha_P[\"z\"+str(i-1)] = S\n",
    "            else:\n",
    "                if data_bias == True:\n",
    "                    p = sigmoid(np.matmul(theta,np.append(S,[[1]], axis=0)))\n",
    "                else:\n",
    "                    p = sigmoid(np.matmul(theta[:,:-1],S))\n",
    "                S = ((p > np.random.rand(len(p),1)).astype(int))*(a-b)+b   # rejection sampling as a or b\n",
    "                Alpha_P[\"z\"+str(i-1)] = S\n",
    "        else:\n",
    "            g = S\n",
    "            for j in range(n+1,1,-1):\n",
    "                theta = Theta[\"Theta_\" + str(i) + str(i-1) + \"_\" + str(j)]\n",
    "                if activation_type == \"sigmoid\":\n",
    "                    if mlp_bias == True:\n",
    "                        g = sigmoid(np.matmul(theta,np.append(g,[[1]], axis=0)))*(a-b)+b  # scale to [b,a]\n",
    "                    else:\n",
    "                        g = sigmoid(np.matmul(theta[:,:-1],g))*(a-b)+b\n",
    "                elif activation_type == \"tanh\":\n",
    "                    if mlp_bias == True:\n",
    "                        g = np.tanh(np.matmul(theta,np.append(g,[[1]], axis=0)))*(a-b)/2+(a+b)/2 # scale to [b,a]\n",
    "                    else:\n",
    "                        g = np.tanh(np.matmul(theta[:,:-1],g))*(a-b)/2+(a+b)/2\n",
    "                    \n",
    "            theta = Theta[\"Theta_\" + str(i) + str(i-1) + \"_\" + str(j-1)]\n",
    "            \n",
    "            if i > 1:\n",
    "                if inst_bias == True:\n",
    "                    p = sigmoid(np.matmul(theta,np.append(g,[[1]], axis=0)))\n",
    "                else:\n",
    "                    p = sigmoid(np.matmul(theta[:,:-1],g))\n",
    "                S = ((p > np.random.rand(len(p),1)).astype(int))*(a-b)+b   # rejection sampling as a or b\n",
    "                Alpha_P[\"z\"+str(i-1)] = S\n",
    "            else:\n",
    "                if data_bias == True:\n",
    "                    p = sigmoid(np.matmul(theta,np.append(g,[[1]], axis=0)))\n",
    "                else:\n",
    "                    p = sigmoid(np.matmul(theta[:,:-1],g))\n",
    "                S = ((p > np.random.rand(len(p),1)).astype(int))*(a-b)+b   # rejection sampling as a or b\n",
    "                Alpha_P[\"z\"+str(i-1)] = S\n",
    "            \n",
    "    return Alpha_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fb88a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "331f524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_Bernoulli_update(x,y,parameter_set,lr,value_set,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- input instantiation layer, numpy array of shape (n,1)\n",
    "    y -- target instantiation layer, numpy array of shape (m,1)\n",
    "    parameter_set -- parameters from x to y. Python dictionary of length l+1, l is the number of inserted layers. \n",
    "    The keys are ordered sequentially from layer x to y.\n",
    "    lr -- learning rate, decimals\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation (data) bias, MLP bias], taking binary value in {True, False}. For example, \n",
    "    [False,True] means no instantiation bias but has MLP (data) bias\n",
    "    \n",
    "    Returns:\n",
    "    parameter_set -- updated parameters\n",
    "    loss -- value of loss function before updating, a number\n",
    "    \"\"\"\n",
    "    \n",
    "    inst_bias = bias[0]\n",
    "    mlp_bias = bias[1]\n",
    "    a = value_set[0]\n",
    "    b = value_set[1]\n",
    "    l = len(parameter_set)\n",
    "    keys = [*parameter_set]\n",
    "    G = {'z0': x}\n",
    "    g = x\n",
    "    \n",
    "    for i in range(l-1):\n",
    "        phi = parameter_set[keys[i]]\n",
    "        if activation_type == \"sigmoid\":\n",
    "            if mlp_bias == True:\n",
    "                g = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)+b  # scale to [b,a]\n",
    "            else:\n",
    "                g = sigmoid(np.matmul(phi[:,:-1],g))*(a-b)+b\n",
    "        elif activation_type == \"tanh\":\n",
    "            if mlp_bias == True:\n",
    "                g = np.tanh(np.matmul(phi,np.append(g,[[1]], axis=0)))*(a-b)/2+(a+b)/2 # scale to [b,a]\n",
    "            else:\n",
    "                g = np.tanh(np.matmul(phi[:,:-1],g))*(a-b)/2+(a+b)/2\n",
    "        G['z'+str(i+1)] = g\n",
    "\n",
    "    phi = parameter_set[keys[l-1]]\n",
    "    if inst_bias == True:\n",
    "        q = sigmoid(np.matmul(phi,np.append(g,[[1]], axis=0)))\n",
    "    else:\n",
    "        q = sigmoid(np.matmul(phi[:,:-1],g))\n",
    "        \n",
    "    # derivatives\n",
    "    u = q - (y-b)/(a-b)\n",
    "    loss = np.sum(np.abs(u))  # for visulization\n",
    "    for i in range(l-1,0,-1):\n",
    "        phi = parameter_set[keys[i]][:,:-1]\n",
    "        dz = np.matmul(phi.T,u)\n",
    "        z = G['z'+str(i)]\n",
    "        parameter_set[keys[i]] -= lr * np.outer(u,np.append(z,[[1]], axis=0))\n",
    "        if activation_type == \"sigmoid\":\n",
    "            u = dz * z * (1-z) * (a-b)\n",
    "        elif activation_type == \"tanh\":\n",
    "            u = dz * (1-z**2) * (a-b)/2\n",
    "            \n",
    "    parameter_set[keys[0]] -= lr * np.outer(u,np.append(x,[[1]], axis=0))\n",
    "    print(u)\n",
    "    return parameter_set,loss,G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "596ad577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Theta_10_2', 'Theta_10_1']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = [*parameter_set]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "3adc3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_update_delta(Phi,Alpha_P,lr,n_dz,value_set,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Phi -- Recognition parameter set, Python dictionary of length m-1 with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i+1}, n_zi+1), where the last column represents bias b's\n",
    "    Alpha_P -- assignment of each neuron (binary value), Python dictionary of length m with each key-value pair being \n",
    "    a numpy array of shape (n_dz[0,i], 1),i = m-1,...,0\n",
    "    lr -- learning rate, decimals\n",
    "    \n",
    "    n_dz -- number of neurons for each layer, numpy array of shape (n+1,m), where m is the number of instantiation layers, \n",
    "    n is the maximum number of inserted layers between adjacent instantiation layers\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation bias, MLP bias], taking binary value in {True, False}. For example, [False,True] means \n",
    "    no instantiation bias but has MLP bias\n",
    "    \n",
    "    Returns:\n",
    "    Phi -- Updated recognition parameter set, Python dictionary of length m-1 with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i+1}, n_zi+1), where the last column represents bias b's\n",
    "    Loss -- numpy array of length m-1; the first m-2 values are layer loss, the last term is the total loss\n",
    "    \"\"\"\n",
    "    m = n_dz.shape[1]\n",
    "    Loss = np.zeros(m)\n",
    "    for i in range(m-2):\n",
    "        n = np.where(n_dz[1:,i] != 0)[0].size  # number of inserted layers between i and i+1\n",
    "        if n == 0:\n",
    "            parameter_set = {\"Phi_\" + str(i) + str(i+1): Phi[\"Phi_\" + str(i) + str(i+1)]}\n",
    "        else:\n",
    "            parameter_set = {k: Phi[k] for k in [\"Phi_\" + str(i) + str(i+1) + \"_\" + str(j) for j in range(1,n+2)]}\n",
    "            \n",
    "        x = Alpha_P['z'+str(i)]\n",
    "        y = Alpha_P['z'+str(i+1)]\n",
    "        parameter_set,loss,G = multi_Bernoulli_update(x,y,parameter_set,lr,value_set,activation_type,bias)\n",
    "        Loss[i] = loss\n",
    "        Loss[-1] += loss\n",
    "        for k in [*parameter_set]:\n",
    "            Phi[k] = parameter_set[k]\n",
    "        \n",
    "    return Phi,Loss,G,parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4bb33d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_update_delta(Theta,Alpha_Q,lr,n_dz,value_set,activation_type,bias):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Theta -- Generative parameter set, Python dictionary of length m with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i}, n_z{i+1}+1), where the last column represents bias b's\n",
    "    Alpha_Q -- Recognition assignment of each neuron (binary value), Python dictionary of length m with each key-value pair being \n",
    "    a numpy array of shape (n_z, 1)\n",
    "    lr -- learning rate, decimals\n",
    "    \n",
    "    n_dz -- number of neurons for each layer, numpy array of shape (n+1,m), where m is the number of instantiation layers, \n",
    "    n is the maximum number of inserted layers between adjacent instantiation layers\n",
    "    value_set -- list or array [a,b], where a is the positive outcome and b is the negative outcome of a Bernoulli experiment\n",
    "    activation_type -- we provide 2 choices of activation functions: tanh(x) and sigmoid(x)\n",
    "    bias -- list or array [instantiation bias, MLP bias], taking binary value in {True, False}. For example, [False,True] means \n",
    "    no instantiation bias but has MLP bias\n",
    "    \n",
    "    Returns:\n",
    "    Theta -- Updated generative parameter set, Python dictionary of length m with each key-value pair being a parameter matrix of \n",
    "    shape (n_z{i}, n_z{i+1}+1), where the last column represents bias b's\n",
    "    Loss -- numpy array of length m; the first m-1 values are layer loss, the last term is the total loss\n",
    "    \"\"\"\n",
    "    \n",
    "    m = n_dz.shape[1]\n",
    "    inst_bias = bias[0]\n",
    "    mlp_bias = bias[1]\n",
    "    data_bias = bias[2]\n",
    "    \n",
    "    Loss = np.zeros(m)\n",
    "    bias = [inst_bias,mlp_bias]\n",
    "    for i in range(m-1,1,-1):\n",
    "        n = np.where(n_dz[1:,i-1] != 0)[0].size  # number of inserted layers between i and i+1\n",
    "        if n == 0:\n",
    "            parameter_set = {\"Theta_\" + str(i) + str(i-1): Theta[\"Theta_\" + str(i) + str(i-1)]}\n",
    "        else:\n",
    "            parameter_set = {k: Theta[k] for k in [\"Theta_\" + str(i) + str(i-1) + \"_\" + str(j) for j in range(n+1,0,-1)]}\n",
    "       \n",
    "        x = Alpha_Q['z'+str(i)]\n",
    "        y = Alpha_Q['z'+str(i-1)]\n",
    "        parameter_set,loss,G = multi_Bernoulli_update(x,y,parameter_set,lr,value_set,activation_type,bias)\n",
    "        Loss[i-1] = loss\n",
    "        Loss[-1] += loss\n",
    "        for k in [*parameter_set]:\n",
    "            Theta[k] = parameter_set[k]\n",
    "            \n",
    "    bias = [data_bias,mlp_bias]     \n",
    "    n = np.where(n_dz[1:,0] != 0)[0].size  # number of inserted layers between 0 and 1\n",
    "    if n == 0:\n",
    "        parameter_set = {\"Theta_10\": Theta[\"Theta_10\"]}\n",
    "    else:\n",
    "        parameter_set = {k: Theta[k] for k in [\"Theta_10_\"+ str(j) for j in range(n+1,0,-1)]}\n",
    "\n",
    "    x = Alpha_Q['z1']\n",
    "    y = Alpha_Q['z0']\n",
    "    parameter_set,loss,G = multi_Bernoulli_update(x,y,parameter_set,lr,value_set,activation_type,bias)\n",
    "    Loss[0] = loss\n",
    "    Loss[-1] += loss\n",
    "    for k in [*parameter_set]:\n",
    "        Theta[k] = parameter_set[k]\n",
    "\n",
    "    return Theta,Loss,G,parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8bca34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = dataset.shape[1]\n",
    "n_layer = n_dz.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d770df31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta_10_1': array([[ 0.6010653 , -0.48508052,  0.6774026 , -0.82140179,  0.937665  ,\n",
       "          2.29049904,  0.57965442,  0.7413375 ,  0.98325658, -1.60315525],\n",
       "        [-0.81068888,  1.07310774,  0.99413419, -0.80715707, -0.73535167,\n",
       "         -1.27548043, -0.68263782, -0.32889438, -1.03038359, -1.08745944],\n",
       "        [-0.8054341 , -1.29747267, -0.52761607, -1.17408012,  0.4406551 ,\n",
       "          0.26973603,  0.7454193 ,  1.2352713 ,  0.21740866,  0.36839592],\n",
       "        [-1.34705628, -0.52059043, -0.60186252, -0.42716726,  2.15936337,\n",
       "         -0.76078391, -0.65105585, -0.13506363, -2.29521727,  1.50811776],\n",
       "        [ 1.7648389 , -1.04155708, -1.43912931, -0.804952  ,  0.39230544,\n",
       "         -0.04600603,  2.20639813, -1.42770988,  0.00412754,  1.01395777],\n",
       "        [-0.5381456 , -0.45457833, -1.48474235,  0.65566491,  0.190558  ,\n",
       "          0.54755684,  0.49753518, -0.1505676 , -1.62248917, -1.54557073],\n",
       "        [-1.13553163,  0.2522295 , -1.50273098, -0.06173152,  0.11635276,\n",
       "          1.22484777, -0.31532862,  1.360499  , -0.10583422, -0.29316704],\n",
       "        [ 1.1166365 , -1.82095514,  0.97272322,  0.21722657,  0.09164444,\n",
       "          0.07264183,  0.62408383, -0.48323   , -0.25644487,  0.20475995],\n",
       "        [-0.26924005,  0.58660559, -1.24787231,  0.54248865, -0.19218812,\n",
       "         -1.73051789, -0.49089137, -1.62002356,  0.74729062,  0.03714414],\n",
       "        [ 0.44060994, -0.84028627, -0.10566975,  0.18610986,  1.55226091,\n",
       "          0.16487945, -0.06711949,  0.37494715, -0.97160368, -0.07755127]]),\n",
       " 'Theta_10_2': array([[ 0.47100845, -1.28422505, -0.88207863,  0.87931555, -0.19206961,\n",
       "          1.38147438, -0.44738616, -0.95620211,  0.11845318],\n",
       "        [ 1.59383796,  1.46272255, -1.14990658,  0.43867565,  0.10043057,\n",
       "         -0.85037459, -0.75580047,  0.611733  ,  0.77017052],\n",
       "        [-1.27875783,  0.7066523 ,  0.8694089 , -0.92095319, -1.04045518,\n",
       "         -2.1522639 , -1.41605687,  2.18054985, -0.988983  ],\n",
       "        [-0.71231306, -0.78732015, -0.44288898, -0.57400801, -0.09374139,\n",
       "          0.04825647,  0.10237654, -0.03729666, -1.38965886],\n",
       "        [ 0.8567297 , -0.43788026,  0.48559359, -0.26208211,  0.47044291,\n",
       "          0.60822621, -0.03386072, -0.85044072, -0.31203519],\n",
       "        [-0.56745146,  0.80677387,  2.94519307, -1.14143492,  0.04205269,\n",
       "          0.05235754,  1.08620885,  1.35251843, -0.97383012],\n",
       "        [-0.5102379 , -1.6197585 , -1.08428401,  0.02450444, -1.50192928,\n",
       "         -0.45507361,  0.19404227,  1.56896442,  1.63194057],\n",
       "        [ 1.24137332, -0.7749687 , -0.77884182, -1.33523262,  0.20092632,\n",
       "         -0.6598023 , -0.99105373, -1.90124471, -1.06626173],\n",
       "        [ 0.70328115,  0.83267587,  0.80966492, -0.35456688, -0.18504369,\n",
       "          0.45952521, -0.24894963, -0.1480031 , -1.76555179]]),\n",
       " 'Theta_21_1': array([[ 1.86572624, -1.16521331,  1.14612041, -1.18813113, -0.28135825,\n",
       "         -0.91413135, -1.78285474, -1.46717752],\n",
       "        [ 1.061944  ,  1.67343772,  0.71765884,  1.2940693 , -1.07974353,\n",
       "         -0.11121435, -0.17451316,  0.82311579],\n",
       "        [-0.40562003,  0.09652434, -1.21775893,  0.28993704, -0.97233241,\n",
       "         -1.47448465, -1.08256937, -0.54214791],\n",
       "        [-2.2132938 ,  0.30578166,  1.12701873, -1.27416157,  1.21162568,\n",
       "         -0.56176545, -1.04728348, -1.24584195],\n",
       "        [ 0.41443358,  1.68973229,  0.15121716,  0.19930855,  1.39870512,\n",
       "         -0.28488094,  1.22678415,  0.16482332],\n",
       "        [ 1.36345929,  1.186473  , -1.67562244, -0.41802095, -1.74718208,\n",
       "          0.67448355, -1.80815459,  0.3923561 ],\n",
       "        [ 0.28447234,  2.02815753,  1.61157231, -0.33551588, -1.37140912,\n",
       "         -1.8169209 , -0.41192378,  1.38698255],\n",
       "        [ 0.70581756, -0.64209396,  0.46540251, -0.38717875, -0.92435058,\n",
       "         -0.09935347,  0.5194343 ,  0.72749667]]),\n",
       " 'Theta_21_2': array([[ 0.30507198,  0.39628288,  0.20262374, -1.04987437,  1.02930398,\n",
       "          0.68228802, -0.22517998],\n",
       "        [ 0.53589942,  0.13594348, -0.28113659,  0.86883359, -1.14993301,\n",
       "          0.0854987 , -1.60134498],\n",
       "        [ 0.45938593,  0.78414554,  0.45603234,  0.25064447, -0.94448883,\n",
       "          0.15048361, -1.59355945],\n",
       "        [ 0.41977966,  0.46274689, -0.66347496,  2.56810717, -1.52714047,\n",
       "         -1.18084228, -0.97879401],\n",
       "        [-0.61316521,  0.65522352, -1.26499756, -0.22244135,  0.17164336,\n",
       "          0.74604419,  0.33491339],\n",
       "        [ 0.50591788,  1.34817562, -1.23609984, -1.13281108, -0.40709846,\n",
       "          1.51365154, -0.37726425],\n",
       "        [-0.69135017, -1.13170733,  0.5199713 ,  1.51227393,  0.59299122,\n",
       "         -0.79028933,  0.40717868]]),\n",
       " 'Theta_32_1': array([[-0.09361928,  1.37767234,  0.54731368,  0.87408881,  0.19129206,\n",
       "          0.04570822],\n",
       "        [ 1.85329348, -0.43150949,  0.30942292, -0.84722214, -1.03860788,\n",
       "          0.60032038],\n",
       "        [-1.87757387,  0.71180323, -0.74035838, -0.09427455, -2.09055671,\n",
       "         -0.50871147],\n",
       "        [-0.21183684,  0.16783422, -0.67395799, -0.40002016,  0.51168242,\n",
       "          1.30641282],\n",
       "        [-0.46122986, -0.48001527, -1.37019663,  0.0464977 , -0.14042328,\n",
       "          0.51731224],\n",
       "        [ 0.23613678, -0.61655374,  2.48965145,  0.33129247, -0.48980078,\n",
       "          0.71245915]]),\n",
       " 'Theta_32_2': array([[ 2.03006235, -0.54350278, -0.8729317 ,  0.03256393],\n",
       "        [-0.07019583,  0.23151138,  0.29178878,  1.31476377],\n",
       "        [-0.95083252, -1.43291892, -0.19384667,  1.18049014],\n",
       "        [ 0.48008935, -0.07453456,  1.76859189,  0.46986854],\n",
       "        [ 0.74310084, -1.39660993, -0.38514146, -0.64501137]]),\n",
       " 'Theta_43_1': array([[ 0.29218311,  1.13640728, -0.36497119],\n",
       "        [ 1.30745287,  0.96120374,  0.30988103],\n",
       "        [-1.11312883,  0.5406087 , -1.82712464]]),\n",
       " 'Theta_43_2': array([[-0.49928421,  0.754304  ],\n",
       "        [ 1.02220281,  1.13186162]])}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi, Theta = ut.parameter_initialization(\"random\",n_dz)  # \"zero\" or \"random\"\n",
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4aa5a2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "d0 = dataset[:,i:i+1]\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "3b6ce5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z0': array([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]),\n",
       " 'z1': array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]]),\n",
       " 'z2': array([[1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]),\n",
       " 'z3': array([[0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " 'z4': [[1]]}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alpha_Q = wake_sample(n_dz,d0,value_set,Phi,activation_type,bias)\n",
    "Alpha_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "daa4006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15636175]\n",
      " [0.3550469 ]]\n",
      "[[ 0.74577729]\n",
      " [-0.16460142]\n",
      " [ 0.36496014]\n",
      " [-0.09660865]\n",
      " [ 0.31582683]]\n",
      "[[ 0.7539933 ]\n",
      " [ 1.09743588]\n",
      " [ 0.14360652]\n",
      " [ 0.46148075]\n",
      " [-0.35607646]\n",
      " [-0.29649025]\n",
      " [ 0.04985954]]\n",
      "[[ 0.11138586]\n",
      " [ 0.48970154]\n",
      " [ 0.72092184]\n",
      " [-0.02659587]\n",
      " [-0.3115253 ]\n",
      " [-0.19046928]\n",
      " [-0.22422034]\n",
      " [-0.00498524]\n",
      " [ 0.18256938]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Theta_10_1': array([[ 0.6028122 , -0.48238869,  0.68023287, -0.82012369,  0.93856391,\n",
       "          2.29250678,  0.58267416,  0.7414749 ,  0.98462615, -1.59952184],\n",
       "        [-0.81734877,  1.06284542,  0.98334406, -0.81202968, -0.73877867,\n",
       "         -1.28313473, -0.69415029, -0.32941821, -1.03560493, -1.10131146],\n",
       "        [-0.78710502, -1.2692291 , -0.49791989, -1.1606699 ,  0.45008676,\n",
       "          0.29080188,  0.77710347,  1.23671295,  0.23177864,  0.40651893],\n",
       "        [-1.34825199, -0.52243292, -0.60379978, -0.42804209,  2.15874809,\n",
       "         -0.76215816, -0.6531228 , -0.13515768, -2.2961547 ,  1.50563078],\n",
       "        [ 1.77377031, -1.02779452, -1.42465892, -0.79841745,  0.39690131,\n",
       "         -0.03574104,  2.22183723, -1.42700739,  0.01112976,  1.0325344 ],\n",
       "        [-0.51895583, -0.42500851, -1.45365171,  0.66970484,  0.20043255,\n",
       "          0.5696119 ,  0.53070717, -0.14905825, -1.60744442, -1.50565755],\n",
       "        [-1.11751265,  0.27999522, -1.47353722, -0.04854818,  0.12562485,\n",
       "          1.24555723, -0.2841805 ,  1.36191626, -0.09170737, -0.25568901],\n",
       "        [ 1.12577753, -1.8068696 ,  0.9875332 ,  0.22391447,  0.09634817,\n",
       "          0.08314772,  0.63988526, -0.48251102, -0.24927832,  0.22377253],\n",
       "        [-0.24901734,  0.61776707, -1.21510815,  0.55728431, -0.18178205,\n",
       "         -1.70727567, -0.45593383, -1.61843297,  0.76314519,  0.07920573],\n",
       "        [ 0.45477147, -0.81846455, -0.08272571,  0.19647095,  1.55954807,\n",
       "          0.18115549, -0.04263946,  0.37606101, -0.96050106, -0.04809643]]),\n",
       " 'Theta_10_2': array([[ 0.47100845, -1.28422505, -0.88207863,  0.87374626, -0.19206961,\n",
       "          1.38147438, -0.44738616, -0.9617714 ,  0.11288389],\n",
       "        [ 1.59383796,  1.46272255, -1.14990658,  0.41419057,  0.10043057,\n",
       "         -0.85037459, -0.75580047,  0.58724792,  0.74568545],\n",
       "        [-1.27875783,  0.7066523 ,  0.8694089 , -0.95699928, -1.04045518,\n",
       "         -2.1522639 , -1.41605687,  2.14450376, -1.02502909],\n",
       "        [-0.71231306, -0.78732015, -0.44288898, -0.57267821, -0.09374139,\n",
       "          0.04825647,  0.10237654, -0.03596687, -1.38832907],\n",
       "        [ 0.8567297 , -0.43788026,  0.48559359, -0.24650585,  0.47044291,\n",
       "          0.60822621, -0.03386072, -0.83486446, -0.29645893],\n",
       "        [-0.56745146,  0.80677387,  2.94519307, -1.13191145,  0.04205269,\n",
       "          0.05235754,  1.08620885,  1.3620419 , -0.96430666],\n",
       "        [-0.5102379 , -1.6197585 , -1.08428401,  0.03571546, -1.50192928,\n",
       "         -0.45507361,  0.19404227,  1.58017543,  1.64315159],\n",
       "        [ 1.24137332, -0.7749687 , -0.77884182, -1.33498336,  0.20092632,\n",
       "         -0.6598023 , -0.99105373, -1.90099545, -1.06601246],\n",
       "        [ 0.70328115,  0.83267587,  0.80966492, -0.36369535, -0.18504369,\n",
       "          0.45952521, -0.24894963, -0.15713157, -1.77468025]]),\n",
       " 'Theta_21_1': array([[ 1.85297592, -1.17381534,  1.13622888, -1.19490309, -0.2852772 ,\n",
       "         -0.91946882, -1.79552652, -1.48388743],\n",
       "        [ 1.02759794,  1.65026606,  0.6910136 ,  1.27582739, -1.09030016,\n",
       "         -0.12559213, -0.20864768,  0.7781036 ],\n",
       "        [-0.4088426 ,  0.09435022, -1.22025896,  0.28822546, -0.97332291,\n",
       "         -1.47583367, -1.0857721 , -0.54637125],\n",
       "        [-2.1794162 ,  0.32863727,  1.15330054, -1.25616847,  1.22203833,\n",
       "         -0.54758377, -1.01361454, -1.2014437 ],\n",
       "        [ 0.37911295,  1.66590314,  0.12381586,  0.18054903,  1.38784894,\n",
       "         -0.29966669,  1.19168106,  0.1185339 ],\n",
       "        [ 1.35375623,  1.1799268 , -1.68314996, -0.42317445, -1.75016443,\n",
       "          0.67042169, -1.81779789,  0.37963976],\n",
       "        [ 0.25762652,  2.01004593,  1.59074566, -0.34977426, -1.37966047,\n",
       "         -1.82815897, -0.43860425,  1.35179978],\n",
       "        [ 0.72047338, -0.63220637,  0.47677231, -0.37939474, -0.91984595,\n",
       "         -0.09321832,  0.53399985,  0.74670384]]),\n",
       " 'Theta_21_2': array([[ 0.26737231,  0.39628288,  0.16492408, -1.08757403,  0.99160431,\n",
       "          0.64458835, -0.26287965],\n",
       "        [ 0.48102762,  0.13594348, -0.33600839,  0.8139618 , -1.2048048 ,\n",
       "          0.03062691, -1.65621677],\n",
       "        [ 0.45220561,  0.78414554,  0.44885201,  0.24346415, -0.95166916,\n",
       "          0.14330329, -1.60073977],\n",
       "        [ 0.39670562,  0.46274689, -0.686549  ,  2.54503313, -1.55021451,\n",
       "         -1.20391632, -1.00186804],\n",
       "        [-0.59536138,  0.65522352, -1.24719374, -0.20463753,  0.18944719,\n",
       "          0.76384801,  0.35271721],\n",
       "        [ 0.5207424 ,  1.34817562, -1.22127533, -1.11798657, -0.39227394,\n",
       "          1.52847605, -0.36243974],\n",
       "        [-0.69384315, -1.13170733,  0.51747832,  1.50978095,  0.59049824,\n",
       "         -0.79278231,  0.4046857 ]]),\n",
       " 'Theta_32_1': array([[-0.08886298,  1.38242864,  0.55206997,  0.87884511,  0.19604836,\n",
       "          0.05522082],\n",
       "        [ 1.84127643, -0.44352653,  0.29740588, -0.85923918, -1.05062492,\n",
       "          0.5762863 ],\n",
       "        [-1.85543661,  0.73394048, -0.71822113, -0.0721373 , -2.06841946,\n",
       "         -0.46443697],\n",
       "        [-0.19745653,  0.18221453, -0.65957768, -0.38563985,  0.52606272,\n",
       "          1.33517342],\n",
       "        [-0.44200482, -0.46079022, -1.35097159,  0.06572275, -0.12119824,\n",
       "          0.55576233],\n",
       "        [ 0.2429821 , -0.60970842,  2.49649677,  0.33813779, -0.48295546,\n",
       "          0.7261498 ]]),\n",
       " 'Theta_32_2': array([[ 2.03006235, -0.54350278, -0.8729317 , -0.00472494],\n",
       "        [-0.07019583,  0.23151138,  0.29178878,  1.32299384],\n",
       "        [-0.95083252, -1.43291892, -0.19384667,  1.16224213],\n",
       "        [ 0.48008935, -0.07453456,  1.76859189,  0.47469897],\n",
       "        [ 0.74310084, -1.39660993, -0.38514146, -0.66080271]]),\n",
       " 'Theta_43_1': array([[ 0.27857945,  1.10992087, -0.40098746],\n",
       "        [ 1.29293656,  0.93294041,  0.2714485 ],\n",
       "        [-1.12246356,  0.52243392, -1.85183872]]),\n",
       " 'Theta_43_2': array([[-0.5071023 ,  0.74648591],\n",
       "        [ 1.00445046,  1.11410928]])}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta,Loss_P,G,parameter_set = sleep_update_delta(Theta,Alpha_Q,lr,n_dz,value_set,activation_type,bias)\n",
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b3196912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta_10_2': array([[ 0.00675541,  0.00675541,  0.00675541,  0.00675541,  0.00675541,\n",
       "          0.        ,  0.        ,  0.00675541,  0.00675541],\n",
       "        [ 0.00432536,  0.00432536,  0.00432536,  0.00432536,  0.00432536,\n",
       "          0.        ,  0.        ,  0.00432536,  0.00432536],\n",
       "        [ 0.00010898,  0.00010898,  0.00010898,  0.00010898,  0.00010898,\n",
       "          0.        ,  0.        ,  0.00010898,  0.00010898],\n",
       "        [ 0.01201875,  0.01201875,  0.01201875,  0.01201875,  0.01201875,\n",
       "          0.        ,  0.        ,  0.01201875,  0.01201875],\n",
       "        [ 0.01508518,  0.01508518,  0.01508518,  0.01508518,  0.01508518,\n",
       "          0.        ,  0.        ,  0.01508518,  0.01508518],\n",
       "        [ 0.02055841,  0.02055841,  0.02055841,  0.02055841,  0.02055841,\n",
       "          0.        ,  0.        ,  0.02055841,  0.02055841],\n",
       "        [-0.01633431, -0.01633431, -0.01633431, -0.01633431, -0.01633431,\n",
       "         -0.        , -0.        , -0.01633431, -0.01633431],\n",
       "        [ 0.00105825,  0.00105825,  0.00105825,  0.00105825,  0.00105825,\n",
       "          0.        ,  0.        ,  0.00105825,  0.00105825],\n",
       "        [-0.00142964, -0.00142964, -0.00142964, -0.00142964, -0.00142964,\n",
       "         -0.        , -0.        , -0.00142964, -0.00142964]]),\n",
       " 'Theta_10_1': array([[-7.99767356e-01, -3.18659934e-01, -8.19134075e-04,\n",
       "         -4.36604228e-01, -7.21867700e-01, -4.81986396e-01,\n",
       "         -5.98133724e-01, -1.67094856e-02, -7.82599823e-03,\n",
       "         -8.33263792e-01],\n",
       "        [ 1.56496682e-01,  6.23546612e-02,  1.60286319e-04,\n",
       "          8.54337360e-02,  1.41253452e-01,  9.43140169e-02,\n",
       "          1.17041465e-01,  3.26967467e-03,  1.53137378e-03,\n",
       "          1.63051190e-01],\n",
       "        [-6.86340763e-01, -2.73466153e-01, -7.02960807e-04,\n",
       "         -3.74683058e-01, -6.19489185e-01, -4.13628924e-01,\n",
       "         -5.13303717e-01, -1.43396714e-02, -6.71608006e-03,\n",
       "         -7.15086584e-01],\n",
       "        [ 5.70286947e-01,  2.27225580e-01,  5.84096697e-04,\n",
       "          3.11327651e-01,  5.14739347e-01,  3.43688134e-01,\n",
       "          4.26508850e-01,  1.19149669e-02,  5.58045362e-03,\n",
       "          5.94172118e-01],\n",
       "        [-5.83606434e-01, -2.32532606e-01, -5.97738721e-04,\n",
       "         -3.18598946e-01, -5.26761477e-01, -3.51715233e-01,\n",
       "         -4.36470289e-01, -1.21932500e-02, -5.71078937e-03,\n",
       "         -6.08049461e-01],\n",
       "        [-7.90795521e-01, -3.15085189e-01, -8.09944983e-04,\n",
       "         -4.31706377e-01, -7.13769747e-01, -4.76579445e-01,\n",
       "         -5.91423826e-01, -1.65220377e-02, -7.73820574e-03,\n",
       "         -8.23916191e-01],\n",
       "        [-2.33812573e-01, -9.31604654e-02, -2.39474447e-04,\n",
       "         -1.27641566e-01, -2.11038551e-01, -1.40909076e-01,\n",
       "         -1.74864833e-01, -4.88503038e-03, -2.28793632e-03,\n",
       "         -2.43605280e-01],\n",
       "        [-7.89748915e-01, -3.14668179e-01, -8.08873033e-04,\n",
       "         -4.31135020e-01, -7.12825083e-01, -4.75948700e-01,\n",
       "         -5.90641085e-01, -1.65001710e-02, -7.72796434e-03,\n",
       "         -8.22825751e-01],\n",
       "        [-6.08069149e-01, -2.42279550e-01, -6.22793811e-04,\n",
       "         -3.31953485e-01, -5.48841453e-01, -3.66457890e-01,\n",
       "         -4.54765578e-01, -1.27043479e-02, -5.95016544e-03,\n",
       "         -6.33536741e-01],\n",
       "        [-7.87126212e-01, -3.13623187e-01, -8.06186820e-04,\n",
       "         -4.29703250e-01, -7.10457839e-01, -4.74368106e-01,\n",
       "         -5.88679606e-01, -1.64453751e-02, -7.70230029e-03,\n",
       "         -8.20093202e-01]])}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "047ac2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z0': array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]]),\n",
       " 'z1': array([[0.95980092],\n",
       "        [0.38242383],\n",
       "        [0.00098304],\n",
       "        [0.5239688 ],\n",
       "        [0.86631353],\n",
       "        [0.57843195],\n",
       "        [0.71782037],\n",
       "        [0.02005306],\n",
       "        [0.00939198]])}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Alpha_P = sleep_sample(n_dz,value_set,Theta,activation_type,bias)\n",
    "Phi,Loss_Q = wake_update_delta(Phi,Alpha_P,lr,n_dz,value_set,activation_type,bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
